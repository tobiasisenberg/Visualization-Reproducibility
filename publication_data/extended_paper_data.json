{
    "10.1145/3592145": {
        "doi": "10.1145/3592145",
        "authors": [
            {
                "family": "Li",
                "given": "Bosheng",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Klein",
                "given": "Jonathan",
                "countries": [
                    "SA"
                ]
            },
            {
                "family": "Michels",
                "given": "Dominik L.",
                "countries": [
                    "SA"
                ]
            },
            {
                "family": "Benes",
                "given": "Bedrich",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Pirk",
                "given": "S\u00f6ren",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Pa\u0142ubicki",
                "given": "Wojtek",
                "countries": [
                    "PL"
                ]
            }
        ],
        "title": "Rhizomorph: The Coordinated Function of Shoots and Roots",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2023,
        "volume": "42",
        "number": "4",
        "pages": "59:1\u201359:16",
        "article_number": "59",
        "number_of_pages": 16,
        "abstract": "Computer graphics has dedicated a considerable amount of effort to generating realistic models of trees and plants. Many existing methods leverage procedural modeling algorithms - that often consider biological findings - to generate branching structures of individual trees. While the realism of tree models generated by these algorithms steadily increases, most approaches neglect to model the root system of trees. However, the root system not only adds to the visual realism of tree models but also plays an important role in the development of trees. In this paper, we advance tree modeling in the following ways: First, we define a physically-plausible soil model to simulate resource gradients, such as water and nutrients. Second, we propose a novel developmental procedural model for tree roots that enables us to emergently develop root systems that adapt to various soil types. Third, we define long-distance signaling to coordinate the development of shoots and roots. We show that our advanced procedural model of tree development enables - for the first time - the generation of trees with their root systems.",
        "countries": [
            "US",
            "SA",
            "PL"
        ]
    },
    "10.1145/3631936": {
        "doi": "10.1145/3631936",
        "authors": [
            {
                "family": "Jeske",
                "given": "Stefan Rhys",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Westhofen",
                "given": "Lukas",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "L\u00f6schner",
                "given": "Fabian",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Fern\u00e1ndez-Fern\u00e1ndez",
                "given": "Jos\u00e9 Antonio",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Bender",
                "given": "Jan",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Implicit Surface Tension for SPH Fluid Simulation",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2024,
        "volume": "43",
        "number": "1",
        "pages": "13:1\u201313:14",
        "article_number": "13",
        "number_of_pages": 14,
        "abstract": "The numerical simulation of surface tension is an active area of research in many different fields of application and has been attempted using a wide range of methods. Our contribution is the derivation and implementation of an implicit cohesion force based approach for the simulation of surface tension effects using the Smoothed Particle Hydrodynamics (SPH) method. We define a continuous formulation inspired by the properties of surface tension at the molecular scale which is spatially discretized using SPH. An adapted variant of the linearized backward Euler method is used for time discretization, which we also strongly couple with an implicit viscosity model. Finally, we extend our formulation with adhesion forces for interfaces with rigid objects. Existing SPH approaches for surface tension in computer graphics are mostly based on explicit time integration, thereby lacking in stability for challenging settings. We compare our implicit surface tension method to these approaches and further evaluate our model on a wider variety of complex scenarios, showcasing its efficacy and versatility. Among others, these include but are not limited to simulations of a water crown, a dripping faucet, and a droplet toy.",
        "countries": [
            "DE"
        ]
    },
    "10.1145/3592450": {
        "doi": "10.1145/3592450",
        "authors": [
            {
                "family": "Avrahami",
                "given": "Omri",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Fried",
                "given": "Ohad",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Lischinski",
                "given": "Dani",
                "countries": [
                    "IL"
                ]
            }
        ],
        "title": "Blended Latent Diffusion",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2023,
        "volume": "42",
        "number": "4",
        "pages": "149:1\u2013149:11",
        "article_number": "149",
        "number_of_pages": 11,
        "abstract": "The tremendous progress in neural image generation, coupled with the emergence of seemingly omnipotent vision-language models has finally enabled text-based interfaces for creating and editing images. Handling generic images requires a diverse underlying generative model, hence the latest works utilize diffusion models, which were shown to surpass GANs in terms of diversity. One major drawback of diffusion models, however, is their relatively slow inference time. In this paper, we present an accelerated solution to the task of local text-driven editing of generic images, where the desired edits are confined to a user-provided mask. Our solution leverages a text-to-image Latent Diffusion Model (LDM), which speeds up diffusion by operating in a lower-dimensional latent space and eliminating the need for resource-intensive CLIP gradient calculations at each diffusion step. We first enable LDM to perform local image edits by blending the latents at each step, similarly to Blended Diffusion. Next we propose an optimization-based solution for the inherent inability of LDM to accurately reconstruct images. Finally, we address the scenario of performing local edits using thin masks. We evaluate our method against the available baselines both qualitatively and quantitatively and demonstrate that in addition to being faster, it produces more precise results.",
        "countries": [
            "IL"
        ]
    },
    "10.1145/3592141": {
        "doi": "10.1145/3592141",
        "authors": [
            {
                "family": "Reed",
                "given": "Albert",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Kim",
                "given": "Juhyeon",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Blanford",
                "given": "Thomas",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Pediredla",
                "given": "Adithya",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Brown",
                "given": "Daniel",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Jayasuriya",
                "given": "Suren",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Neural Volumetric Reconstruction for Coherent Synthetic Aperture Sonar",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2023,
        "volume": "42",
        "number": "4",
        "pages": "113:1\u2013113:20",
        "article_number": "113",
        "number_of_pages": 20,
        "abstract": "Synthetic aperture sonar (SAS) measures a scene from multiple views in order to increase the resolution of reconstructed imagery. Image reconstruction methods for SAS coherently combine measurements to focus acoustic energy onto the scene. However, image formation is typically under-constrained due to a limited number of measurements and bandlimited hardware, which limits the capabilities of existing reconstruction methods. To help meet these challenges, we design an analysis-by-synthesis optimization that leverages recent advances in neural rendering to perform coherent SAS imaging. Our optimization enables us to incorporate physics-based constraints and scene priors into the image formation process. We validate our method on simulation and experimental results captured in both air and water. We demonstrate both quantitatively and qualitatively that our method typically produces superior reconstructions than existing approaches. We share code and data for reproducibility.",
        "countries": [
            "US"
        ]
    },
    "10.1145/3386569.3392396": {
        "doi": "10.1145/3386569.3392396",
        "authors": [
            {
                "family": "Ly",
                "given": "Micka\u00ebl",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Jouve",
                "given": "Jean",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Boissieux",
                "given": "Laurence",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Bertails-Descoubes",
                "given": "Florence",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Projective dynamics with dry frictional contact",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2020,
        "volume": "39",
        "number": "4",
        "pages": "57:1\u201357:8",
        "article_number": "57",
        "number_of_pages": 8,
        "abstract": "Projective dynamics was introduced a few years ago as a fast method to yield an approximate yet stable solution to the dynamics of nodal systems subject to stiff internal forces. Previous attempts to include contact forces in that framework considered adding a quadratic penalty energy to the global system, which however broke the simple - constant matrix - structure of the global linear equation, while failing to treat contact in an implicit manner. In this paper we propose a simple yet effective method to integrate in a unified and semi-implicit way contact as well as dry frictional forces into the nested architecture of Projective dynamics. Assuming that contacts apply to nodes only, the key is to split the global matrix into a diagonal and a positive matrix, and use this splitting in the local step so as to make a good prediction of frictional contact forces at next iteration. Each frictional contact force is refined independently in the local step, while the original efficient structure of the global step is left unchanged. We apply our algorithm to cloth simulation and show that contact and dry friction can be captured at a reasonable precision within a few iterations only, hence one order of magnitude faster compared to global implicit contact solvers of the literature.",
        "countries": [
            "FR"
        ]
    },
    "10.1145/3592414": {
        "doi": "10.1145/3592414",
        "authors": [
            {
                "family": "Yu",
                "given": "Yunchen",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Xia",
                "given": "Mengqi",
                "countries": [
                    "CH"
                ]
            },
            {
                "family": "Walter",
                "given": "Bruce",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Michielssen",
                "given": "Eric",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Marschner",
                "given": "Steve",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "A Full-Wave Reference Simulator for Computing Surface Reflectance",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2023,
        "volume": "42",
        "number": "4",
        "pages": "109:1\u2013109:17",
        "article_number": "109",
        "number_of_pages": 17,
        "abstract": "Computing light reflection from rough surfaces is an important topic in computer graphics. Reflection models developed based on geometric optics fail to capture wave effects such as diffraction and interference, while existing models based on physical optics approximations give erroneous predictions under many circumstances (e.g. when multiple scattering from the surface cannot be ignored). We present a scalable 3D full-wave simulator for computing reference solutions to surface scattering problems, which can be used to evaluate and guide the development of approximate models for rendering. We investigate the range of validity for some existing wave optics based reflection models; our results confirm these models for low-roughness surfaces but also show that prior rendering methods do not accurately predict the scattering behavior of some types of surfaces.Our simulator is based on the boundary element method (BEM) and accelerated using the adaptive integral method (AIM), and is implemented to execute on modern GPUs. We demonstrate the simulator on domains up to 60 \u00d7 60 \u00d7 10 wavelengths, involving surface samples with significant height variations. Furthermore, we propose a new system for efficiently computing BRDF values for large numbers of incident and outgoing directions at once, by combining small simulations to characterize larger areas. Our simulator will be released as an open-source toolkit for computing surface scattering.",
        "countries": [
            "US",
            "CH"
        ]
    },
    "10.1145/3550454.3555460": {
        "doi": "10.1145/3550454.3555460",
        "authors": [
            {
                "family": "Cherchi",
                "given": "Gianmarco",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Pellacini",
                "given": "Fabio",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Attene",
                "given": "Marco",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Livesu",
                "given": "Marco",
                "countries": [
                    "IT"
                ]
            }
        ],
        "title": "Interactive and Robust Mesh Booleans",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2022,
        "volume": "41",
        "number": "6",
        "pages": "248:1\u2013248:14",
        "article_number": "248",
        "number_of_pages": 14,
        "abstract": "Boolean operations are among the most used paradigms to create and edit digital shapes. Despite being conceptually simple, the computation of mesh Booleans is notoriously challenging. Main issues come from numerical approximations that make the detection and processing of intersection points inconsistent and unreliable, exposing implementations based on floating point arithmetic to many kinds of degeneracy and failure. Numerical methods based on rational numbers or exact geometric predicates have the needed robustness guarantees, that are achieved at the cost of increased computation times that, as of today, has always restricted the use of robust mesh Booleans to offline applications. We introduce an algorithm for Boolean operations with robustness guarantees that is capable of operating at interactive frame rates on meshes with up to 200K triangles. We evaluate our tool thoroughly, considering not only interactive applications but also batch processing of large collections of meshes, processing of huge meshes containing millions of elements and variadic Booleans of hundreds of shapes altogether. In all these experiments, we consistently outperform prior robust floating point methods by at least one order of magnitude.",
        "countries": [
            "IT"
        ]
    },
    "10.1145/3592131": {
        "doi": "10.1145/3592131",
        "authors": [
            {
                "family": "Wang",
                "given": "Peng-Shuai",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "OctFormer: Octree-based Transformers for 3D Point Clouds",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2023,
        "volume": "42",
        "number": "4",
        "pages": "155:1\u2013155:11",
        "article_number": "155",
        "number_of_pages": 11,
        "abstract": "We propose octree-based transformers, named OctFormer, for 3D point cloud learning. OctFormer can not only serve as a general and effective backbone for 3D point cloud segmentation and object detection but also have linear complexity and is scalable for large-scale point clouds. The key challenge in applying transformers to point clouds is reducing the quadratic, thus overwhelming, computation complexity of attentions. To combat this issue, several works divide point clouds into non-overlapping windows and constrain attentions in each local window. However, the point number in each window varies greatly, impeding the efficient execution on GPU. Observing that attentions are robust to the shapes of local windows, we propose a novel octree attention, which leverages sorted shuffled keys of octrees to partition point clouds into local windows containing a fixed number of points while permitting shapes of windows to change freely. And we also introduce dilated octree attention to expand the receptive field further. Our octree attention can be implemented in 10 lines of code with open-sourced libraries and runs 17 times faster than other point cloud attentions when the point number exceeds 200k. Built upon the octree attention, OctFormer can be easily scaled up and achieves state-of-the-art performances on a series of 3D semantic segmentation and 3D object detection benchmarks, surpassing previous sparse-voxel-based CNNs and point cloud transformers in terms of both efficiency and effectiveness. Notably, on the challenging ScanNet200 dataset, OctFormer outperforms sparse-voxel-based CNNs by 7.3 in mIoU. Our code and trained models are available at https://wang-ps.github.io/octformer.",
        "countries": [
            "CN"
        ]
    },
    "10.1145/3592412": {
        "doi": "10.1145/3592412",
        "authors": [
            {
                "family": "Chermain",
                "given": "Xavier",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Zanni",
                "given": "C\u00e9dric",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Mart\u00ednez",
                "given": "Jon\u00e0s",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Hugron",
                "given": "Pierre-Alexandre",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Lefebvre",
                "given": "Sylvain",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Orientable Dense Cyclic Infill for Anisotropic Appearance Fabrication",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2023,
        "volume": "42",
        "number": "4",
        "pages": "68:1\u201368:13",
        "article_number": "68",
        "number_of_pages": 13,
        "abstract": "We present a method to 3D print surfaces exhibiting a prescribed varying field of anisotropic appearance using only standard fused filament fabrication printers. This enables the fabrication of patterns triggering reflections similar to that of brushed metal with direct control over the directionality of the reflections. Our key insight, on which we ground the method, is that the direction of the deposition paths leads to a certain degree of surface roughness, which yields a visual anisotropic appearance. Therefore, generating dense cyclic infills aligned with a line field allows us to grade the anisotropic appearance of the printed surface. To achieve this, we introduce a highly parallelizable algorithm for optimizing oriented, cyclic paths. Our algorithm outperforms existing approaches regarding efficiency, robustness, and result quality. We demonstrate the effectiveness of our technique in conveying an anisotropic appearance on several challenging test cases, ranging from patterns to photographs reinterpreted as anisotropic appearances.",
        "countries": [
            "FR"
        ]
    },
    "10.1145/3478513.3480564": {
        "doi": "10.1145/3478513.3480564",
        "authors": [
            {
                "family": "Diazzi",
                "given": "Lorenzo",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Attene",
                "given": "Marco",
                "countries": [
                    "IT"
                ]
            }
        ],
        "title": "Convex polyhedral meshing for robust solid modeling",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "6",
        "pages": "259:1\u2013259:16",
        "article_number": "259",
        "number_of_pages": 16,
        "abstract": "We introduce a new technique to create a mesh of convex polyhedra representing the interior volume of a triangulated input surface. Our approach is particularly tolerant to defects in the input, which is allowed to self-intersect, to be non-manifold, disconnected, and to contain surface holes and gaps. We guarantee that the input surface is exactly represented as the union of polygonal facets of the output volume mesh. Thanks to our algorithm, traditionally difficult solid modeling operations such as mesh booleans and Minkowski sums become surprisingly robust and easy to implement, even if the input has defects. Our technique leverages on the recent concept of indirect geometric predicate to provide an unprecedented combination of guaranteed robustness and speed, thus enabling the practical implementation of robust though flexible solid modeling systems. We have extensively tested our method on all the 10000 models of the Thingi10k dataset, and concluded that no existing method provides comparable robustness, precision and performances.",
        "countries": [
            "IT"
        ]
    },
    "10.1145/3450626.3459760": {
        "doi": "10.1145/3450626.3459760",
        "authors": [
            {
                "family": "Chen",
                "given": "Shu-Yu",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Liu",
                "given": "Feng-Lin",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Lai",
                "given": "Yu-Kun",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Rosin",
                "given": "Paul L.",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Li",
                "given": "Chunpeng",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Fu",
                "given": "Hongbo",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Gao",
                "given": "Lin",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "DeepFaceEditing: deep face generation and editing with disentangled geometry and appearance control",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "90:1\u201390:15",
        "article_number": "90",
        "number_of_pages": 15,
        "abstract": "Recent facial image synthesis methods have been mainly based on conditional generative models. Sketch-based conditions can effectively describe the geometry of faces, including the contours of facial components, hair structures, as well as salient edges (e.g., wrinkles) on face surfaces but lack effective control of appearance, which is influenced by color, material, lighting condition, etc. To have more control of generated results, one possible approach is to apply existing disentangling works to disentangle face images into geometry and appearance representations. However, existing disentangling methods are not optimized for human face editing, and cannot achieve fine control of facial details such as wrinkles. To address this issue, we propose DeepFaceEditing, a structured disentanglement framework specifically designed for face images to support face generation and editing with disentangled control of geometry and appearance. We adopt a local-to-global approach to incorporate the face domain knowledge: local component images are decomposed into geometry and appearance representations, which are fused consistently using a global fusion module to improve generation quality. We exploit sketches to assist in extracting a better geometry representation, which also supports intuitive geometry editing via sketching. The resulting method can either extract the geometry and appearance representations from face images, or directly extract the geometry representation from face sketches. Such representations allow users to easily edit and synthesize face images, with decoupled control of their geometry and appearance. Both qualitative and quantitative evaluations show the superior detail and appearance control abilities of our method compared to state-of-the-art methods.",
        "countries": [
            "CN",
            "GB"
        ]
    },
    "10.1145/3528223.3530102": {
        "doi": "10.1145/3528223.3530102",
        "authors": [
            {
                "family": "Padilla",
                "given": "Marcel",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Gross",
                "given": "Oliver",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Kn\u00f6ppel",
                "given": "Felix",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Chern",
                "given": "Albert",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Pinkall",
                "given": "Ulrich",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Schr\u00f6der",
                "given": "Peter",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Filament based plasma",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2022,
        "volume": "41",
        "number": "4",
        "pages": "153:1\u2013153:14",
        "article_number": "153",
        "number_of_pages": 14,
        "abstract": "Simulation of stellar atmospheres, such as that of our own sun, is a common task in CGI for scientific visualization, movies and games. A fibrous volumetric texture is a visually dominant feature of the solar corona---the plasma that extends from the solar surface into space. These coronal fibers can be modeled as magnetic filaments whose shape is governed by the magnetohydrostatic equation. The magnetic filaments provide a Lagrangian curve representation and their initial configuration can be prescribed by an artist or generated from magnetic flux given as a scalar texture on the sun's surface. Subsequently, the shape of the filaments is determined based on a variational formulation. The output is a visual rendering of the whole sun. We demonstrate the fidelity of our method by comparing the resulting renderings with actual images of our sun's corona.",
        "countries": [
            "DE",
            "US"
        ]
    },
    "10.1145/3528223.3530108": {
        "doi": "10.1145/3528223.3530108",
        "authors": [
            {
                "family": "Chen",
                "given": "Zhiqin",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Tagliasacchi",
                "given": "Andrea",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Funkhouser",
                "given": "Thomas",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Zhang",
                "given": "Hao",
                "countries": [
                    "CA"
                ]
            }
        ],
        "title": "Neural dual contouring",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2022,
        "volume": "41",
        "number": "4",
        "pages": "104:1\u2013104:13",
        "article_number": "104",
        "number_of_pages": 13,
        "abstract": "We introduce neural dual contouring (NDC), a new data-driven approach to mesh reconstruction based on dual contouring (DC). Like traditional DC, it produces exactly one vertex per grid cell and one quad for each grid edge intersection, a natural and efficient structure for reproducing sharp features. However, rather than computing vertex locations and edge crossings with hand-crafted functions that depend directly on difficult-to-obtain surface gradients, NDC uses a neural network to predict them. As a result, NDC can be trained to produce meshes from signed or unsigned distance fields, binary voxel grids, or point clouds (with or without normals); and it can produce open surfaces in cases where the input represents a sheet or partial surface. During experiments with five prominent datasets, we find that NDC, when trained on one of the datasets, generalizes well to the others. Furthermore, NDC provides better surface reconstruction accuracy, feature preservation, output complexity, triangle quality, and inference time in comparison to previous learned (e.g., neural marching cubes, convolutional occupancy networks) and traditional (e.g., Poisson) methods. Code and data are available at https://github.com/czq142857/NDC.",
        "countries": [
            "CA",
            "US"
        ]
    },
    "10.1145/3528223.3530176": {
        "doi": "10.1145/3528223.3530176",
        "authors": [
            {
                "family": "Du",
                "given": "Xingyi",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Zhou",
                "given": "Qingnan",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Carr",
                "given": "Nathan",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Ju",
                "given": "Tao",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Robust computation of implicit surface networks for piecewise linear functions",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2022,
        "volume": "41",
        "number": "4",
        "pages": "41:1\u201341:16",
        "article_number": "41",
        "number_of_pages": 16,
        "abstract": "Implicit surface networks, such as arrangements of implicit surfaces and materials interfaces, are used for modeling piecewise smooth or partitioned shapes. However, accurate and numerically robust algorithms for discretizing either structure on a grid are still lacking. We present a unified approach for computing both types of surface networks for piecewise linear functions defined on a tetrahedral grid. Both algorithms are guaranteed to produce a correct combinatorial structure for any number of functions. Our main contribution is an exact and efficient method for partitioning a tetrahedron using the level sets of linear functions defined by barycentric interpolation. To further improve performance, we designed look-up tables to speed up processing of tetrahedra involving few functions and introduced an efficient algorithm for identifying nested 3D regions.",
        "countries": [
            "US"
        ]
    },
    "10.1145/3528223.3530157": {
        "doi": "10.1145/3528223.3530157",
        "authors": [
            {
                "family": "Li",
                "given": "Peizhuo",
                "countries": [
                    "CH"
                ]
            },
            {
                "family": "Aberman",
                "given": "Kfir",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Zhang",
                "given": "Zihan",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Hanocka",
                "given": "Rana",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Sorkine-Hornung",
                "given": "Olga",
                "countries": [
                    "CH"
                ]
            }
        ],
        "title": "GANimator: neural motion synthesis from a single sequence",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2022,
        "volume": "41",
        "number": "4",
        "pages": "138:1\u2013138:12",
        "article_number": "138",
        "number_of_pages": 12,
        "abstract": "We present GANimator, a generative model that learns to synthesize novel motions from a single, short motion sequence. GANimator generates motions that resemble the core elements of the original motion, while simultaneously synthesizing novel and diverse movements. Existing data-driven techniques for motion synthesis require a large motion dataset which contains the desired and specific skeletal structure. By contrast, GANimator only requires training on a single motion sequence, enabling novel motion synthesis for a variety of skeletal structures e.g., bipeds, quadropeds, hexapeds, and more. Our framework contains a series of generative and adversarial neural networks, each responsible for generating motions in a specific frame rate. The framework progressively learns to synthesize motion from random noise, enabling hierarchical control over the generated motion content across varying levels of detail. We show a number of applications, including crowd simulation, key-frame editing, style transfer, and interactive control, which all learn from a single input sequence. Code and data for this paper are at https://peizhuoli.github.io/ganimator.",
        "countries": [
            "CH",
            "US"
        ]
    },
    "10.1145/3528223.3530083": {
        "doi": "10.1145/3528223.3530083",
        "authors": [
            {
                "family": "Ansari",
                "given": "Navid",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Seidel",
                "given": "Hans-Peter",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Babaei",
                "given": "Vahid",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Mixed integer neural inverse design",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2022,
        "volume": "41",
        "number": "4",
        "pages": "151:1\u2013151:14",
        "article_number": "151",
        "number_of_pages": 14,
        "abstract": "In computational design and fabrication, neural networks are becoming important surrogates for bulky forward simulations. A long-standing, intertwined question is that of inverse design: how to compute a design that satisfies a desired target performance? Here, we show that the piecewise linear property, very common in everyday neural networks, allows for an inverse design formulation based on mixed-integer linear programming. Our mixed-integer inverse design uncovers globally optimal or near optimal solutions in a principled manner. Furthermore, our method significantly facilitates emerging, but challenging, combinatorial inverse design tasks, such as material selection. For problems where finding the optimal solution is intractable, we develop an efficient yet near-optimal hybrid approach. Eventually, our method is able to find solutions provably robust to possible fabrication perturbations among multiple designs with similar performances. Our code and data are available at https://gitlab.mpi-klsb.mpg.de/nansari/mixed-integer-neural-inverse-design.",
        "countries": [
            "DE"
        ]
    },
    "10.1145/3528223.3530127": {
        "doi": "10.1145/3528223.3530127",
        "authors": [
            {
                "family": "M\u00fcller",
                "given": "Thomas",
                "countries": [
                    "CH"
                ]
            },
            {
                "family": "Evans",
                "given": "Alex",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Schied",
                "given": "Christoph",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Keller",
                "given": "Alexander",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Instant neural graphics primitives with a multiresolution hash encoding",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2022,
        "volume": "41",
        "number": "4",
        "pages": "102:1\u2013102:15",
        "article_number": "102",
        "number_of_pages": 15,
        "abstract": "Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate. We reduce this cost with a versatile new input encoding that permits the use of a smaller network without sacrificing quality, thus significantly reducing the number of floating point and memory access operations: a small neural network is augmented by a multiresolution hash table of trainable feature vectors whose values are optimized through stochastic gradient descent. The multiresolution structure allows the network to disambiguate hash collisions, making for a simple architecture that is trivial to parallelize on modern GPUs. We leverage this parallelism by implementing the whole system using fully-fused CUDA kernels with a focus on minimizing wasted bandwidth and compute operations. We achieve a combined speedup of several orders of magnitude, enabling training of high-quality neural graphics primitives in a matter of seconds, and rendering in tens of milliseconds at a resolution of 1920\u00d71080.",
        "countries": [
            "CH",
            "GB",
            "US",
            "DE"
        ]
    },
    "10.1145/3528223.3530109": {
        "doi": "10.1145/3528223.3530109",
        "authors": [
            {
                "family": "Shao",
                "given": "Han",
                "countries": [
                    "SA"
                ]
            },
            {
                "family": "Huang",
                "given": "Libo",
                "countries": [
                    "SA"
                ]
            },
            {
                "family": "Michels",
                "given": "Dominik L.",
                "countries": [
                    "SA"
                ]
            }
        ],
        "title": "A fast unsmoothed aggregation algebraic multigrid framework for the large-scale simulation of incompressible flow",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2022,
        "volume": "41",
        "number": "4",
        "pages": "49:1\u201349:18",
        "article_number": "49",
        "number_of_pages": 18,
        "abstract": "Multigrid methods are quite efficient for solving the pressure Poisson equation in simulations of incompressible flow. However, for viscous liquids, geometric multigrid turned out to be less efficient for solving the variational viscosity equation. In this contribution, we present an Unsmoothed Aggregation Algebraic MultiGrid (UAAMG) method with a multi-color Gauss-Seidel smoother, which consistently solves the variational viscosity equation in a few iterations for various material parameters. Moreover, we augment the OpenVDB data structure with Intel SIMD intrinsic functions to perform sparse matrix-vector multiplications efficiently on all multigrid levels. Our framework is 2.0 to 14.6 times faster compared to the state-of-the-art adaptive octree solver in commercial software for the large-scale simulation of both non-viscous and viscous flow. The code is available at http://computationalsciences.org/publications/shao-2022-multigrid.html.",
        "countries": [
            "SA"
        ]
    },
    "10.1145/3528223.3530115": {
        "doi": "10.1145/3528223.3530115",
        "authors": [
            {
                "family": "Mantiuk",
                "given": "Rafa\u0142 K.",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Ashraf",
                "given": "Maliha",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Chapiro",
                "given": "Alexandre",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "stelaCSF: a unified model of contrast sensitivity as the function of spatio-temporal frequency, eccentricity, luminance and area",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2022,
        "volume": "41",
        "number": "4",
        "pages": "145:1\u2013145:16",
        "article_number": "145",
        "number_of_pages": 16,
        "abstract": "A contrast sensitivity function, or CSF, is a cornerstone of many visual models. It explains whether a contrast pattern is visible to the human eye. The existing CSFs typically account for a subset of relevant dimensions describing a stimulus, limiting the use of such functions to either static or foveal content but not both. In this paper, we propose a unified CSF, stelaCSF, which accounts for all major dimensions of the stimulus: spatial and temporal frequency, eccentricity, luminance, and area. To model the 5-dimensional space of contrast sensitivity, we combined data from 11 papers, each of which studied a subset of this space. While previously proposed CSFs were fitted to a single dataset, stelaCSF can predict the data from all these studies using the same set of parameters. The predictions are accurate in the entire domain, including low frequencies. In addition, stelaCSF relies on psychophysical models and experimental evidence to explain the major interactions between the 5 dimensions of the CSF. We demonstrate the utility of our new CSF in a flicker detection metric and in foveated rendering.",
        "countries": [
            "GB",
            "US"
        ]
    },
    "10.1145/3528223.3530124": {
        "doi": "10.1145/3528223.3530124",
        "authors": [
            {
                "family": "Mercier-Aubin",
                "given": "Alexandre",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Kry",
                "given": "Paul G.",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Winter",
                "given": "Alexandre",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Levin",
                "given": "David I. W.",
                "countries": [
                    "CA"
                ]
            }
        ],
        "title": "Adaptive rigidification of elastic solids",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2022,
        "volume": "41",
        "number": "4",
        "pages": "71:1\u201371:11",
        "article_number": "71",
        "number_of_pages": 11,
        "abstract": "We present a method for reducing the computational cost of elastic solid simulation by treating connected sets of non-deforming elements as rigid bodies. Non-deforming elements are identified as those where the strain rate squared Frobenius norm falls below a threshold for several frames. Rigidification uses a breadth first search to identify connected components while avoiding connections that would form hinges between rigid components. Rigid elements become elastic again when their approximate strain velocity rises above a threshold, which is fast to compute using a single iteration of conjugate gradient with a fixed Laplacian-based incomplete Cholesky preconditioner. With rigidification, the system size to solve at each time step can be greatly reduced, and if all elastic element become rigid, it reduces to solving the rigid body system. We demonstrate our results on a variety of 2D and 3D examples, and show that our method is likewise especially beneficial in contact rich examples.",
        "countries": [
            "CA"
        ]
    },
    "10.1145/3528223.3530096": {
        "doi": "10.1145/3528223.3530096",
        "authors": [
            {
                "family": "Hou",
                "given": "Fei",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wang",
                "given": "Chiyu",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wang",
                "given": "Wencheng",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Qin",
                "given": "Hong",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Qian",
                "given": "Chen",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "He",
                "given": "Ying",
                "countries": [
                    "SG"
                ]
            }
        ],
        "title": "Iterative poisson surface reconstruction (iPSR) for unoriented points",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2022,
        "volume": "41",
        "number": "4",
        "pages": "128:1\u2013128:13",
        "article_number": "128",
        "number_of_pages": 13,
        "abstract": "Poisson surface reconstruction (PSR) remains a popular technique for reconstructing watertight surfaces from 3D point samples thanks to its efficiency, simplicity, and robustness. Yet, the existing PSR method and subsequent variants work only for oriented points. This paper intends to validate that an improved PSR, called iPSR, can completely eliminate the requirement of point normals and proceed in an iterative manner. In each iteration, iPSR takes as input point samples with normals directly computed from the surface obtained in the preceding iteration, and then generates a new surface with better quality. Extensive quantitative evaluation confirms that the new iPSR algorithm converges in 5--30 iterations even with randomly initialized normals. If initialized with a simple visibility based heuristic, iPSR can further reduce the number of iterations. We conduct comprehensive comparisons with PSR and other powerful implicit-function based methods. Finally, we confirm iPSR's effectiveness and scalability on the AIM@SHAPE dataset and challenging (indoor and outdoor) scenes. Code and data for this paper are at https://github.com/houfei0801/ipsr.",
        "countries": [
            "CN",
            "US",
            "SG"
        ]
    },
    "10.1145/3528223.3530068": {
        "doi": "10.1145/3528223.3530068",
        "authors": [
            {
                "family": "Vinker",
                "given": "Yael",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Pajouheshgar",
                "given": "Ehsan",
                "countries": [
                    "CH"
                ]
            },
            {
                "family": "Bo",
                "given": "Jessica Y.",
                "countries": [
                    "CH"
                ]
            },
            {
                "family": "Bachmann",
                "given": "Roman Christian",
                "countries": [
                    "CH"
                ]
            },
            {
                "family": "Bermano",
                "given": "Amit Haim",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Cohen-Or",
                "given": "Daniel",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Zamir",
                "given": "Amir",
                "countries": [
                    "CH"
                ]
            },
            {
                "family": "Shamir",
                "given": "Ariel",
                "countries": [
                    "IL"
                ]
            }
        ],
        "title": "CLIPasso: semantically-aware object sketching",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2022,
        "volume": "41",
        "number": "4",
        "pages": "86:1\u201386:11",
        "article_number": "86",
        "number_of_pages": 11,
        "abstract": "Abstraction is at the heart of sketching due to the simple and minimal nature of line drawings. Abstraction entails identifying the essential visual properties of an object or scene, which requires semantic understanding and prior knowledge of high-level concepts. Abstract depictions are therefore challenging for artists, and even more so for machines. We present CLIPasso, an object sketching method that can achieve different levels of abstraction, guided by geometric and semantic simplifications. While sketch generation methods often rely on explicit sketch datasets for training, we utilize the remarkable ability of CLIP (Contrastive-Language-Image-Pretraining) to distill semantic concepts from sketches and images alike. We define a sketch as a set of B\u00e9zier curves and use a differentiable rasterizer to optimize the parameters of the curves directly with respect to a CLIP-based perceptual loss. The abstraction degree is controlled by varying the number of strokes. The generated sketches demonstrate multiple levels of abstraction while maintaining recognizability, underlying structure, and essential visual components of the subject drawn.",
        "countries": [
            "IL",
            "CH"
        ]
    },
    "10.1145/3528223.3530166": {
        "doi": "10.1145/3528223.3530166",
        "authors": [
            {
                "family": "Wiersma",
                "given": "Ruben",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Nasikun",
                "given": "Ahmad",
                "countries": [
                    "NL",
                    "ID"
                ]
            },
            {
                "family": "Eisemann",
                "given": "Elmar",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Hildebrandt",
                "given": "Klaus",
                "countries": [
                    "NL"
                ]
            }
        ],
        "title": "DeltaConv: anisotropic operators for geometric deep learning on point clouds",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2022,
        "volume": "41",
        "number": "4",
        "pages": "105:1\u2013105:10",
        "article_number": "105",
        "number_of_pages": 10,
        "abstract": "Learning from 3D point-cloud data has rapidly gained momentum, motivated by the success of deep learning on images and the increased availability of 3D data. In this paper, we aim to construct anisotropic convolution layers that work directly on the surface derived from a point cloud. This is challenging because of the lack of a global coordinate system for tangential directions on surfaces. We introduce DeltaConv, a convolution layer that combines geometric operators from vector calculus to enable the construction of anisotropic filters on point clouds. Because these operators are defined on scalar- and vector-fields, we separate the network into a scalar- and a vector-stream, which are connected by the operators. The vector stream enables the network to explicitly represent, evaluate, and process directional information. Our convolutions are robust and simple to implement and match or improve on state-of-the-art approaches on several benchmarks, while also speeding up training and inference.",
        "countries": [
            "NL",
            "ID"
        ]
    },
    "10.1145/3342765": {
        "doi": "10.1145/3342765",
        "authors": [
            {
                "family": "Paris",
                "given": "Axel",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Galin",
                "given": "Eric",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Peytavie",
                "given": "Adrien",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Gu\u00e9rin",
                "given": "Eric",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Gain",
                "given": "James",
                "countries": [
                    "ZA"
                ]
            }
        ],
        "title": "Terrain Amplification with Implicit 3D Features",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2019,
        "volume": "38",
        "number": "5",
        "pages": "147:1\u2013147:15",
        "article_number": "147",
        "number_of_pages": 15,
        "abstract": "While three-dimensional landforms, such as arches and overhangs, occupy a relatively small proportion of most computer-generated landscapes, they are distinctive and dramatic and have an outsize visual impact. Unfortunately, the dominant heightfield representation of terrain precludes such features, and existing in-memory volumetric structures are too memory intensive to handle larger scenes.In this article, we present a novel memory-optimized paradigm for representing and generating volumetric terrain based on implicit surfaces. We encode feature shapes and terrain geology using construction trees that arrange and combine implicit primitives. The landform primitives themselves are positioned using Poisson sampling, built using open shape grammars guided by stratified erosion and invasion percolation processes, and, finally, queried during polygonization. Users can also interactively author landforms using high-level modeling tools to create or edit the underlying construction trees, with support for iterative cycles of editing and simulation.We demonstrate that our framework is capable of importing existing large-scale heightfield terrains and amplifying them with such diverse structures as slot canyons, sea arches, stratified cliffs, fields of hoodoos, and complex karst cave networks.",
        "countries": [
            "FR",
            "ZA"
        ]
    },
    "10.1145/3490168": {
        "doi": "10.1145/3490168",
        "authors": [
            {
                "family": "Du",
                "given": "Tao",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Wu",
                "given": "Kui",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Ma",
                "given": "Pingchuan",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Wah",
                "given": "Sebastien",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Spielberg",
                "given": "Andrew",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Rus",
                "given": "Daniela",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Matusik",
                "given": "Wojciech",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "DiffPD: Differentiable Projective Dynamics",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2022,
        "volume": "41",
        "number": "2",
        "pages": "13:1\u201313:21",
        "article_number": "13",
        "number_of_pages": 21,
        "abstract": "We present a novel, fast differentiable simulator for soft-body learning and control applications. Existing differentiable soft-body simulators can be classified into two categories based on their time integration methods: Simulators using explicit timestepping schemes require tiny timesteps to avoid numerical instabilities in gradient computation, and simulators using implicit time integration typically compute gradients by employing the adjoint method and solving the expensive linearized dynamics. Inspired by Projective Dynamics (PD), we present Differentiable Projective Dynamics (DiffPD), an efficient differentiable soft-body simulator based on PD with implicit time integration. The key idea in DiffPD is to speed up backpropagation by exploiting the prefactorized Cholesky decomposition in forward PD simulation. In terms of contact handling, DiffPD supports two types of contacts: a penalty-based model describing contact and friction forces and a complementarity-based model enforcing non-penetration conditions and static friction. We evaluate the performance of DiffPD and observe it is 4\u201319 times faster compared with the standard Newton\u2019s method in various applications including system identification, inverse design problems, trajectory optimization, and closed-loop control. We also apply DiffPD in a reality-to-simulation (real-to-sim) example with contact and collisions and show its capability of reconstructing a digital twin of real-world scenes.",
        "countries": [
            "US"
        ]
    },
    "10.1145/3450626.3459819": {
        "doi": "10.1145/3450626.3459819",
        "authors": [
            {
                "family": "Wang",
                "given": "Zeyu",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Qiu",
                "given": "Sherry",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Feng",
                "given": "Nicole",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Rushmeier",
                "given": "Holly",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "McMillan",
                "given": "Leonard",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Dorsey",
                "given": "Julie",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Tracing versus freehand for evaluating computer-generated drawings",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "52:1\u201352:12",
        "article_number": "52",
        "number_of_pages": 12,
        "abstract": "Non-photorealistic rendering (NPR) and image processing algorithms are widely assumed as a proxy for drawing. However, this assumption is not well assessed due to the difficulty in collecting and registering freehand drawings. Alternatively, tracings are easier to collect and register, but there is no quantitative evaluation of tracing as a proxy for freehand drawing. In this paper, we compare tracing, freehand drawing, and computer-generated drawing approximation (CGDA) to understand their similarities and differences. We collected a dataset of 1,498 tracings and freehand drawings by 110 participants for 100 image prompts. Our drawings are registered to the prompts and include vector-based timestamped strokes collected via stylus input. Comparing tracing and freehand drawing, we found a high degree of similarity in stroke placement and types of strokes used over time. We show that tracing can serve as a viable proxy for freehand drawing because of similar correlations between spatio-temporal stroke features and labeled stroke types. Comparing hand-drawn content and current CGDA output, we found that 60% of drawn pixels corresponded to computer-generated pixels on average. The overlap tended to be commonly drawn content, but people's artistic choices and temporal tendencies remained largely uncaptured. We present an initial analysis to inform new CGDA algorithms and drawing applications, and provide the dataset for use by the community.",
        "countries": [
            "US"
        ]
    },
    "10.1145/3450626.3459840": {
        "doi": "10.1145/3450626.3459840",
        "authors": [
            {
                "family": "Jiang",
                "given": "Zhongshi",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Zhang",
                "given": "Ziyi",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Hu",
                "given": "Yixin",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Schneider",
                "given": "Teseo",
                "countries": [
                    "US",
                    "CA"
                ]
            },
            {
                "family": "Zorin",
                "given": "Denis",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Panozzo",
                "given": "Daniele",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Bijective and coarse high-order tetrahedral meshes",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "157:1\u2013157:16",
        "article_number": "157",
        "number_of_pages": 16,
        "abstract": "We introduce a robust and automatic algorithm to convert linear triangle meshes with feature annotated into coarse tetrahedral meshes with curved elements. Our construction guarantees that the high-order meshes are free of element inversion or self-intersection. A user-specified maximal geometrical error from the input mesh controls the faithfulness of the curved approximation. The boundary of the output mesh is in bijective correspondence to the input, enabling attribute transfer between them, such as boundary conditions for simulations, making our curved mesh an ideal replacement or complement for the original input geometry.The availability of a bijective shell around the input surface is employed to ensure robust curving, prevent self-intersections, and compute a bijective map between the linear input and curved output surface. As necessary building blocks of our algorithm, we extend the bijective shell formulation to support features and propose a robust approach for boundary-preserving linear tetrahedral meshing.We demonstrate the robustness and effectiveness of our algorithm by generating high-order meshes for a large collection of complex 3D models.",
        "countries": [
            "US",
            "CA"
        ]
    },
    "10.1145/3450626.3459778": {
        "doi": "10.1145/3450626.3459778",
        "authors": [
            {
                "family": "Qu",
                "given": "Ante",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "James",
                "given": "Doug L.",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Fast linking numbers for topology verification of loopy structures",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "106:1\u2013106:19",
        "article_number": "106",
        "number_of_pages": 19,
        "abstract": "It is increasingly common to model, simulate, and process complex materials based on loopy structures, such as in yarn-level cloth garments, which possess topological constraints between inter-looping curves. While the input model may satisfy specific topological linkages between pairs of closed loops, subsequent processing may violate those topological conditions. In this paper, we explore a family of methods for efficiently computing and verifying linking numbers between closed curves, and apply these to applications in geometry processing, animation, and simulation, so as to verify that topological invariants are preserved during and after processing of the input models. Our method has three stages: (1) we identify potentially interacting loop-loop pairs, then (2) carefully discretize each loop's spline curves into line segments so as to enable (3) efficient linking number evaluation using accelerated kernels based on either counting projected segment-segment crossings, or by evaluating the Gauss linking integral using direct or fast summation methods (Barnes-Hut or fast multipole methods). We evaluate CPU and GPU implementations of these methods on a suite of test problems, including yarn-level cloth and chainmail, that involve significant processing: physics-based relaxation and animation, user-modeled deformations, curve compression and reparameterization. We show that topology errors can be efficiently identified to enable more robust processing of loopy structures.",
        "countries": [
            "US"
        ]
    },
    "10.1145/3450626.3459800": {
        "doi": "10.1145/3450626.3459800",
        "authors": [
            {
                "family": "Hafner",
                "given": "Christian",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Bickel",
                "given": "Bernd",
                "countries": [
                    "AT"
                ]
            }
        ],
        "title": "The design space of plane elastic curves",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "126:1\u2013126:20",
        "article_number": "126",
        "number_of_pages": 20,
        "abstract": "Elastic bending of initially flat slender elements allows the realization and economic fabrication of intriguing curved shapes. In this work, we derive an intuitive but rigorous geometric characterization of the design space of plane elastic rods with variable stiffness. It enables designers to determine which shapes are physically viable with active bending by visual inspection alone. Building on these insights, we propose a method for efficiently designing the geometry of a flat elastic rod that realizes a target equilibrium curve, which only requires solving a linear program.We implement this method in an interactive computational design tool that gives feedback about the feasibility of a design, and computes the geometry of the structural elements necessary to realize it within an instant. The tool also offers an iterative optimization routine that improves the fabricability of a model while modifying it as little as possible. In addition, we use our geometric characterization to derive an algorithm for analyzing and recovering the stability of elastic curves that would otherwise snap out of their unstable equilibrium shapes by buckling. We show the efficacy of our approach by designing and manufacturing several physical models that are assembled from flat elements.",
        "countries": [
            "AT"
        ]
    },
    "10.1145/3450626.3459748": {
        "doi": "10.1145/3450626.3459748",
        "authors": [
            {
                "family": "Mahmoud",
                "given": "Ahmed H.",
                "countries": [
                    "US",
                    "CA"
                ]
            },
            {
                "family": "Porumbescu",
                "given": "Serban D.",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Owens",
                "given": "John D.",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "RXMesh: a GPU mesh data structure",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "104:1\u2013104:16",
        "article_number": "104",
        "number_of_pages": 16,
        "abstract": "We propose a new static high-performance mesh data structure for triangle surface meshes on the GPU. Our data structure is carefully designed for parallel execution while capturing mesh locality and confining data access, as much as possible, within the GPU's fast \"shared memory.\" We achieve this by subdividing the mesh into patches and representing these patches compactly using a matrix-based representation. Our patching technique is decorated with ribbons, thin mesh strips around patches that eliminate the need to communicate between different computation thread blocks, resulting in consistent high throughput. We call our data structure RXMesh: Ribbon-matriX Mesh. We hide the complexity of our data structure behind a flexible but powerful programming model that helps deliver high performance by inducing load balance even in highly irregular input meshes. We show the efficacy of our programming model on common geometry processing applications---mesh smoothing and filtering, geodesic distance, and vertex normal computation. For evaluation, we benchmark our data structure against well-optimized GPU and (single and multi-core) CPU data structures and show significant speedups.",
        "countries": [
            "US",
            "CA"
        ]
    },
    "10.1145/3450626.3459786": {
        "doi": "10.1145/3450626.3459786",
        "authors": [
            {
                "family": "Yi",
                "given": "Xinyu",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhou",
                "given": "Yuxiao",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Xu",
                "given": "Feng",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "TransPose: real-time 3D human translation and pose estimation with six inertial sensors",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "86:1\u201386:13",
        "article_number": "86",
        "number_of_pages": 13,
        "abstract": "Motion capture is facing some new possibilities brought by the inertial sensing technologies which do not suffer from occlusion or wide-range recordings as vision-based solutions do. However, as the recorded signals are sparse and quite noisy, online performance and global translation estimation turn out to be two key difficulties. In this paper, we present TransPose, a DNN-based approach to perform full motion capture (with both global translations and body poses) from only 6 Inertial Measurement Units (IMUs) at over 90 fps. For body pose estimation, we propose a multi-stage network that estimates leaf-to-full joint positions as intermediate results. This design makes the pose estimation much easier, and thus achieves both better accuracy and lower computation cost. For global translation estimation, we propose a supporting-foot-based method and an RNN-based method to robustly solve for the global translations with a confidence-based fusion technique. Quantitative and qualitative comparisons show that our method outperforms the state-of-the-art learning- and optimization-based methods with a large margin in both accuracy and efficiency. As a purely inertial sensor-based approach, our method is not limited by environmental settings (e.g., fixed cameras), making the capture free from common difficulties such as wide-range motion space and strong occlusion.",
        "countries": [
            "CN"
        ]
    },
    "10.1145/3450626.3459805": {
        "doi": "10.1145/3450626.3459805",
        "authors": [
            {
                "family": "Alaluf",
                "given": "Yuval",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Patashnik",
                "given": "Or",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Cohen-Or",
                "given": "Daniel",
                "countries": [
                    "IL"
                ]
            }
        ],
        "title": "Only a matter of style: age transformation using a style-based regression model",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "45:1\u201345:12",
        "article_number": "45",
        "number_of_pages": 12,
        "abstract": "The task of age transformation illustrates the change of an individual's appearance over time. Accurately modeling this complex transformation over an input facial image is extremely challenging as it requires making convincing, possibly large changes to facial features and head shape, while still preserving the input identity. In this work, we present an image-to-image translation method that learns to directly encode real facial images into the latent space of a pre-trained unconditional GAN (e.g., StyleGAN) subject to a given aging shift. We employ a pre-trained age regression network to explicitly guide the encoder in generating the latent codes corresponding to the desired age. In this formulation, our method approaches the continuous aging process as a regression task between the input age and desired target age, providing fine-grained control over the generated image. Moreover, unlike approaches that operate solely in the latent space using a prior on the path controlling age, our method learns a more disentangled, non-linear path. Finally, we demonstrate that the end-to-end nature of our approach, coupled with the rich semantic latent space of StyleGAN, allows for further editing of the generated images. Qualitative and quantitative evaluations show the advantages of our method compared to state-of-the-art approaches. Code is available at our project page: https://yuval-alaluf.github.io/SAM.",
        "countries": [
            "IL"
        ]
    },
    "10.1145/3450626.3459859": {
        "doi": "10.1145/3450626.3459859",
        "authors": [
            {
                "family": "Randrianandrasana",
                "given": "Jo\u00ebl",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Callet",
                "given": "Patrick",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Lucas",
                "given": "Laurent",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Transfer matrix based layered materials rendering",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "177:1\u2013177:16",
        "article_number": "177",
        "number_of_pages": 16,
        "abstract": "A statistical multi-lobe approach was recently introduced in order to efficiently handle layered materials rendering as an alternative to expensive general-purpose approaches. However, this approach poorly supports scattering volumes as the method does not account for back-scattering and resorts to single scattering approximations. In this paper, we address these limitations with an efficient solution based upon a transfer matrix approach which leverages the properties of the Henyey-Greenstein phase function. Under this formalism, each scattering component of the stack is described through a lightweight matrix, layering operations are reduced to simple matrix products and the statistics of each BSDF lobe accounting for multiple scattering effects are obtained through matrix operators. Based on this representation, we leverage the versatility of the transfer matrix approach to efficiently handle forward and backward scattering which occurs in arbitrary layered materials. The resulting model enables the reproduction of a wide range of layered structures embedding scattering volumes of arbitrary depth, in constant computation time and with low variance.",
        "countries": [
            "FR"
        ]
    },
    "10.1145/3450626.3459676": {
        "doi": "10.1145/3450626.3459676",
        "authors": [
            {
                "family": "Zhang",
                "given": "Jiazhao",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhu",
                "given": "Chenyang",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zheng",
                "given": "Lintao",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Xu",
                "given": "Kai",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "ROSEFusion: random optimization for online dense reconstruction under fast camera motion",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "56:1\u201356:17",
        "article_number": "56",
        "number_of_pages": 17,
        "abstract": "Online reconstruction based on RGB-D sequences has thus far been restrained to relatively slow camera motions (&lt;1m/s). Under very fast camera motion (e.g., 3m/s), the reconstruction can easily crumble even for the state-of-the-art methods. Fast motion brings two challenges to depth fusion: 1) the high nonlinearity of camera pose optimization due to large inter-frame rotations and 2) the lack of reliably trackable features due to motion blur. We propose to tackle the difficulties of fast-motion camera tracking in the absence of inertial measurements using random optimization, in particular, the Particle Filter Optimization (PFO). To surmount the computation-intensive particle sampling and update in standard PFO, we propose to accelerate the randomized search via updating a particle swarm template (PST). PST is a set of particles pre-sampled uniformly within the unit sphere in the 6D space of camera pose. Through moving and rescaling the pre-sampled PST guided by swarm intelligence, our method is able to drive tens of thousands of particles to locate and cover a good local optimum extremely fast and robustly. The particles, representing candidate poses, are evaluated with a fitness function defined based on depth-model conformance. Therefore, our method, being depth-only and correspondence-free, mitigates the motion blur impediment as (ToF-based) depths are often resilient to motion blur. Thanks to the efficient template-based particle set evolution and the effective fitness function, our method attains good quality pose tracking under fast camera motion (up to 4m/s) in a realtime framerate without including loop closure or global pose optimization. Through extensive evaluations on public datasets of RGB-D sequences, especially on a newly proposed benchmark of fast camera motion, we demonstrate the significant advantage of our method over the state of the arts.",
        "countries": [
            "CN"
        ]
    },
    "10.1145/3450626.3459794": {
        "doi": "10.1145/3450626.3459794",
        "authors": [
            {
                "family": "Liao",
                "given": "Wentao",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Chen",
                "given": "Renjie",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Hua",
                "given": "Yuchen",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Liu",
                "given": "Ligang",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Weber",
                "given": "Ofir",
                "countries": [
                    "IL"
                ]
            }
        ],
        "title": "Real-time locally injective volumetric deformation",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "74:1\u201374:16",
        "article_number": "74",
        "number_of_pages": 16,
        "abstract": "We present a highly efficient method for interactive volumetric meshless shape deformation. Our method operates within a low dimensional sub-space of shape-aware C\u221e harmonic maps, and is the first method that is guaranteed to produce a smooth locally injective deformation in 3D. Unlike mesh-based methods in which local injectivity is enforced on tetrahedral elements, our method enforces injectivity on a sparse set of domain samples. The main difficulty is then to certify the map as locally injective throughout the entire domain. This is done by utilizing the Lipschitz continuity property of the harmonic basis functions. We show a surprising relation between the Lipschitz constant of the smallest singular value of the map Jacobian and the norm of the Hessian. We further carefully derive a Lipschitz constant for the Hessian, and develop a sufficient condition for the injectivity certification. This is done by utilizing the special structure of the harmonic basis functions combined with a novel regularization term that pushes the Lipschitz constants further down. As a result, the injectivity analysis can be performed on a relatively sparse set of samples. Combined with a parallel GPU-based implementation, our method can produce superior deformations with unique quality guarantees at real-time rates which were possible only in 2D so far.",
        "countries": [
            "CN",
            "IL"
        ]
    },
    "10.1145/3450626.3459831": {
        "doi": "10.1145/3450626.3459831",
        "authors": [
            {
                "family": "Mantiuk",
                "given": "Rafa\u0142 K.",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Denes",
                "given": "Gyorgy",
                "countries": [
                    "US",
                    "GB"
                ]
            },
            {
                "family": "Chapiro",
                "given": "Alexandre",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Kaplanyan",
                "given": "Anton",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Rufo",
                "given": "Gizem",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Bachy",
                "given": "Romain",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Lian",
                "given": "Trisha",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Patney",
                "given": "Anjul",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "FovVideoVDP: a visible difference predictor for wide field-of-view video",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "49:1\u201349:19",
        "article_number": "49",
        "number_of_pages": 19,
        "abstract": "FovVideoVDP is a video difference metric that models the spatial, temporal, and peripheral aspects of perception. While many other metrics are available, our work provides the first practical treatment of these three central aspects of vision simultaneously. The complex interplay between spatial and temporal sensitivity across retinal locations is especially important for displays that cover a large field-of-view, such as Virtual and Augmented Reality displays, and associated methods, such as foveated rendering. Our metric is derived from psychophysical studies of the early visual system, which model spatio-temporal contrast sensitivity, cortical magnification and contrast masking. It accounts for physical specification of the display (luminance, size, resolution) and viewing distance. To validate the metric, we collected a novel foveated rendering dataset which captures quality degradation due to sampling and reconstruction. To demonstrate our algorithm's generality, we test it on 3 independent foveated video datasets, and on a large image quality dataset, achieving the best performance across all datasets when compared to the state-of-the-art.",
        "countries": [
            "GB",
            "US"
        ]
    },
    "10.1145/3450626.3459952": {
        "doi": "10.1145/3450626.3459952",
        "authors": [
            {
                "family": "Ecormier-Nocca",
                "given": "Pierre",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Cordonnier",
                "given": "Guillaume",
                "countries": [
                    "CH",
                    "FR"
                ]
            },
            {
                "family": "Carrez",
                "given": "Philippe",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Moigne",
                "given": "Anne-Marie",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Memari",
                "given": "Pooran",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Benes",
                "given": "Bedrich",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Cani",
                "given": "Marie-Paule",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Authoring consistent landscapes with flora and fauna",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "105:1\u2013105:13",
        "article_number": "105",
        "number_of_pages": 13,
        "abstract": "We present a novel method for authoring landscapes with flora and fauna while considering their mutual interactions. Our algorithm outputs a steady-state ecosystem in the form of density maps for each species, their daily circuits, and a modified terrain with eroded trails from a terrain, climatic conditions, and species with related biological information. We introduce the Resource Access Graph, a new data structure that encodes both interactions between food chain levels and animals traveling between resources over the terrain. A novel competition algorithm operating on this data progressively computes a steady-state solution up the food chain, from plants to carnivores. The user can explore the resulting landscape, where plants and animals are instantiated on the fly, and interactively edit it by over-painting the maps. Our results show that our system enables the authoring of consistent landscapes where the impact of wildlife is visible through animated animals, clearings in the vegetation, and eroded trails. We provide quantitative validation with existing ecosystems and a user-study with expert paleontologist end-users, showing that our system enables them to author and compare different ecosystems illustrating climate changes over the same terrain while enabling relevant visual immersion into consistent landscapes.",
        "countries": [
            "FR",
            "CH",
            "US"
        ]
    },
    "10.1145/3450626.3459852": {
        "doi": "10.1145/3450626.3459852",
        "authors": [
            {
                "family": "Li",
                "given": "Peizhuo",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Aberman",
                "given": "Kfir",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Hanocka",
                "given": "Rana",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Liu",
                "given": "Libin",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Sorkine-Hornung",
                "given": "Olga",
                "countries": [
                    "CH",
                    "CN"
                ]
            },
            {
                "family": "Chen",
                "given": "Baoquan",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Learning skeletal articulations with neural blend shapes",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "130:1\u2013130:15",
        "article_number": "130",
        "number_of_pages": 15,
        "abstract": "Animating a newly designed character using motion capture (mocap) data is a long standing problem in computer animation. A key consideration is the skeletal structure that should correspond to the available mocap data, and the shape deformation in the joint regions, which often requires a tailored, pose-specific refinement. In this work, we develop a neural technique for articulating 3D characters using enveloping with a pre-defined skeletal structure which produces high quality pose dependent deformations. Our framework learns to rig and skin characters with the same articulation structure (e.g., bipeds or quadrupeds), and builds the desired skeleton hierarchy into the network architecture. Furthermore, we propose neural blend shapes - a set of corrective pose-dependent shapes which improve the deformation quality in the joint regions in order to address the notorious artifacts resulting from standard rigging and skinning. Our system estimates neural blend shapes for input meshes with arbitrary connectivity, as well as weighting coefficients which are conditioned on the input joint rotations. Unlike recent deep learning techniques which supervise the network with ground-truth rigging and skinning parameters, our approach does not assume that the training data has a specific underlying deformation model. Instead, during training, the network observes deformed shapes and learns to infer the corresponding rig, skin and blend shapes using indirect supervision. During inference, we demonstrate that our network generalizes to unseen characters with arbitrary mesh connectivity, including unrigged characters built by 3D artists. Conforming to standard skeletal animation models enables direct plug-and-play in standard animation software, as well as game engines.",
        "countries": [
            "CN",
            "US",
            "IL",
            "CH"
        ]
    },
    "10.1145/3450626.3459776": {
        "doi": "10.1145/3450626.3459776",
        "authors": [
            {
                "family": "Kim",
                "given": "Suzi",
                "countries": [
                    "KR"
                ]
            },
            {
                "family": "Choi",
                "given": "Sunghee",
                "countries": [
                    "KR"
                ]
            }
        ],
        "title": "Dynamic closest color warping to sort and compare palettes",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "95:1\u201395:15",
        "article_number": "95",
        "number_of_pages": 15,
        "abstract": "A color palette is one of the simplest and most intuitive descriptors that can be extracted from images or videos. This paper proposes a method to assess the similarity between color palettes by sorting colors. While previous palette similarity measures compare only colors without considering the overall palette combination, we sort palettes to minimize the geometric distance between colors and align them to share a common color tendency. We propose dynamic closest color warping (DCCW) to calculate the minimum distance sum between colors and the graph connecting the colors in the other palette. We evaluate the proposed palette sorting and DCCW with several datasets and demonstrate that DCCW outperforms previous methods in terms of accuracy and computing time. We validate the effectiveness of the proposed sorting technique by conducting a perceptual study, which indicates a clear preference for the results of our approach. We also demonstrate useful applications enabled by DCCW, including palette interpolation, palette navigation, and image recoloring.",
        "countries": [
            "KR"
        ]
    },
    "10.1145/3450626.3459851": {
        "doi": "10.1145/3450626.3459851",
        "authors": [
            {
                "family": "Chen",
                "given": "Jiong",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Sch\u00e4fer",
                "given": "Florian",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Huang",
                "given": "Jin",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Desbrun",
                "given": "Mathieu",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Multiscale Cholesky preconditioning for ill-conditioned problems",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "81:1\u201381:13",
        "article_number": "81",
        "number_of_pages": 13,
        "abstract": "Many computer graphics applications boil down to solving sparse systems of linear equations. While the current arsenal of numerical solvers available in various specialized libraries and for different computer architectures often allow efficient and scalable solutions to image processing, modeling and simulation applications, an increasing number of graphics problems face large-scale and ill-conditioned sparse linear systems --- a numerical challenge which typically chokes both direct factorizations (due to high memory requirements) and iterative solvers (because of slow convergence). We propose a novel approach to the efficient preconditioning of such problems which often emerge from the discretization over unstructured meshes of partial differential equations with heterogeneous and anisotropic coefficients. Our numerical approach consists in simply performing a fine-to-coarse ordering and a multiscale sparsity pattern of the degrees of freedom, using which we apply an incomplete Cholesky factorization. By further leveraging supernodes for cache coherence, graph coloring to improve parallelism and partial diagonal shifting to remedy negative pivots, we obtain a preconditioner which, combined with a conjugate gradient solver, far exceeds the performance of existing carefully-engineered libraries for graphics problems involving bad mesh elements and/or high contrast of coefficients. We also back the core concepts behind our simple solver with theoretical foundations linking the recent method of operator-adapted wavelets used in numerical homogenization to the traditional Cholesky factorization of a matrix, providing us with a clear bridge between incomplete Cholesky factorization and multiscale analysis that we leverage numerically.",
        "countries": [
            "CN",
            "US"
        ]
    },
    "10.1145/3450626.3459823": {
        "doi": "10.1145/3450626.3459823",
        "authors": [
            {
                "family": "Michel",
                "given": "\u00c9lie",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Boubekeur",
                "given": "Tamy",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "DAG amendment for inverse control of parametric shapes",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "173:1\u2013173:14",
        "article_number": "173",
        "number_of_pages": 14,
        "abstract": "Parametric shapes model objects as programs producing a geometry based on a few semantic degrees of freedom, called hyper-parameters. These shapes are the typical output of non-destructive modeling, CAD modeling or rigging. However they suffer from the core issue of being manipulated only indirectly, through a series of values rather than the geometry itself. In this paper, we introduce an amendment process of the underlying direct acyclic graph (DAG) of a parametric shape. This amendment enables a local differentiation of the shape w.r.t. its hyper-parameters that we leverage to provide interactive direct manipulation of the output. By acting on the shape synthesis process itself, our method is agnostic to the variations of the connectivity and topology that may occur in its output while changing the input hyper-parameters. Furthermore, our method is oblivious to the internal logic of the DAG nodes. We illustrate our approach on a collection of examples combining the typical nodes found in modern parametric modeling packages - such as deformation, booleans and surfacing operators - for which our method provides the user with inverse control over the hyper-parameters through a brush stroke metaphor.",
        "countries": [
            "FR"
        ]
    },
    "10.1145/3450626.3459770": {
        "doi": "10.1145/3450626.3459770",
        "authors": [
            {
                "family": "Pluta",
                "given": "Kacper",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Edelstein",
                "given": "Michal",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Vaxman",
                "given": "Amir",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Ben-Chen",
                "given": "Mirela",
                "countries": [
                    "IL"
                ]
            }
        ],
        "title": "PH-CPF: planar hexagonal meshing using coordinate power fields",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "156:1\u2013156:19",
        "article_number": "156",
        "number_of_pages": 19,
        "abstract": "We present a new approach for computing planar hexagonal meshes that approximate a given surface, represented as a triangle mesh. Our method is based on two novel technical contributions. First, we introduce Coordinate Power Fields, which are a pair of tangent vector fields on the surface that fulfill a certain continuity constraint. We prove that the fulfillment of this constraint guarantees the existence of a seamless parameterization with quantized rotational jumps, which we then use to regularly remesh the surface. We additionally propose an optimization framework for finding Coordinate Power Fields, which also fulfill additional constraints, such as alignment, sizing and bijectivity. Second, we build upon this framework to address a challenging meshing problem: planar hexagonal meshing. To this end, we suggest a combination of conjugacy, scaling and alignment constraints, which together lead to planarizable hexagons. We demonstrate our approach on a variety of surfaces, automatically generating planar hexagonal meshes on complicated meshes, which were not achievable with existing methods.",
        "countries": [
            "IL",
            "NL"
        ]
    },
    "10.1145/3450626.3459816": {
        "doi": "10.1145/3450626.3459816",
        "authors": [
            {
                "family": "Sperl",
                "given": "Georg",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Narain",
                "given": "Rahul",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Wojtan",
                "given": "Chris",
                "countries": [
                    "AT"
                ]
            }
        ],
        "title": "Mechanics-aware deformation of yarn pattern geometry",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "168:1\u2013168:11",
        "article_number": "168",
        "number_of_pages": 11,
        "abstract": "Triangle mesh-based simulations are able to produce satisfying animations of knitted and woven cloth; however, they lack the rich geometric detail of yarn-level simulations. Naive texturing approaches do not consider yarn-level physics, while full yarn-level simulations may become prohibitively expensive for large garments. We propose a method to animate yarn-level cloth geometry on top of an underlying deforming mesh in a mechanics-aware fashion. Using triangle strains to interpolate precomputed yarn geometry, we are able to reproduce effects such as knit loops tightening under stretching. In combination with precomputed mesh animation or real-time mesh simulation, our method is able to animate yarn-level cloth in real-time at large scales.",
        "countries": [
            "AT",
            "IN"
        ]
    },
    "10.1145/3450626.3459777": {
        "doi": "10.1145/3450626.3459777",
        "authors": [
            {
                "family": "Van Mossel",
                "given": "Dave Pagurek",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Liu",
                "given": "Chenxi",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Vining",
                "given": "Nicholas",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Bessmeltsev",
                "given": "Mikhail",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Sheffer",
                "given": "Alla",
                "countries": [
                    "CA"
                ]
            }
        ],
        "title": "StrokeStrip: joint parameterization and fitting of stroke clusters",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "50:1\u201350:18",
        "article_number": "50",
        "number_of_pages": 18,
        "abstract": "When creating freeform drawings, artists routinely employ clusters of overdrawn strokes to convey intended, aggregate curves. The ability to algorithmically fit these intended curves to their corresponding clusters is central to many applications that use artist drawings as inputs. However, while human observers effortlessly envision the intended curves given stroke clusters as input, existing fitting algorithms lack robustness and frequently fail when presented with input stroke clusters with non-trivial geometry or topology. We present StrokeStrip, a new and robust method for fitting intended curves to vector-format stroke clusters. Our method generates fitting outputs consistent with viewer expectations across a vast range of input stroke cluster configurations. We observe that viewers perceive stroke clusters as continuous, varying-width strips whose paths are described by the intended curves. An arc length parameterization of these strips defines a natural mapping from a strip to its path. We recast the curve fitting problem as one of parameterizing the cluster strokes using a joint 1D parameterization that is the restriction of the natural arc length parameterization of this strip to the strokes in the cluster. We simultaneously compute the joint cluster parameterization and implicitly reconstruct the a priori unknown strip geometry by solving a variational problem using a discrete-continuous optimization framework. We use this parameterization to compute parametric aggregate curves whose shape reflects the geometric properties of the cluster strokes at the corresponding isovalues. We demonstrate StrokeStrip outputs to be significantly better aligned with observer preferences compared to those of prior art; in a perceptual study, viewers preferred our fitting outputs by a factor of 12:1 compared to alternatives. We further validate our algorithmic choices via a range of ablation studies; extend our framework to raster data; and illustrate applications that benefit from the parameterizations produced.",
        "countries": [
            "CA"
        ]
    },
    "10.1145/3450626.3459781": {
        "doi": "10.1145/3450626.3459781",
        "authors": [
            {
                "family": "Wang",
                "given": "Stephanie",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Chern",
                "given": "Albert",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Computing minimal surfaces with differential forms",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "113:1\u2013113:14",
        "article_number": "113",
        "number_of_pages": 14,
        "abstract": "We describe a new algorithm that solves a classical geometric problem: Find a surface of minimal area bordered by an arbitrarily prescribed boundary curve. Existing numerical methods face challenges due to the non-convexity of the problem. Using a representation of curves and surfaces via differential forms on the ambient space, we reformulate this problem as a convex optimization. This change of variables overcomes many difficulties in previous numerical attempts and allows us to find the global minimum across all possible surface topologies. The new algorithm is based on differential forms on the ambient space and does not require handling meshes. We adopt the Alternating Direction Method of Multiplier (ADMM) to find global minimal surfaces. The resulting algorithm is simple and efficient: it boils down to an alternation between a Fast Fourier Transform (FFT) and a pointwise shrinkage operation. We also show other applications of our solver in geometry processing such as surface reconstruction.",
        "countries": [
            "US"
        ]
    },
    "10.1145/3450626.3459835": {
        "doi": "10.1145/3450626.3459835",
        "authors": [
            {
                "family": "Metzer",
                "given": "Gal",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Hanocka",
                "given": "Rana",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Zorin",
                "given": "Denis",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Giryes",
                "given": "Raja",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Panozzo",
                "given": "Daniele",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Cohen-Or",
                "given": "Daniel",
                "countries": [
                    "IL"
                ]
            }
        ],
        "title": "Orienting point clouds with dipole propagation",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "165:1\u2013165:14",
        "article_number": "165",
        "number_of_pages": 14,
        "abstract": "Establishing a consistent normal orientation for point clouds is a notoriously difficult problem in geometry processing, requiring attention to both local and global shape characteristics. The normal direction of a point is a function of the local surface neighborhood; yet, point clouds do not disclose the full underlying surface structure. Even assuming known geodesic proximity, calculating a consistent normal orientation requires the global context. In this work, we introduce a novel approach for establishing a globally consistent normal orientation for point clouds. Our solution separates the local and global components into two different sub-problems. In the local phase, we train a neural network to learn a coherent normal direction per patch (i.e., consistently oriented normals within a single patch). In the global phase, we propagate the orientation across all coherent patches using a dipole propagation. Our dipole propagation decides to orient each patch using the electric field defined by all previously orientated patches. This gives rise to a global propagation that is stable, as well as being robust to nearby surfaces, holes, sharp features and noise.",
        "countries": [
            "IL",
            "US"
        ]
    },
    "10.1145/3450626.3459822": {
        "doi": "10.1145/3450626.3459822",
        "authors": [
            {
                "family": "Xie",
                "given": "Minshan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Xia",
                "given": "Menghan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Liu",
                "given": "Xueting",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Li",
                "given": "Chengze",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wong",
                "given": "Tien-Tsin",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Seamless manga inpainting with semantics awareness",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "96:1\u201396:11",
        "article_number": "96",
        "number_of_pages": 11,
        "abstract": "Manga inpainting fills up the disoccluded pixels due to the removal of dialogue balloons or \"sound effect\" text. This process is long needed by the industry for the language localization and the conversion to animated manga. It is mostly done manually, as existing methods (mostly for natural image inpainting) cannot produce satisfying results. Manga inpainting is more tricky than natural image inpainting because its highly abstract illustration using structural lines and screentone patterns, which confuses the semantic interpretation and visual content synthesis. In this paper, we present the first manga inpainting method, a deep learning model, that generates high-quality results. Instead of direct inpainting, we propose to separate the complicated inpainting into two major phases, semantic inpainting and appearance synthesis. This separation eases both the feature understanding and hence the training of the learning model. A key idea is to disentangle the structural line and screentone, that helps the network to better distinguish the structural line and the screentone features for semantic interpretation. Both the visual comparison and the quantitative experiments evidence the effectiveness of our method and justify its superiority over existing state-of-the-art methods in the application of manga inpainting.",
        "countries": [
            "CN"
        ]
    },
    "10.1145/3450626.3459833": {
        "doi": "10.1145/3450626.3459833",
        "authors": [
            {
                "family": "Mo",
                "given": "Haoran",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Simo-Serra",
                "given": "Edgar",
                "countries": [
                    "JP"
                ]
            },
            {
                "family": "Gao",
                "given": "Chengying",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zou",
                "given": "Changqing",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Wang",
                "given": "Ruomei",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "General virtual sketching framework for vector line art",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2021,
        "volume": "40",
        "number": "4",
        "pages": "51:1\u201351:14",
        "article_number": "51",
        "number_of_pages": 14,
        "abstract": "Vector line art plays an important role in graphic design, however, it is tedious to manually create. We introduce a general framework to produce line drawings from a wide variety of images, by learning a mapping from raster image space to vector image space. Our approach is based on a recurrent neural network that draws the lines one by one. A differentiable rasterization module allows for training with only supervised raster data. We use a dynamic window around a virtual pen while drawing lines, implemented with a proposed aligned cropping and differentiable pasting modules. Furthermore, we develop a stroke regularization loss that encourages the model to use fewer and longer strokes to simplify the resulting vector image. Ablation studies and comparisons with existing methods corroborate the efficiency of our approach which is able to generate visually better results in less computation time, while generalizing better to a diversity of images and applications.",
        "countries": [
            "CN",
            "JP",
            "CA"
        ]
    },
    "10.1145/3386569.3392386": {
        "doi": "10.1145/3386569.3392386",
        "authors": [
            {
                "family": "Chen",
                "given": "Shu-Yu",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Su",
                "given": "Wanchao",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Gao",
                "given": "Lin",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Xia",
                "given": "Shihong",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Fu",
                "given": "Hongbo",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "DeepFaceDrawing: deep generation of face images from sketches",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2020,
        "volume": "39",
        "number": "4",
        "pages": "72:1\u201372:16",
        "article_number": "72",
        "number_of_pages": 16,
        "abstract": "Recent deep image-to-image translation techniques allow fast generation of face images from freehand sketches. However, existing solutions tend to overfit to sketches, thus requiring professional sketches or even edge maps as input. To address this issue, our key idea is to implicitly model the shape space of plausible face images and synthesize a face image in this space to approximate an input sketch. We take a local-to-global approach. We first learn feature embeddings of key face components, and push corresponding parts of input sketches towards underlying component manifolds defined by the feature vectors of face component samples. We also propose another deep neural network to learn the mapping from the embedded component features to realistic images with multi-channel feature maps as intermediate results to improve the information flow. Our method essentially uses input sketches as soft constraints and is thus able to produce high-quality face images even from rough and/or incomplete sketches. Our tool is easy to use even for non-artists, while still supporting fine-grained control of shape details. Both qualitative and quantitative evaluations show the superior generation ability of our system to existing and alternative solutions. The usability and expressiveness of our system are confirmed by a user study.",
        "countries": [
            "CN"
        ]
    },
    "10.1145/3414685.3417795": {
        "doi": "10.1145/3414685.3417795",
        "authors": [
            {
                "family": "Du",
                "given": "Tao",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Wu",
                "given": "Kui",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Spielberg",
                "given": "Andrew",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Matusik",
                "given": "Wojciech",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Zhu",
                "given": "Bo",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Sifakis",
                "given": "Eftychios",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Functional optimization of fluidic devices with differentiable stokes flow",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2020,
        "volume": "39",
        "number": "6",
        "pages": "197:1\u2013197:15",
        "article_number": "197",
        "number_of_pages": 15,
        "abstract": "We present a method for performance-driven optimization of fluidic devices. In our approach, engineers provide a high-level specification of a device using parametric surfaces for the fluid-solid boundaries. They also specify desired flow properties for inlets and outlets of the device. Our computational approach optimizes the boundary of the fluidic device such that its steady-state flow matches desired flow at outlets. In order to deal with computational challenges of this task, we propose an efficient, differentiable Stokes flow solver. Our solver provides explicit access to gradients of performance metrics with respect to the parametric boundary representation. This key feature allows us to couple the solver with efficient gradient-based optimization methods. We demonstrate the efficacy of this approach on designs of five complex 3D fluidic systems. Our approach makes an important step towards practical computational design tools for high-performance fluidic devices.",
        "countries": [
            "US"
        ]
    },
    "10.1145/3386569.3392413": {
        "doi": "10.1145/3386569.3392413",
        "authors": [
            {
                "family": "Bonneel",
                "given": "Nicolas",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Coeurjolly",
                "given": "David",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Digne",
                "given": "Julie",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Mellado",
                "given": "Nicolas",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Code replicability in computer graphics",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2020,
        "volume": "39",
        "number": "4",
        "pages": "93:1\u201393:8",
        "article_number": "93",
        "number_of_pages": 8,
        "abstract": "Being able to duplicate published research results is an important process of conducting research whether to build upon these findings or to compare with them. This process is called \"replicability\" when using the original authors' artifacts (e.g., code), or \"reproducibility\" otherwise (e.g., re-implementing algorithms). Reproducibility and replicability of research results have gained a lot of interest recently with assessment studies being led in various fields, and they are often seen as a trigger for better result diffusion and transparency. In this work, we assess replicability in Computer Graphics, by evaluating whether the code is available and whether it works properly. As a proxy for this field we compiled, ran and analyzed 151 codes out of 374 papers from 2014, 2016 and 2018 SIGGRAPH conferences. This analysis shows a clear increase in the number of papers with available and operational research codes with a dependency on the subfields, and indicates a correlation between code replicability and citation count. We further provide an interactive tool to explore our results and evaluation data.",
        "countries": [
            "FR"
        ]
    },
    "10.1145/3386569.3392488": {
        "doi": "10.1145/3386569.3392488",
        "authors": [
            {
                "family": "Tan",
                "given": "Zhentao",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Chai",
                "given": "Menglei",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Chen",
                "given": "Dongdong",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Liao",
                "given": "Jing",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Chu",
                "given": "Qi",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Yuan",
                "given": "Lu",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Tulyakov",
                "given": "Sergey",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Yu",
                "given": "Nenghai",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "MichiGAN: multi-input-conditioned hair image generation for portrait editing",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2020,
        "volume": "39",
        "number": "4",
        "pages": "95:1\u201395:13",
        "article_number": "95",
        "number_of_pages": 13,
        "abstract": "Despite the recent success of face image generation with GANs, conditional hair editing remains challenging due to the under-explored complexity of its geometry and appearance. In this paper, we present MichiGAN (Multi-Input-Conditioned Hair Image GAN), a novel conditional image generation method for interactive portrait hair manipulation. To provide user control over every major hair visual factor, we explicitly disentangle hair into four orthogonal attributes, including shape, structure, appearance, and background. For each of them, we design a corresponding condition module to represent, process, and convert user inputs, and modulate the image generation pipeline in ways that respect the natures of different visual attributes. All these condition modules are integrated with the backbone generator to form the final end-to-end network, which allows fully-conditioned hair generation from multiple user inputs. Upon it, we also build an interactive portrait hair editing system that enables straightforward manipulation of hair by projecting intuitive and high-level user inputs such as painted masks, guiding strokes, or reference photos to well-defined condition representations. Through extensive experiments and evaluations, we demonstrate the superiority of our method regarding both result quality and user controllability.",
        "countries": [
            "CN",
            "US"
        ]
    },
    "10.1145/2897824.2925930": {
        "doi": "10.1145/2897824.2925930",
        "authors": [
            {
                "family": "Qin",
                "given": "Yipeng",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Han",
                "given": "Xiaoguang",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Yu",
                "given": "Hongchuan",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Yu",
                "given": "Yizhou",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhang",
                "given": "Jianjun",
                "countries": [
                    "GB"
                ]
            }
        ],
        "title": "Fast and exact discrete geodesic computation based on triangle-oriented wavefront propagation",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2016,
        "volume": "35",
        "number": "4",
        "pages": "125:1\u2013125:13",
        "article_number": "125",
        "number_of_pages": 13,
        "abstract": "Computing discrete geodesic distance over triangle meshes is one of the fundamental problems in computational geometry and computer graphics. In this problem, an effective window pruning strategy can significantly affect the actual running time. Due to its importance, we conduct an in-depth study of window pruning operations in this paper, and produce an exhaustive list of scenarios where one window can make another window partially or completely redundant. To identify a maximal number of redundant windows using such pairwise cross checking, we propose a set of procedures to synchronize local window propagation within the same triangle by simultaneously propagating a collection of windows from one triangle edge to its two opposite edges. On the basis of such synchronized window propagation, we design a new geodesic computation algorithm based on a triangle-oriented region growing scheme. Our geodesic algorithm can remove most of the redundant windows at the earliest possible stage, thus significantly reducing computational cost and memory usage at later stages. In addition, by adopting triangles instead of windows as the primitive in propagation management, our algorithm significantly cuts down the data management overhead. As a result, it runs 4--15 times faster than MMP and ICH algorithms, 2-4 times faster than FWP-MMP and FWP-CH algorithms, and also incurs the least memory usage.",
        "countries": [
            "GB",
            "CN"
        ]
    },
    "10.1145/3386569.3392421": {
        "doi": "10.1145/3386569.3392421",
        "authors": [
            {
                "family": "Ruppert",
                "given": "Lukas",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Herholz",
                "given": "Sebastian",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Lensch",
                "given": "Hendrik P. A.",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Robust fitting of parallax-aware mixtures for path guiding",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2020,
        "volume": "39",
        "number": "4",
        "pages": "147:1\u2013147:15",
        "article_number": "147",
        "number_of_pages": 15,
        "abstract": "Effective local light transport guiding demands for high quality guiding information, i.e., a precise representation of the directional incident radiance distribution at every point inside the scene. We introduce a parallax-aware distribution model based on parametric mixtures. By parallax-aware warping of the distribution, the local approximation of the 5D radiance field remains valid and precise across large spatial regions, even for close-by contributors. Our robust optimization scheme fits parametric mixtures to radiance samples collected in previous rendering passes. Robustness is achieved by splitting and merging of components refining the mixture. These splitting and merging decisions minimize and bound the expected variance of the local radiance estimator. In addition, we extend the fitting scheme to a robust, iterative update method, which allows for incremental training of our model using smaller sample batches. This results in more frequent training updates and, at the same time, significantly reduces the required sample memory footprint. The parametric representation of our model allows for the application of advanced importance sampling methods such as radiance-based, cosine-aware, and even product importance sampling. Our method further smoothly integrates next-event estimation (NEE) into path guiding, avoiding importance sampling of contributions better covered by NEE. The proposed robust fitting and update scheme, in combination with the parallax-aware representation, results in faster learning and lower variance compared to state-of-the-art path guiding approaches.",
        "countries": [
            "DE"
        ]
    },
    "10.1145/3386569.3392417": {
        "doi": "10.1145/3386569.3392417",
        "authors": [
            {
                "family": "Coevoet",
                "given": "Eulalie",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Benchekroun",
                "given": "Otman",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Kry",
                "given": "Paul G.",
                "countries": [
                    "CA"
                ]
            }
        ],
        "title": "Adaptive merging for rigid body simulation",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2020,
        "volume": "39",
        "number": "4",
        "pages": "35:1\u201335:13",
        "article_number": "35",
        "number_of_pages": 13,
        "abstract": "We reduce computation time in rigid body simulations by merging collections of bodies when they share a common spatial velocity. Merging relies on monitoring the state of contacts, and a metric that compares the relative linear and angular motion of bodies based on their sizes. Unmerging relies on an inexpensive single iteration projected Gauss-Seidel sweep over contacts between merged bodies, which lets us update internal contact forces over time, and use the same metrics as merging to identify when bodies should unmerge. Furthermore we use a contact ordering for graph traversal refinement of the internal contact forces in collections, which helps to correctly identify all the bodies that must unmerge when there are impacts. The general concept of merging is similar to the common technique of sleeping and waking rigid bodies in the inertial frame, and we exploit this too, but our merging is in moving frames, and unmerging takes place at contacts between bodies rather than at the level of bodies themselves. We discuss the previous relative motion metrics in comparison to ours, and evaluate our method on a variety of scenarios.",
        "countries": [
            "CA"
        ]
    },
    "10.1145/3386569.3392419": {
        "doi": "10.1145/3386569.3392419",
        "authors": [
            {
                "family": "Sell\u00e1n",
                "given": "Silvia",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Aigerman",
                "given": "Noam",
                "countries": [
                    "CA",
                    "US"
                ]
            },
            {
                "family": "Jacobson",
                "given": "Alec",
                "countries": [
                    "CA"
                ]
            }
        ],
        "title": "Developability of heightfields via rank minimization",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2020,
        "volume": "39",
        "number": "4",
        "pages": "109:1\u2013109:15",
        "article_number": "109",
        "number_of_pages": 15,
        "abstract": "This work concerns the computation and approximation of developable surfaces --- surfaces that are locally isometric to the two-dimensional plane. These surfaces are heavily studied in differential geometry, and are also of great interest to fabrication, architecture and fashion. We focus specifically on developability of heightfields. Our main observation is that developability can be cast as a rank constraint, which can then be plugged into theoretically-grounded rank-minimization techniques from the field of compressed sensing. This leads to a convex semidefinite optimization problem, which receives an input heightfield and recovers a similar heightfield which is developable. Due to the sparsifying nature of compressed sensing, the recovered surface is piecewise developable, with creases emerging between connected developable pieces. The convex program includes one user-specified parameter, balancing adherence to the original surface with developability and number of patches. We moreover show, that in contrast to previous techniques, our discretization does not introduce a bias and the same results are achieved across resolutions and orientations, and with no limit on the number of creases and patches. We solve this convex semidefinite optimization problem efficiently, by devising a tailor-made ADMM solver which leverages matrix-projection observations unique to our problem. We employ our method on a plethora of experiments, from denoising 3D scans of developable geometry such as documents and buildings, through approximating general heightfields with developable ones, and up to interpolating sparse annotations with a developable heightfield.",
        "countries": [
            "CA",
            "US"
        ]
    },
    "10.1145/3386569.3392385": {
        "doi": "10.1145/3386569.3392385",
        "authors": [
            {
                "family": "Hu",
                "given": "Yixin",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Schneider",
                "given": "Teseo",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Wang",
                "given": "Bolun",
                "countries": [
                    "CN",
                    "US"
                ]
            },
            {
                "family": "Zorin",
                "given": "Denis",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Panozzo",
                "given": "Daniele",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Fast tetrahedral meshing in the wild",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2020,
        "volume": "39",
        "number": "4",
        "pages": "117:1\u2013117:18",
        "article_number": "117",
        "number_of_pages": 18,
        "abstract": "We propose a new tetrahedral meshing method, fTetWild, to convert triangle soups into high-quality tetrahedral meshes. Our method builds on the TetWild algorithm, replacing the rational triangle insertion with a new incremental approach to construct and optimize the output mesh, interleaving triangle insertion and mesh optimization. Our approach makes it possible to maintain a valid floating-point tetrahedral mesh at all algorithmic stages, eliminating the need for costly constructions with rational numbers used by TetWild, while maintaining full robustness and similar output quality. This allows us to improve on TetWild in two ways. First, our algorithm is significantly faster, with running time comparable to less robust Delaunay-based tetrahedralization algorithms. Second, our algorithm is guaranteed to produce a valid tetrahedral mesh with floating-point vertex coordinates, while TetWild produces a valid mesh with rational coordinates which is not guaranteed to be valid after floating-point conversion. As a trade-off, our algorithm no longer guarantees that all input triangles are present in the output mesh, but in practice, as confirmed by our tests on the Thingi10k dataset, the algorithm always succeeds in inserting all input triangles.",
        "countries": [
            "US",
            "CN"
        ]
    },
    "10.1145/3306346.3322949": {
        "doi": "10.1145/3306346.3322949",
        "authors": [
            {
                "family": "Wolper",
                "given": "Joshuah",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Fang",
                "given": "Yu",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Li",
                "given": "Minchen",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Lu",
                "given": "Jiecong",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Gao",
                "given": "Ming",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Jiang",
                "given": "Chenfanfu",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "CD-MPM: continuum damage material point methods for dynamic fracture animation",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2019,
        "volume": "38",
        "number": "4",
        "pages": "119:1\u2013119:15",
        "article_number": "119",
        "number_of_pages": 15,
        "abstract": "We present two new approaches for animating dynamic fracture involving large elastoplastic deformation. In contrast to traditional mesh-based techniques, where sharp discontinuity is introduced to split the continuum at crack surfaces, our methods are based on Continuum Damage Mechanics (CDM) with a variational energy-based formulation for crack evolution. Our first approach formulates the resulting dynamic material damage evolution with a Ginzburg-Landau type phase-field equation and discretizes it with the Material Point Method (MPM), resulting in a coupled momentum/damage solver rooted in phase field fracture: PFF-MPM. Although our PFF-MPM approach achieves convincing fracture with or without plasticity, we also introduce a return mapping algorithm that can be analytically solved for a wide range of general non-associated plasticity models, achieving more than two times speedup over traditional iterative approaches. To demonstrate the efficacy of the algorithm, we also develop a Non-Associated Cam-Clay (NACC) plasticity model with a novel fracture-friendly hardening scheme. Our NACC plasticity paired with traditional MPM composes a second approach to dynamic fracture, as it produces a breadth of organic, brittle material fracture effects on its own. Though NACC and PFF can be combined, we focus on exploring their material effects separately. Both methods can be easily integrated into any existing MPM solver, enabling the simulation of various fracturing materials with extremely high visual fidelity while requiring little additional computational overhead.",
        "countries": [
            "US"
        ]
    },
    "10.1145/3386569.3392448": {
        "doi": "10.1145/3386569.3392448",
        "authors": [
            {
                "family": "Hornus",
                "given": "Samuel",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Kuipers",
                "given": "Tim",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Devillers",
                "given": "Olivier",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Teillaud",
                "given": "Monique",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Mart\u00ednez",
                "given": "Jon\u00e0s",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Glisse",
                "given": "Marc",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Lazard",
                "given": "Sylvain",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Lefebvre",
                "given": "Sylvain",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Variable-width contouring for additive manufacturing",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2020,
        "volume": "39",
        "number": "4",
        "pages": "131:1\u2013131:17",
        "article_number": "131",
        "number_of_pages": 17,
        "abstract": "In most layered additive manufacturing processes, a tool solidifies or deposits material while following pre-planned trajectories to form solid beads. Many interesting problems arise in this context, among which one concerns the planning of trajectories for filling a planar shape as densely as possible. This is the problem we tackle in the present paper. Recent works have shown that allowing the bead width to vary along the trajectories helps increase the filling density. We present a novel technique that, given a deposition width range, constructs a set of closed beads whose width varies within the prescribed range and fill the input shape. The technique outperforms the state of the art in important metrics: filling density (while still guaranteeing the absence of bead overlap) and trajectories smoothness. We give a detailed geometric description of our algorithm, explore its behavior on example inputs and provide a statistical comparison with the state of the art. We show that it is possible to obtain high quality fabricated layers on commodity FDM printers.",
        "countries": [
            "FR",
            "NL"
        ]
    },
    "10.1145/3386569.3392415": {
        "doi": "10.1145/3386569.3392415",
        "authors": [
            {
                "family": "Hanocka",
                "given": "Rana",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Metzer",
                "given": "Gal",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Giryes",
                "given": "Raja",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Cohen-Or",
                "given": "Daniel",
                "countries": [
                    "IL"
                ]
            }
        ],
        "title": "Point2Mesh: a self-prior for deformable meshes",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2020,
        "volume": "39",
        "number": "4",
        "pages": "126:1\u2013126:12",
        "article_number": "126",
        "number_of_pages": 12,
        "abstract": "In this paper, we introduce Point2Mesh, a technique for reconstructing a surface mesh from an input point cloud. Instead of explicitly specifying a prior that encodes the expected shape properties, the prior is defined automatically using the input point cloud, which we refer to as a self-prior. The self-prior encapsulates reoccurring geometric repetitions from a single shape within the weights of a deep neural network. We optimize the network weights to deform an initial mesh to shrink-wrap a single input point cloud. This explicitly considers the entire reconstructed shape, since shared local kernels are calculated to fit the overall object. The convolutional kernels are optimized globally across the entire shape, which inherently encourages local-scale geometric self-similarity across the shape surface. We show that shrink-wrapping a point cloud with a self-prior converges to a desirable solution; compared to a prescribed smoothness prior, which often becomes trapped in undesirable local minima. While the performance of traditional reconstruction approaches degrades in non-ideal conditions that are often present in real world scanning, i.e., unoriented normals, noise and missing (low density) parts, Point2Mesh is robust to non-ideal conditions. We demonstrate the performance of Point2Mesh on a large variety of shapes with varying complexity.",
        "countries": [
            "IL"
        ]
    },
    "10.1145/3386569.3392471": {
        "doi": "10.1145/3386569.3392471",
        "authors": [
            {
                "family": "Hertz",
                "given": "Amir",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Hanocka",
                "given": "Rana",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Giryes",
                "given": "Raja",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Cohen-Or",
                "given": "Daniel",
                "countries": [
                    "IL"
                ]
            }
        ],
        "title": "Deep geometric texture synthesis",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2020,
        "volume": "39",
        "number": "4",
        "pages": "108:1\u2013108:11",
        "article_number": "108",
        "number_of_pages": 11,
        "abstract": "Recently, deep generative adversarial networks for image generation have advanced rapidly; yet, only a small amount of research has focused on generative models for irregular structures, particularly meshes. Nonetheless, mesh generation and synthesis remains a fundamental topic in computer graphics. In this work, we propose a novel framework for synthesizing geometric textures. It learns geometric texture statistics from local neighborhoods (i.e., local triangular patches) of a single reference 3D model. It learns deep features on the faces of the input triangulation, which is used to subdivide and generate offsets across multiple scales, without parameterization of the reference or target mesh. Our network displaces mesh vertices in any direction (i.e., in the normal and tangential direction), enabling synthesis of geometric textures, which cannot be expressed by a simple 2D displacement map. Learning and synthesizing on local geometric patches enables a genus-oblivious framework, facilitating texture transfer between shapes of different genus.",
        "countries": [
            "IL"
        ]
    },
    "10.1145/2897824.2925976": {
        "doi": "10.1145/2897824.2925976",
        "authors": [
            {
                "family": "Lyon",
                "given": "Max",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Bommes",
                "given": "David",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Kobbelt",
                "given": "Leif",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "HexEx: robust hexahedral mesh extraction",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2016,
        "volume": "35",
        "number": "4",
        "pages": "123:1\u2013123:11",
        "article_number": "123",
        "number_of_pages": 11,
        "abstract": "State-of-the-art hex meshing algorithms consist of three steps: Frame-field design, parametrization generation, and mesh extraction. However, while the first two steps are usually discussed in detail, the last step is often not well studied. In this paper, we fully concentrate on reliable mesh extraction.Parametrization methods employ computationally expensive countermeasures to avoid mapping input tetrahedra to degenerate or flipped tetrahedra in the parameter domain because such a parametrization does not define a proper hexahedral mesh. Nevertheless, there is no known technique that can guarantee the complete absence of such artifacts.We tackle this problem from the other side by developing a mesh extraction algorithm which is extremely robust against typical imperfections in the parametrization. First, a sanitization process cleans up numerical inconsistencies of the parameter values caused by limited precision solvers and floating-point number representation. On the sanitized parametrization, we extract vertices and so-called darts based on intersections of the integer grid with the parametric image of the tetrahedral mesh. The darts are reliably interconnected by tracing within the parametrization and thus define the topology of the hexahedral mesh. In a postprocessing step, we let certain pairs of darts cancel each other, counteracting the effect of flipped regions of the parametrization. With this strategy, our algorithm is able to robustly extract hexahedral meshes from imperfect parametrizations which previously would have been considered defective. The algorithm will be published as an open source library [Lyon et al. 2016].",
        "countries": [
            "DE"
        ]
    },
    "10.1145/3386569.3392462": {
        "doi": "10.1145/3386569.3392462",
        "authors": [
            {
                "family": "Aberman",
                "given": "Kfir",
                "countries": [
                    "CN",
                    "IL"
                ]
            },
            {
                "family": "Li",
                "given": "Peizhuo",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Lischinski",
                "given": "Dani",
                "countries": [
                    "IL",
                    "CN"
                ]
            },
            {
                "family": "Sorkine-Hornung",
                "given": "Olga",
                "countries": [
                    "CH",
                    "CN"
                ]
            },
            {
                "family": "Cohen-Or",
                "given": "Daniel",
                "countries": [
                    "IL",
                    "CN"
                ]
            },
            {
                "family": "Chen",
                "given": "Baoquan",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Skeleton-aware networks for deep motion retargeting",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2020,
        "volume": "39",
        "number": "4",
        "pages": "62:1\u201362:14",
        "article_number": "62",
        "number_of_pages": 14,
        "abstract": "We introduce a novel deep learning framework for data-driven motion retargeting between skeletons, which may have different structure, yet corresponding to homeomorphic graphs. Importantly, our approach learns how to retarget without requiring any explicit pairing between the motions in the training set.We leverage the fact that different homeomorphic skeletons may be reduced to a common primal skeleton by a sequence of edge merging operations, which we refer to as skeletal pooling. Thus, our main technical contribution is the introduction of novel differentiable convolution, pooling, and unpooling operators. These operators are skeleton-aware, meaning that they explicitly account for the skeleton's hierarchical structure and joint adjacency, and together they serve to transform the original motion into a collection of deep temporal features associated with the joints of the primal skeleton. In other words, our operators form the building blocks of a new deep motion processing framework that embeds the motion into a common latent space, shared by a collection of homeomorphic skeletons. Thus, retargeting can be achieved simply by encoding to, and decoding from this latent space.Our experiments show the effectiveness of our framework for motion retargeting, as well as motion processing in general, compared to existing approaches. Our approach is also quantitatively evaluated on a synthetic dataset that contains pairs of motions applied to different skeletons. To the best of our knowledge, our method is the first to perform retargeting between skeletons with differently sampled kinematic chains, without any paired examples.",
        "countries": [
            "CN",
            "IL",
            "CH"
        ]
    },
    "10.1145/3386569.3392392": {
        "doi": "10.1145/3386569.3392392",
        "authors": [
            {
                "family": "Nehab",
                "given": "Diego",
                "countries": [
                    "BR"
                ]
            }
        ],
        "title": "Converting stroked primitives to filled primitives",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2020,
        "volume": "39",
        "number": "4",
        "pages": "137:1\u2013137:17",
        "article_number": "137",
        "number_of_pages": 17,
        "abstract": "Vector graphics formats offer support for both filled and stroked primitives. Filled primitives paint all points in the region bounded by a set of outlines. Stroked primitives paint all points covered by a line drawn over the outlines. Editors allow users to convert stroked primitives to the outlines of equivalent filled primitives for further editing. Likewise, renderers typically convert stroked primitives to equivalent filled primitives prior to rendering. This conversion problem is deceivingly difficult to solve. Surprisingly, it has received little to no attention in the literature. Existing implementations output too many segments, do not satisfy accuracy requirements, or fail under a variety of conditions, often spectacularly. In this paper, we present a solution to the stroke-to-fill conversion problem that addresses these issues. One of our key insights is to take into account the evolutes of input outlines, in addition to their offsets, in regions of high curvature. Furthermore, our approach strives to maintain continuity between the input and the set of painted points. Our implementation is available in open source.",
        "countries": [
            "BR"
        ]
    },
    "10.1145/3386569.3392433": {
        "doi": "10.1145/3386569.3392433",
        "authors": [
            {
                "family": "Luo",
                "given": "Ying-Sheng",
                "countries": [
                    "TW"
                ]
            },
            {
                "family": "Soeseno",
                "given": "Jonathan Hans",
                "countries": [
                    "TW"
                ]
            },
            {
                "family": "Chen",
                "given": "Trista Pei-Chun",
                "countries": [
                    "TW"
                ]
            },
            {
                "family": "Chen",
                "given": "Wei-Chao",
                "countries": [
                    "TW"
                ]
            }
        ],
        "title": "CARL: controllable agent with reinforcement learning for quadruped locomotion",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2020,
        "volume": "39",
        "number": "4",
        "pages": "38:1\u201338:10",
        "article_number": "38",
        "number_of_pages": 10,
        "abstract": "Motion synthesis in a dynamic environment has been a long-standing problem for character animation. Methods using motion capture data tend to scale poorly in complex environments because of their larger capturing and labeling requirement. Physics-based controllers are effective in this regard, albeit less controllable. In this paper, we present CARL, a quadruped agent that can be controlled with high-level directives and react naturally to dynamic environments. Starting with an agent that can imitate individual animation clips, we use Generative Adversarial Networks to adapt high-level controls, such as speed and heading, to action distributions that correspond to the original animations. Further fine-tuning through the deep reinforcement learning enables the agent to recover from unseen external perturbations while producing smooth transitions. It then becomes straightforward to create autonomous agents in dynamic environments by adding navigation modules over the entire process. We evaluate our approach by measuring the agent's ability to follow user control and provide a visual analysis of the generated motion to show its effectiveness.",
        "countries": [
            "TW"
        ]
    },
    "10.1145/3386569.3392379": {
        "doi": "10.1145/3386569.3392379",
        "authors": [
            {
                "family": "Xu",
                "given": "Zhan",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Zhou",
                "given": "Yang",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Kalogerakis",
                "given": "Evangelos",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Landreth",
                "given": "Chris",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Singh",
                "given": "Karan",
                "countries": [
                    "CA"
                ]
            }
        ],
        "title": "RigNet: neural rigging for articulated characters",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2020,
        "volume": "39",
        "number": "4",
        "pages": "58:1\u201358:14",
        "article_number": "58",
        "number_of_pages": 14,
        "abstract": "We present RigNet, an end-to-end automated method for producing animation rigs from input character models. Given an input 3D model representing an articulated character, RigNet predicts a skeleton that matches the animator expectations in joint placement and topology. It also estimates surface skin weights based on the predicted skeleton. Our method is based on a deep architecture that directly operates on the mesh representation without making assumptions on shape class and structure. The architecture is trained on a large and diverse collection of rigged models, including their mesh, skeletons and corresponding skin weights. Our evaluation is three-fold: we show better results than prior art when quantitatively compared to animator rigs; qualitatively we show that our rigs can be expressively posed and animated at multiple levels of detail; and finally, we evaluate the impact of various algorithm choices on our output rigs.1",
        "countries": [
            "US",
            "CA"
        ]
    },
    "10.1145/3388887": {
        "doi": "10.1145/3388887",
        "authors": [
            {
                "family": "Liu",
                "given": "Wei",
                "countries": [
                    "AU"
                ]
            },
            {
                "family": "Zhang",
                "given": "Pingping",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Huang",
                "given": "Xiaolin",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Yang",
                "given": "Jie",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Shen",
                "given": "Chunhua",
                "countries": [
                    "AU"
                ]
            },
            {
                "family": "Reid",
                "given": "Ian",
                "countries": [
                    "AU"
                ]
            }
        ],
        "title": "Real-time Image Smoothing via Iterative Least Squares",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2020,
        "volume": "39",
        "number": "3",
        "pages": "28:1\u201328:24",
        "article_number": "28",
        "number_of_pages": 24,
        "abstract": "Edge-preserving image smoothing is a fundamental procedure for many computer vision and graphic applications. There is a tradeoff between the smoothing quality and the processing speed: the high smoothing quality usually requires a high computational cost, which leads to the low processing speed. In this article, we propose a new global optimization based method, named iterative least squares (ILS), for efficient edge-preserving image smoothing. Our approach can produce high-quality results but at a much lower computational cost. Comprehensive experiments demonstrate that the proposed method can produce results with little visible artifacts. Moreover, the computation of ILS can be highly parallel, which can be easily accelerated through either multi-thread computing or the GPU hardware. With the acceleration of a GTX 1080 GPU, it is able to process images of 1080p resolution (1920 \u00d7 1080) at the rate of 20fps for color images and 47fps for gray images. In addition, the ILS is flexible and can be modified to handle more applications that require different smoothing properties. Experimental results of several applications show the effectiveness and efficiency of the proposed method. The code is available at https://github.com/wliusjtu/Real-time-Image-Smoothing-via-Iterative-Least-Squares.",
        "countries": [
            "AU",
            "CN"
        ]
    },
    "10.1145/3197517.3201363": {
        "doi": "10.1145/3197517.3201363",
        "authors": [
            {
                "family": "Gruson",
                "given": "Adrien",
                "countries": [
                    "JP",
                    "FR"
                ]
            },
            {
                "family": "Hua",
                "given": "Binh-Son",
                "countries": [
                    "JP",
                    "SG"
                ]
            },
            {
                "family": "Vibert",
                "given": "Nicolas",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Nowrouzezahrai",
                "given": "Derek",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Hachisuka",
                "given": "Toshiya",
                "countries": [
                    "JP"
                ]
            }
        ],
        "title": "Gradient-domain volumetric photon density estimation",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2018,
        "volume": "37",
        "number": "4",
        "pages": "82:1\u201382:13",
        "article_number": "82",
        "number_of_pages": 13,
        "abstract": "Gradient-domain rendering can improve the convergence of surface-based light transport by exploiting smoothness in image space. Scenes with participating media exhibit similar smoothness and could potentially benefit from gradient-domain techniques. We introduce the first gradient-domain formulation of image synthesis with homogeneous participating media, including four novel and efficient gradient-domain volumetric density estimation algorithms. We show that na\u00efve extensions of gradient domain path-space and density estimation methods to volumetric media, while functional, can result in inefficient estimators. Focussing on point-, beam- and plane-based gradient-domain estimators, we introduce a novel shift mapping that eliminates redundancies in the na\u00efve formulations using spatial relaxation within the volume. We show that gradient-domain volumetric rendering improve convergence compared to primal domain state-of-the-art, across a suite of scenes. Our formulation and algorithms support progressive estimation and are easy to incorporate atop existing renderers.",
        "countries": [
            "JP",
            "FR",
            "SG",
            "CA"
        ]
    },
    "10.1145/3197517.3201275": {
        "doi": "10.1145/3197517.3201275",
        "authors": [
            {
                "family": "Aksoy",
                "given": "Ya\u011fiz",
                "countries": [
                    "US",
                    "CH"
                ]
            },
            {
                "family": "Oh",
                "given": "Tae-Hyun",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Paris",
                "given": "Sylvain",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Pollefeys",
                "given": "Marc",
                "countries": [
                    "CH",
                    "US"
                ]
            },
            {
                "family": "Matusik",
                "given": "Wojciech",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Semantic soft segmentation",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2018,
        "volume": "37",
        "number": "4",
        "pages": "72:1\u201372:13",
        "article_number": "72",
        "number_of_pages": 13,
        "abstract": "Accurate representation of soft transitions between image regions is essential for high-quality image editing and compositing. Current techniques for generating such representations depend heavily on interaction by a skilled visual artist, as creating such accurate object selections is a tedious task. In this work, we introduce semantic soft segments, a set of layers that correspond to semantically meaningful regions in an image with accurate soft transitions between different objects. We approach this problem from a spectral segmentation angle and propose a graph structure that embeds texture and color features from the image as well as higher-level semantic information generated by a neural network. The soft segments are generated via eigendecomposition of the carefully constructed Laplacian matrix fully automatically. We demonstrate that otherwise complex image editing tasks can be done with little effort using semantic soft segments.",
        "countries": [
            "US",
            "CH"
        ]
    },
    "10.1145/3197517.3201342": {
        "doi": "10.1145/3197517.3201342",
        "authors": [
            {
                "family": "Dai",
                "given": "Chengkai",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Wang",
                "given": "Charlie C. L.",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Wu",
                "given": "Chenming",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Lefebvre",
                "given": "Sylvain",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Fang",
                "given": "Guoxin",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Liu",
                "given": "Yong-Jin",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Support-free volume printing by multi-axis motion",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2018,
        "volume": "37",
        "number": "4",
        "pages": "134:1\u2013134:14",
        "article_number": "134",
        "number_of_pages": 14,
        "abstract": "This paper presents a new method to fabricate 3D models on a robotic printing system equipped with multi-axis motion. Materials are accumulated inside the volume along curved tool-paths so that the need of supporting structures can be tremendously reduced - if not completely abandoned - on all models. Our strategy to tackle the challenge of tool-path planning for multi-axis 3D printing is to perform two successive decompositions, first volume-to-surfaces and then surfaces-to-curves. The volume-to-surfaces decomposition is achieved by optimizing a scalar field within the volume that represents the fabrication sequence. The field is constrained such that its iso-values represent curved layers that are supported from below, and present a convex surface affording for collision-free navigation of the printer head. After extracting all curved layers, the surfaces-to-curves decomposition covers them with tool-paths while taking into account constraints from the robotic printing system. Our method successfully generates tool-paths for 3D printing models with large overhangs and high-genus topology. We fabricated several challenging cases on our robotic platform to verify and demonstrate its capabilities.",
        "countries": [
            "NL",
            "CN",
            "FR"
        ]
    },
    "10.1145/2897824.2925920": {
        "doi": "10.1145/2897824.2925920",
        "authors": [
            {
                "family": "Kovalsky",
                "given": "Shahar Z.",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Galun",
                "given": "Meirav",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Lipman",
                "given": "Yaron",
                "countries": [
                    "IL"
                ]
            }
        ],
        "title": "Accelerated quadratic proxy for geometric optimization",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2016,
        "volume": "35",
        "number": "4",
        "pages": "134:1\u2013134:11",
        "article_number": "134",
        "number_of_pages": 11,
        "abstract": "We present the Accelerated Quadratic Proxy (AQP) - a simple first-order algorithm for the optimization of geometric energies defined over triangular and tetrahedral meshes.The main stumbling block of current optimization techniques used to minimize geometric energies over meshes is slow convergence due to ill-conditioning of the energies at their minima. We observe that this ill-conditioning is in large part due to a Laplacian-like term existing in these energies. Consequently, we suggest to locally use a quadratic polynomial proxy, whose Hessian is taken to be the Laplacian, in order to achieve a preconditioning effect. This already improves stability and convergence, but more importantly allows incorporating acceleration in an almost universal way, that is independent of mesh size and of the specific energy considered.Experiments with AQP show it is rather insensitive to mesh resolution and requires a nearly constant number of iterations to converge; this is in strong contrast to other popular optimization techniques used today such as Accelerated Gradient Descent and Quasi-Newton methods, e.g., L-BFGS. We have tested AQP for mesh deformation in 2D and 3D as well as for surface parameterization, and found it to provide a considerable speedup over common baseline techniques.",
        "countries": [
            "IL"
        ]
    },
    "10.1145/3197517.3201317": {
        "doi": "10.1145/3197517.3201317",
        "authors": [
            {
                "family": "Prada",
                "given": "Fabi\u00e1n",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Kazhdan",
                "given": "Misha",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Chuang",
                "given": "Ming",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Hoppe",
                "given": "Hugues",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Gradient-domain processing within a texture atlas",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2018,
        "volume": "37",
        "number": "4",
        "pages": "154:1\u2013154:14",
        "article_number": "154",
        "number_of_pages": 14,
        "abstract": "Processing signals on surfaces often involves resampling the signal over the vertices of a dense mesh and applying mesh-based filtering operators. We present a framework to process a signal directly in a texture atlas domain. The benefits are twofold: avoiding resampling degradation and exploiting the regularity of the texture image grid. The main challenges are to preserve continuity across atlas chart boundaries and to adapt differential operators to the non-uniform parameterization. We introduce a novel function space and multigrid solver that jointly enable robust, interactive, and geometry-aware signal processing. We demonstrate our approach using several applications including smoothing and sharpening, multiview stitching, geodesic distance computation, and line integral convolution.",
        "countries": [
            "US"
        ]
    },
    "10.1145/3197517.3201311": {
        "doi": "10.1145/3197517.3201311",
        "authors": [
            {
                "family": "Peng",
                "given": "Xue Bin",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Abbeel",
                "given": "Pieter",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Levine",
                "given": "Sergey",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "van de Panne",
                "given": "Michiel",
                "countries": [
                    "CA"
                ]
            }
        ],
        "title": "DeepMimic: example-guided deep reinforcement learning of physics-based character skills",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2018,
        "volume": "37",
        "number": "4",
        "pages": "143:1\u2013143:14",
        "article_number": "143",
        "number_of_pages": 14,
        "abstract": "A longstanding goal in character animation is to combine data-driven specification of behavior with a system that can execute a similar behavior in a physical simulation, thus enabling realistic responses to perturbations and environmental variation. We show that well-known reinforcement learning (RL) methods can be adapted to learn robust control policies capable of imitating a broad range of example motion clips, while also learning complex recoveries, adapting to changes in morphology, and accomplishing user-specified goals. Our method handles keyframed motions, highly-dynamic actions such as motion-captured flips and spins, and retargeted motions. By combining a motion-imitation objective with a task objective, we can train characters that react intelligently in interactive settings, e.g., by walking in a desired direction or throwing a ball at a user-specified target. This approach thus combines the convenience and motion quality of using motion clips to define the desired style and appearance, with the flexibility and generality afforded by RL methods and physics-based animation. We further explore a number of methods for integrating multiple clips into the learning process to develop multi-skilled agents capable of performing a rich repertoire of diverse skills. We demonstrate results using multiple characters (human, Atlas robot, bipedal dinosaur, dragon) and a large variety of skills, including locomotion, acrobatics, and martial arts.",
        "countries": [
            "US",
            "CA"
        ]
    },
    "10.1145/3306346.3323026": {
        "doi": "10.1145/3306346.3323026",
        "authors": [
            {
                "family": "Preiner",
                "given": "Reinhold",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Boubekeur",
                "given": "Tamy",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Wimmer",
                "given": "Michael",
                "countries": [
                    "AT"
                ]
            }
        ],
        "title": "Gaussian-product subdivision surfaces",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2019,
        "volume": "38",
        "number": "4",
        "pages": "35:1\u201335:11",
        "article_number": "35",
        "number_of_pages": 11,
        "abstract": "Probabilistic distribution models like Gaussian mixtures have shown great potential for improving both the quality and speed of several geometric operators. This is largely due to their ability to model large fuzzy data using only a reduced set of atomic distributions, allowing for large compression rates at minimal information loss. We introduce a new surface model that utilizes these qualities of Gaussian mixtures for the definition and control of a parametric smooth surface. Our approach is based on an enriched mesh data structure, which describes the probability distribution of spatial surface locations around each vertex via a Gaussian covariance matrix. By incorporating this additional covariance information, we show how to define a smooth surface via a nonlinear probabilistic subdivision operator based on products of Gaussians, which is able to capture rich details at fixed control mesh resolution. This entails new applications in surface reconstruction, modeling, and geometric compression.",
        "countries": [
            "AT",
            "FR"
        ]
    },
    "10.1145/3355089.3356488": {
        "doi": "10.1145/3355089.3356488",
        "authors": [
            {
                "family": "Gao",
                "given": "Lin",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Yang",
                "given": "Jie",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wu",
                "given": "Tong",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Yuan",
                "given": "Yu-Jie",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Fu",
                "given": "Hongbo",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Lai",
                "given": "Yu-Kun",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Zhang",
                "given": "Hao",
                "countries": [
                    "CA"
                ]
            }
        ],
        "title": "SDM-NET: deep generative network for structured deformable mesh",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2019,
        "volume": "38",
        "number": "6",
        "pages": "243:1\u2013243:15",
        "article_number": "243",
        "number_of_pages": 15,
        "abstract": "We introduce SDM-NET, a deep generative neural network which produces structured deformable meshes. Specifically, the network is trained to generate a spatial arrangement of closed, deformable mesh parts, which respects the global part structure of a shape collection, e.g., chairs, airplanes, etc. Our key observation is that while the overall structure of a 3D shape can be complex, the shape can usually be decomposed into a set of parts, each homeomorphic to a box, and the finer-scale geometry of the part can be recovered by deforming the box. The architecture of SDM-NET is that of a two-level variational autoencoder (VAE). At the part level, a PartVAE learns a deformable model of part geometries. At the structural level, we train a Structured Parts VAE (SP-VAE), which jointly learns the part structure of a shape collection and the part geometries, ensuring the coherence between global shape structure and surface details. Through extensive experiments and comparisons with the state-of-the-art deep generative models of shapes, we demonstrate the superiority of SDM-NET in generating meshes with visual quality, flexible topology, and meaningful structures, benefiting shape interpolation and other subsequent modeling tasks.",
        "countries": [
            "CN",
            "GB",
            "CA"
        ]
    },
    "10.1145/3272127.3275028": {
        "doi": "10.1145/3272127.3275028",
        "authors": [
            {
                "family": "Gao",
                "given": "Lin",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Yang",
                "given": "Jie",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Qiao",
                "given": "Yi-Ling",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Lai",
                "given": "Yu-Kun",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Rosin",
                "given": "Paul L.",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Xu",
                "given": "Weiwei",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Xia",
                "given": "Shihong",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Automatic unpaired shape deformation transfer",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2018,
        "volume": "37",
        "number": "6",
        "pages": "237:1\u2013237:15",
        "article_number": "237",
        "number_of_pages": 15,
        "abstract": "Transferring deformation from a source shape to a target shape is a very useful technique in computer graphics. State-of-the-art deformation transfer methods require either point-wise correspondences between source and target shapes, or pairs of deformed source and target shapes with corresponding deformations. However, in most cases, such correspondences are not available and cannot be reliably established using an automatic algorithm. Therefore, substantial user effort is needed to label the correspondences or to obtain and specify such shape sets. In this work, we propose a novel approach to automatic deformation transfer between two unpaired shape sets without correspondences. 3D deformation is represented in a high-dimensional space. To obtain a more compact and effective representation, two convolutional variational autoencoders are learned to encode source and target shapes to their latent spaces. We exploit a Generative Adversarial Network (GAN) to map deformed source shapes to deformed target shapes, both in the latent spaces, which ensures the obtained shapes from the mapping are indistinguishable from the target shapes. This is still an under-constrained problem, so we further utilize a reverse mapping from target shapes to source shapes and incorporate cycle consistency loss, i.e. applying both mappings should reverse to the input shape. This VAE-Cycle GAN (VC-GAN) architecture is used to build a reliable mapping between shape spaces. Finally, a similarity constraint is employed to ensure the mapping is consistent with visual similarity, achieved by learning a similarity neural network that takes the embedding vectors from the source and target latent spaces and predicts the light field distance between the corresponding shapes. Experimental results show that our fully automatic method is able to obtain high-quality deformation transfer results with unpaired data sets, comparable or better than existing methods where strict correspondences are required.",
        "countries": [
            "CN",
            "GB"
        ]
    },
    "10.1145/3267346": {
        "doi": "10.1145/3267346",
        "authors": [
            {
                "family": "Rossignac",
                "given": "Jarek",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Corner-operated Tran-similar (COTS) Maps, Patterns, and Lattices",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2020,
        "volume": "39",
        "number": "1",
        "pages": "5:1\u20135:14",
        "article_number": "5",
        "number_of_pages": 14,
        "abstract": "The planar COTS map proposed here takes the unit square to a region R bounded by four log-spiral edges. It is Corner-operated (controlled by the four corners of R) and Tran-similar (it maps translations to similarities). The tiles of the COTS map of a regular pattern are similar to each other. It may facilitate intuitive design and algorithmic optimization of procedural models of complex, possibly multi-resolution, lattices, because it affords constant-cost algorithms for Point-in-Lattice testing and for Total-Area-Calculations. We provide simple, closed-form expressions for evaluating the COTS map and its inverse from the positions of its corners. We conjecture that the COTS map may be useful in a variety of applications in Engineering, Architecture, and Art, and we provide a few illustrative examples of its possibilities. We compare it to related, previously proposed, planar maps and discuss several variations and extensions.",
        "countries": [
            "US"
        ]
    },
    "10.1145/3306346.3323036": {
        "doi": "10.1145/3306346.3323036",
        "authors": [
            {
                "family": "Lagunas",
                "given": "Manuel",
                "countries": [
                    "ES"
                ]
            },
            {
                "family": "Malpica",
                "given": "Sandra",
                "countries": [
                    "ES"
                ]
            },
            {
                "family": "Serrano",
                "given": "Ana",
                "countries": [
                    "ES"
                ]
            },
            {
                "family": "Garces",
                "given": "Elena",
                "countries": [
                    "ES"
                ]
            },
            {
                "family": "Gutierrez",
                "given": "Diego",
                "countries": [
                    "ES"
                ]
            },
            {
                "family": "Masia",
                "given": "Belen",
                "countries": [
                    "ES"
                ]
            }
        ],
        "title": "A similarity measure for material appearance",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2019,
        "volume": "38",
        "number": "4",
        "pages": "135:1\u2013135:12",
        "article_number": "135",
        "number_of_pages": 12,
        "abstract": "We present a model to measure the similarity in appearance between different materials, which correlates with human similarity judgments. We first create a database of 9,000 rendered images depicting objects with varying materials, shape and illumination. We then gather data on perceived similarity from crowdsourced experiments; our analysis of over 114,840 answers suggests that indeed a shared perception of appearance similarity exists. We feed this data to a deep learning architecture with a novel loss function, which learns a feature space for materials that correlates with such perceived appearance similarity. Our evaluation shows that our model outperforms existing metrics. Last, we demonstrate several applications enabled by our metric, including appearance-based search for material suggestions, database visualization, clustering and summarization, and gamut mapping.",
        "countries": [
            "ES"
        ]
    },
    "10.1145/3130800.3130895": {
        "doi": "10.1145/3130800.3130895",
        "authors": [
            {
                "family": "Jiang",
                "given": "Zhongshi",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Schaefer",
                "given": "Scott",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Panozzo",
                "given": "Daniele",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Simplicial complex augmentation framework for bijective maps",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2017,
        "volume": "36",
        "number": "6",
        "pages": "186:1\u2013186:9",
        "article_number": "186",
        "number_of_pages": 9,
        "abstract": "Bijective maps are commonly used in many computer graphics and scientific computing applications, including texture, displacement, and bump mapping. However, their computation is numerically challenging due to the global nature of the problem, which makes standard smooth optimization techniques prohibitively expensive. We propose to use a scaffold structure to reduce this challenging and global problem to a local injectivity condition. This construction allows us to benefit from the recent advancements in locally injective maps optimization to efficiently compute large scale bijective maps (both in 2D and 3D), sidestepping the need to explicitly detect and avoid collisions. Our algorithm is guaranteed to robustly compute a globally bijective map, both in 2D and 3D. To demonstrate the practical applicability, we use it to compute globally bijective single patch parametrizations, to pack multiple charts into a single UV domain, to remove self-intersections from existing models, and to deform 3D objects while preventing self-intersections. Our approach is simple to implement, efficient (two orders of magnitude faster than competing methods), and robust, as we demonstrate in a stress test on a parametrization dataset with over a hundred meshes.",
        "countries": [
            "US"
        ]
    },
    "10.1145/3306346.3323011": {
        "doi": "10.1145/3306346.3323011",
        "authors": [
            {
                "family": "Hu",
                "given": "Yixin",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Schneider",
                "given": "Teseo",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Gao",
                "given": "Xifeng",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Zhou",
                "given": "Qingnan",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Jacobson",
                "given": "Alec",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Zorin",
                "given": "Denis",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Panozzo",
                "given": "Daniele",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "TriWild: robust triangulation with curve constraints",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2019,
        "volume": "38",
        "number": "4",
        "pages": "52:1\u201352:15",
        "article_number": "52",
        "number_of_pages": 15,
        "abstract": "We propose a robust 2D meshing algorithm, TriWild, to generate curved triangles reproducing smooth feature curves, leading to coarse meshes designed to match the simulation requirements necessary by applications and avoiding the geometrical errors introduced by linear meshes. The robustness and effectiveness of our technique are demonstrated by batch processing an SVG collection of 20k images, and by comparing our results against state of the art linear and curvilinear meshing algorithms. We demonstrate for our algorithm the practical utility of computing diffusion curves, fluid simulations, elastic deformations, and shape inflation on complex 2D geometries.",
        "countries": [
            "US",
            "CA"
        ]
    },
    "10.1145/3197517.3201353": {
        "doi": "10.1145/3197517.3201353",
        "authors": [
            {
                "family": "Hu",
                "given": "Yixin",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Zhou",
                "given": "Qingnan",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Gao",
                "given": "Xifeng",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Jacobson",
                "given": "Alec",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Zorin",
                "given": "Denis",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Panozzo",
                "given": "Daniele",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Tetrahedral meshing in the wild",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2018,
        "volume": "37",
        "number": "4",
        "pages": "60:1\u201360:14",
        "article_number": "60",
        "number_of_pages": 14,
        "abstract": "We propose a novel tetrahedral meshing technique that is unconditionally robust, requires no user interaction, and can directly convert a triangle soup into an analysis-ready volumetric mesh. The approach is based on several core principles: (1) initial mesh construction based on a fully robust, yet efficient, filtered exact computation (2) explicit (automatic or user-defined) tolerancing of the mesh relative to the surface input (3) iterative mesh improvement with guarantees, at every step, of the output validity. The quality of the resulting mesh is a direct function of the target mesh size and allowed tolerance: increasing allowed deviation from the initial mesh and decreasing the target edge length both lead to higher mesh quality.Our approach enables \"black-box\" analysis, i.e. it allows to automatically solve partial differential equations on geometrical models available in the wild, offering a robustness and reliability comparable to, e.g., image processing algorithms, opening the door to automatic, large scale processing of real-world geometric data.",
        "countries": [
            "US",
            "CA"
        ]
    },
    "10.1145/3313797": {
        "doi": "10.1145/3313797",
        "authors": [
            {
                "family": "Schneider",
                "given": "Teseo",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Dumas",
                "given": "J\u00e9r\u00e9mie",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Gao",
                "given": "Xifeng",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Botsch",
                "given": "Mario",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Panozzo",
                "given": "Daniele",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Zorin",
                "given": "Denis",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Poly-Spline Finite-Element Method",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2019,
        "volume": "38",
        "number": "3",
        "pages": "19:1\u201319:16",
        "article_number": "19",
        "number_of_pages": 16,
        "abstract": "We introduce an integrated meshing and finite-element method pipeline enabling solution of partial differential equations in the volume enclosed by a boundary representation. We construct a hybrid hexahedral-dominant mesh, which contains a small number of star-shaped polyhedra, and build a set of high-order bases on its elements, combining triquadratic B-splines, triquadratic hexahedra, and harmonic elements. We demonstrate that our approach converges cubically under refinement, while requiring around 50% of the degrees of freedom than a similarly dense hexahedral mesh composed of triquadratic hexahedra. We validate our approach solving Poisson\u2019s equation on a large collection of models, which are automatically processed by our algorithm, only requiring the user to provide boundary conditions on their surface.",
        "countries": [
            "US"
        ]
    },
    "10.1145/3272127.3275067": {
        "doi": "10.1145/3272127.3275067",
        "authors": [
            {
                "family": "Schneider",
                "given": "Teseo",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Hu",
                "given": "Yixin",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Dumas",
                "given": "J\u00e9r\u00e9mie",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Gao",
                "given": "Xifeng",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Panozzo",
                "given": "Daniele",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Zorin",
                "given": "Denis",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Decoupling simulation accuracy from mesh quality",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2018,
        "volume": "37",
        "number": "6",
        "pages": "280:1\u2013280:14",
        "article_number": "280",
        "number_of_pages": 14,
        "abstract": "For a given PDE problem, three main factors affect the accuracy of FEM solutions: basis order, mesh resolution, and mesh element quality. The first two factors are easy to control, while controlling element shape quality is a challenge, with fundamental limitations on what can be achieved.We propose to use p-refinement (increasing element degree) to decouple the approximation error of the finite element method from the domain mesh quality for elliptic PDEs.Our technique produces an accurate solution even on meshes with badly shaped elements, with a slightly higher running time due to the higher cost of high-order elements. We demonstrate that it is able to automatically adapt the basis to badly shaped elements, ensuring an error consistent with high-quality meshing, without any per-mesh parameter tuning. Our construction reduces to traditional fixed-degree FEM methods on high-quality meshes with identical performance.Our construction decreases the burden on meshing algorithms, reducing the need for often expensive mesh optimization and automatically compensates for badly shaped elements, which are present due to boundary constraints or limitations of current meshing methods. By tackling mesh generation and finite element simulation jointly, we obtain a pipeline that is both more efficient and more robust than combinations of existing state of the art meshing and FEM algorithms.",
        "countries": [
            "US"
        ]
    },
    "10.1145/3306346.3322999": {
        "doi": "10.1145/3306346.3322999",
        "authors": [
            {
                "family": "Aberman",
                "given": "Kfir",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Wu",
                "given": "Rundi",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Lischinski",
                "given": "Dani",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Chen",
                "given": "Baoquan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Cohen-Or",
                "given": "Daniel",
                "countries": [
                    "IL"
                ]
            }
        ],
        "title": "Learning character-agnostic motion for motion retargeting in 2D",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2019,
        "volume": "38",
        "number": "4",
        "pages": "75:1\u201375:14",
        "article_number": "75",
        "number_of_pages": 14,
        "abstract": "Analyzing human motion is a challenging task with a wide variety of applications in computer vision and in graphics. One such application, of particular importance in computer animation, is the retargeting of motion from one performer to another. While humans move in three dimensions, the vast majority of human motions are captured using video, requiring 2D-to-3D pose and camera recovery, before existing retargeting approaches may be applied. In this paper, we present a new method for retargeting video-captured motion between different human performers, without the need to explicitly reconstruct 3D poses and/or camera parameters.In order to achieve our goal, we learn to extract, directly from a video, a high-level latent motion representation, which is invariant to the skeleton geometry and the camera view. Our key idea is to train a deep neural network to decompose temporal sequences of 2D poses into three components: motion, skeleton, and camera view-angle. Having extracted such a representation, we are able to re-combine motion with novel skeletons and camera views, and decode a retargeted temporal sequence, which we compare to a ground truth from a synthetic dataset.We demonstrate that our framework can be used to robustly extract human motion from videos, bypassing 3D reconstruction, and outperforming existing retargeting methods, when applied to videos in-the-wild. It also enables additional applications, such as performance cloning, video-driven cartoons, and motion retrieval.",
        "countries": [
            "IL",
            "CN"
        ]
    },
    "10.1145/3272127.3275053": {
        "doi": "10.1145/3272127.3275053",
        "authors": [
            {
                "family": "Guo",
                "given": "Yu",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Ha\u0161an",
                "given": "Milo\u0161",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Zhao",
                "given": "Shuang",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Position-free monte carlo simulation for arbitrary layered BSDFs",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2018,
        "volume": "37",
        "number": "6",
        "pages": "279:1\u2013279:14",
        "article_number": "279",
        "number_of_pages": 14,
        "abstract": "Real-world materials are often layered: metallic paints, biological tissues, and many more. Variation in the interface and volumetric scattering properties of the layers leads to a rich diversity of material appearances from anisotropic highlights to complex textures and relief patterns. However, simulating light-layer interactions is a challenging problem. Past analytical or numerical solutions either introduce several approximations and limitations, or rely on expensive operations on discretized BSDFs, preventing the ability to freely vary the layer properties spatially. We introduce a new unbiased layered BSDF model based on Monte Carlo simulation, whose only assumption is the layer assumption itself. Our novel position-free path formulation is fundamentally more powerful at constructing light transport paths than generic light transport algorithms applied to the special case of flat layers, since it is based on a product of solid angle instead of area measures, so does not contain the high-variance geometry terms needed in the standard formulation. We introduce two techniques for sampling the position-free path integral, a forward path tracer with next-event estimation and a full bidirectional estimator. We show a number of examples, featuring multiple layers with surface and volumetric scattering, surface and phase function anisotropy, and spatial variation in all parameters.",
        "countries": [
            "US"
        ]
    },
    "10.1145/3306346.3322955": {
        "doi": "10.1145/3306346.3322955",
        "authors": [
            {
                "family": "P\u00e9rard-Gayot",
                "given": "Ars\u00e8ne",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Membarth",
                "given": "Richard",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Lei\u00dfa",
                "given": "Roland",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Hack",
                "given": "Sebastian",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Slusallek",
                "given": "Philipp",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Rodent: generating renderers without writing a generator",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2019,
        "volume": "38",
        "number": "4",
        "pages": "40:1\u201340:12",
        "article_number": "40",
        "number_of_pages": 12,
        "abstract": "Monte-Carlo Renderers must generate many color samples to produce a noise-free image, and for each of those, they must evaluate complex mathematical models representing the appearance of the objects in the scene. These models are usually in the form of shaders: Small programs that are executed during rendering in order to compute a value for the current sample.Renderers often compile and optimize shaders just before rendering, taking advantage of the knowledge of the scene. In principle, the entire renderer could benefit from a-priori code generation. For instance, scheduling can take advantage of the knowledge of the scene in order to maximize hardware usage. However, writing such a configurable renderer eventually means writing a compiler that translates a scene description into machine code.In this paper, we present a framework that allows generating entire renderers for CPUs and GPUs without having to write a dedicated compiler: First, we provide a rendering library in a functional/imperative language that elegantly abstracts the individual rendering concepts using higher-order functions. Second, we use partial evaluation to combine and specialize the individual components of a renderer according to a particular scene.Our results show that the renderers we generate outperform equivalent high-performance implementations written with state-of-the-art ray tracing libraries on the CPU and GPU.",
        "countries": [
            "DE"
        ]
    },
    "10.1145/3306346.3322994": {
        "doi": "10.1145/3306346.3322994",
        "authors": [
            {
                "family": "Huang",
                "given": "Zhiyang",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Carr",
                "given": "Nathan",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Ju",
                "given": "Tao",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Variational implicit point set surfaces",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2019,
        "volume": "38",
        "number": "4",
        "pages": "124:1\u2013124:13",
        "article_number": "124",
        "number_of_pages": 13,
        "abstract": "We propose a new method for reconstructing an implicit surface from an un-oriented point set. While existing methods often involve non-trivial heuristics and require additional constraints, such as normals or labelled points, we introduce a direct definition of the function from the points as the solution to a constrained quadratic optimization problem. The definition has a number of appealing features: it uses a single parameter (parameter-free for exact interpolation), applies to any dimensions, commutes with similarity transformations, and can be easily implemented without discretizing the space. More importantly, the use of a global smoothness energy allows our definition to be much more resilient to sampling imperfections than existing methods, making it particularly suited for sparse and non-uniform inputs.",
        "countries": [
            "US"
        ]
    },
    "10.1145/3306346.3322959": {
        "doi": "10.1145/3306346.3322959",
        "authors": [
            {
                "family": "Hanocka",
                "given": "Rana",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Hertz",
                "given": "Amir",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Fish",
                "given": "Noa",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Giryes",
                "given": "Raja",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Fleishman",
                "given": "Shachar",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Cohen-Or",
                "given": "Daniel",
                "countries": [
                    "IL"
                ]
            }
        ],
        "title": "MeshCNN: a network with an edge",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2019,
        "volume": "38",
        "number": "4",
        "pages": "90:1\u201390:12",
        "article_number": "90",
        "number_of_pages": 12,
        "abstract": "Polygonal meshes provide an efficient representation for 3D shapes. They explicitly captureboth shape surface and topology, and leverage non-uniformity to represent large flat regions as well as sharp, intricate features. This non-uniformity and irregularity, however, inhibits mesh analysis efforts using neural networks that combine convolution and pooling operations. In this paper, we utilize the unique properties of the mesh for a direct analysis of 3D shapes using MeshCNN, a convolutional neural network designed specifically for triangular meshes. Analogous to classic CNNs, MeshCNN combines specialized convolution and pooling layers that operate on the mesh edges, by leveraging their intrinsic geodesic connections. Convolutions are applied on edges and the four edges of their incident triangles, and pooling is applied via an edge collapse operation that retains surface topology, thereby, generating new mesh connectivity for the subsequent convolutions. MeshCNN learns which edges to collapse, thus forming a task-driven process where the network exposes and expands the important features while discarding the redundant ones. We demonstrate the effectiveness of MeshCNN on various learning tasks applied to 3D meshes.",
        "countries": [
            "IL"
        ]
    },
    "10.1145/3306346.3322962": {
        "doi": "10.1145/3306346.3322962",
        "authors": [
            {
                "family": "Padilla",
                "given": "Marcel",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Chern",
                "given": "Albert",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Kn\u00f6ppel",
                "given": "Felix",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Pinkall",
                "given": "Ulrich",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Schr\u00f6der",
                "given": "Peter",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "On bubble rings and ink chandeliers",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2019,
        "volume": "38",
        "number": "4",
        "pages": "129:1\u2013129:14",
        "article_number": "129",
        "number_of_pages": 14,
        "abstract": "We introduce variable thickness, viscous vortex filaments. These can model such varied phenomena as underwater bubble rings or the intricate \"chandeliers\" formed by ink dropping into fluid. Treating the evolution of such filaments as an instance of Newtonian dynamics on a Riemannian configuration manifold we are able to extend classical work in the dynamics of vortex filaments through inclusion of viscous drag forces. The latter must be accounted for in low Reynolds number flows where they lead to significant variations in filament thickness and form an essential part of the observed dynamics. We develop and document both the underlying theory and associated practical numerical algorithms.",
        "countries": [
            "DE",
            "US"
        ]
    },
    "10.1145/3197517.3201308": {
        "doi": "10.1145/3197517.3201308",
        "authors": [
            {
                "family": "Li",
                "given": "Jie",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Daviet",
                "given": "Gilles",
                "countries": [
                    "FR",
                    "NZ"
                ]
            },
            {
                "family": "Narain",
                "given": "Rahul",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Bertails-Descoubes",
                "given": "Florence",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Overby",
                "given": "Matthew",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Brown",
                "given": "George E.",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Boissieux",
                "given": "Laurence",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "An implicit frictional contact solver for adaptive cloth simulation",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2018,
        "volume": "37",
        "number": "4",
        "pages": "52:1\u201352:15",
        "article_number": "52",
        "number_of_pages": 15,
        "abstract": "Cloth dynamics plays an important role in the visual appearance of moving characters. Properly accounting for contact and friction is of utmost importance to avoid cloth-body and cloth-cloth penetration and to capture typical folding and stick-slip behavior due to dry friction. We present here the first method able to account for cloth contact with exact Coulomb friction, treating both cloth self-contacts and contacts occurring between the cloth and an underlying character. Our key contribution is to observe that for a nodal system like cloth, the frictional contact problem may be formulated based on velocities as primary variables, without having to compute the costly Delassus operator. Then, by reversing the roles classically played by the velocities and the contact impulses, conical complementarity solvers of the literature can be adapted to solve for compatible velocities at nodes. To handle the full complexity of cloth dynamics scenarios, we have extended this base algorithm in two ways: first, towards the accurate treatment of frictional contact at any location of the cloth, through an adaptive node refinement strategy; second, towards the handling of multiple constraints at each node, through the duplication of constrained nodes and the adding of pin constraints between duplicata. Our method allows us to handle the complex cloth-cloth and cloth-body interactions in full-size garments with an unprecedented level of realism compared to former methods, while maintaining reasonable computational timings.",
        "countries": [
            "US",
            "FR",
            "NZ",
            "IN"
        ]
    },
    "10.1145/3197517.3201397": {
        "doi": "10.1145/3197517.3201397",
        "authors": [
            {
                "family": "Yu",
                "given": "Wenhao",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Turk",
                "given": "Greg",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Liu",
                "given": "C. Karen",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Learning symmetric and low-energy locomotion",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2018,
        "volume": "37",
        "number": "4",
        "pages": "144:1\u2013144:12",
        "article_number": "144",
        "number_of_pages": 12,
        "abstract": "Learning locomotion skills is a challenging problem. To generate realistic and smooth locomotion, existing methods use motion capture, finite state machines or morphology-specific knowledge to guide the motion generation algorithms. Deep reinforcement learning (DRL) is a promising approach for the automatic creation of locomotion control. Indeed, a standard benchmark for DRL is to automatically create a running controller for a biped character from a simple reward function [Duan et al. 2016]. Although several different DRL algorithms can successfully create a running controller, the resulting motions usually look nothing like a real runner. This paper takes a minimalist learning approach to the locomotion problem, without the use of motion examples, finite state machines, or morphology-specific knowledge. We introduce two modifications to the DRL approach that, when used together, produce locomotion behaviors that are symmetric, low-energy, and much closer to that of a real person. First, we introduce a new term to the loss function (not the reward function) that encourages symmetric actions. Second, we introduce a new curriculum learning method that provides modulated physical assistance to help the character with left/right balance and forward movement. The algorithm automatically computes appropriate assistance to the character and gradually relaxes this assistance, so that eventually the character learns to move entirely without help. Because our method does not make use of motion capture data, it can be applied to a variety of character morphologies. We demonstrate locomotion controllers for the lower half of a biped, a full humanoid, a quadruped, and a hexapod. Our results show that learned policies are able to produce symmetric, low-energy gaits. In addition, speed-appropriate gait patterns emerge without any guidance from motion examples or contact planning.",
        "countries": [
            "US"
        ]
    },
    "10.1145/3197517.3201331": {
        "doi": "10.1145/3197517.3201331",
        "authors": [
            {
                "family": "Liu",
                "given": "Ligang",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Ye",
                "given": "Chunyang",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Ni",
                "given": "Ruiqi",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Fu",
                "given": "Xiao-Ming",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Progressive parameterizations",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2018,
        "volume": "37",
        "number": "4",
        "pages": "41:1\u201341:12",
        "article_number": "41",
        "number_of_pages": 12,
        "abstract": "We propose a novel approach, called Progressive Parameterizations, to compute foldover-free parameterizations with low isometric distortion on disk topology meshes. Instead of using the input mesh as a reference to define the objective function, we introduce a progressive reference that contains bounded distortion to the parameterized mesh and is as close as possible to the input mesh. After optimizing the bounded distortion energy between the progressive reference and the parameterized mesh, the parameterized mesh easily approaches the progressive reference, thereby also coming close to the input. By iteratively generating the progressive reference and optimizing the bounded distortion energy to update the parameterized mesh, our algorithm achieves high-quality parameterizations with strong practical reliability and high efficiency. We have demonstrated that our algorithm succeeds on a massive test data set containing over 20712 complex disk topology meshes. Compared to the state-of-the-art methods, our method has achieved higher computational efficiency and practical reliability.",
        "countries": [
            "CN"
        ]
    },
    "10.1145/3132703": {
        "doi": "10.1145/3132703",
        "authors": [
            {
                "family": "Simo-Serra",
                "given": "Edgar",
                "countries": [
                    "JP"
                ]
            },
            {
                "family": "Iizuka",
                "given": "Satoshi",
                "countries": [
                    "JP"
                ]
            },
            {
                "family": "Ishikawa",
                "given": "Hiroshi",
                "countries": [
                    "JP"
                ]
            }
        ],
        "title": "Mastering Sketching: Adversarial Augmentation for Structured Prediction",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2018,
        "volume": "37",
        "number": "1",
        "pages": "11:1\u201311:13",
        "article_number": "11",
        "number_of_pages": 13,
        "abstract": "We present an integral framework for training sketch simplification networks that convert challenging rough sketches into clean line drawings. Our approach augments a simplification network with a discriminator network, training both networks jointly so that the discriminator network discerns whether a line drawing is real training data or the output of the simplification network, which, in turn, tries to fool it. This approach has two major advantages: first, because the discriminator network learns the structure in line drawings, it encourages the output sketches of the simplification network to be more similar in appearance to the training sketches. Second, we can also train the networks with additional unsupervised data: by adding rough sketches and line drawings that are not corresponding to each other, we can improve the quality of the sketch simplification. Thanks to a difference in the architecture, our approach has advantages over similar adversarial training approaches in stability of training and the aforementioned ability to utilize unsupervised training data. We show how our framework can be used to train models that significantly outperform the state of the art in the sketch simplification task, despite using the same architecture for inference. We also present an approach to optimize for a single image, which improves accuracy at the cost of additional computation time. Finally, we show that, using the same framework, it is possible to train the network to perform the inverse problem, i.e., convert simple line sketches into pencil drawings, which is not possible using the standard mean squared error loss. We validate our framework with two user tests, in which our approach is preferred to the state of the art in sketch simplification 88.9% of the time.",
        "countries": [
            "JP"
        ]
    },
    "10.1145/3072959.3073628": {
        "doi": "10.1145/3072959.3073628",
        "authors": [
            {
                "family": "Larionov",
                "given": "Egor",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Batty",
                "given": "Christopher",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Bridson",
                "given": "Robert",
                "countries": [
                    "CA"
                ]
            }
        ],
        "title": "Variational stokes: a unified pressure-viscosity solver for accurate viscous liquids",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2017,
        "volume": "36",
        "number": "4",
        "pages": "101:1\u2013101:11",
        "article_number": "101",
        "number_of_pages": 11,
        "abstract": "We propose a novel unsteady Stokes solver for coupled viscous and pressure forces in grid-based liquid animation which yields greater accuracy and visual realism than previously achieved. Modern fluid simulators treat viscosity and pressure in separate solver stages, which reduces accuracy and yields incorrect free surface behavior. Our proposed implicit variational formulation of the Stokes problem leads to a symmetric positive definite linear system that gives properly coupled forces, provides unconditional stability, and treats difficult boundary conditions naturally through simple volume weights. Surface tension and moving solid boundaries are also easily incorporated. Qualitatively, we show that our method recovers the characteristic rope coiling instability of viscous liquids and preserves fine surface details, while previous grid-based schemes do not. Quantitatively, we demonstrate that our method is convergent through grid refinement studies on analytical problems in two dimensions. We conclude by offering practical guidelines for choosing an appropriate viscous solver, based on the scenario to be animated and the computational costs of different methods.",
        "countries": [
            "CA"
        ]
    },
    "10.1145/3136954": {
        "doi": "10.1145/3136954",
        "authors": [
            {
                "family": "Kar\u010diauskas",
                "given": "K\u0229stutis",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Panozzo",
                "given": "Daniele",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Peters",
                "given": "J\u00f6rg",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "T-junctions in Spline Surfaces",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2017,
        "volume": "36",
        "number": "5",
        "pages": "170:1\u2013170:9",
        "article_number": "170",
        "number_of_pages": 9,
        "abstract": "T-junctions occur where surface strips start or terminate. This paper develops a new way to create smooth piecewise polynomial free-form spline surfaces from quad-meshes that include T-junctions. All mesh nodes are interpreted as control points of GT-splines, that is, geometrically smoothly joined piecewise polynomials. GT-splines are akin to and compatible with B-splines and cover simple T-junctions by two polynomial pieces of degree bi-4 and more complex ones by four such patches. They complement multi-sided surface constructions in generating free-form surfaces with adaptive layout.Since GT-splines do not require a global coordination of knot intervals, GT-constructions are easy to deploy and can provide smooth surfaces with T-junctions where T-splines cannot have a smooth parameterization. GT-constructions display a uniform highlight linedistribution on input meshes where alternatives, such as Catmull-Clark subdivision, exhibit oscillations.",
        "countries": [
            "US"
        ]
    },
    "10.1145/3182158": {
        "doi": "10.1145/3182158",
        "authors": [
            {
                "family": "Yu",
                "given": "Fenggen",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhang",
                "given": "Yan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Xu",
                "given": "Kai",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Mahdavi-Amiri",
                "given": "Ali",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Zhang",
                "given": "Hao",
                "countries": [
                    "CA"
                ]
            }
        ],
        "title": "Semi-Supervised Co-Analysis of 3D Shape Styles from Projected Lines",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2018,
        "volume": "37",
        "number": "2",
        "pages": "21:1\u201321:17",
        "article_number": "21",
        "number_of_pages": 17,
        "abstract": "We present a semi-supervised co-analysis method for learning 3D shape styles from projected feature lines, achieving style patch localization with only weak supervision. Given a collection of 3D shapes spanning multiple object categories and styles, we perform style co-analysis over projected feature lines of each 3D shape and then back-project the learned style features onto the 3D shapes. Our core analysis pipeline starts with mid-level patch sampling and pre-selection of candidate style patches. Projective features are then encoded via patch convolution. Multi-view feature integration and style clustering are carried out under the framework of partially shared latent factor (PSLF) learning, a multi-view feature learning scheme. PSLF achieves effective multi-view feature fusion by distilling and exploiting consistent and complementary feature information from multiple views, while also selecting style patches from the candidates. Our style analysis approach supports both unsupervised and semi-supervised analysis. For the latter, our method accepts both user-specified shape labels and style-ranked triplets as clustering constraints. We demonstrate results from 3D shape style analysis and patch localization as well as improvements over state-of-the-art methods. We also present several applications enabled by our style analysis.",
        "countries": [
            "CN",
            "CA"
        ]
    },
    "10.1145/3072959.3073630": {
        "doi": "10.1145/3072959.3073630",
        "authors": [
            {
                "family": "Fei",
                "given": "Yun (Raymond)",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Maia",
                "given": "Henrique Teles",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Batty",
                "given": "Christopher",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Zheng",
                "given": "Changxi",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Grinspun",
                "given": "Eitan",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "A multi-scale model for simulating liquid-hair interactions",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2017,
        "volume": "36",
        "number": "4",
        "pages": "56:1\u201356:17",
        "article_number": "56",
        "number_of_pages": 17,
        "abstract": "The diverse interactions between hair and liquid are complex and span multiple length scales, yet are central to the appearance of humans and animals in many situations. We therefore propose a novel multi-component simulation framework that treats many of the key physical mechanisms governing the dynamics of wet hair. The foundations of our approach are a discrete rod model for hair and a particle-in-cell model for fluids. To treat the thin layer of liquid that clings to the hair, we augment each hair strand with a height field representation. Our contribution is to develop the necessary physical and numerical models to evolve this new system and the interactions among its components. We develop a new reduced-dimensional liquid model to solve the motion of the liquid along the length of each hair, while accounting for its moving reference frame and influence on the hair dynamics. We derive a faithful model for surface tension-induced cohesion effects between adjacent hairs, based on the geometry of the liquid bridges that connect them. We adopt an empirically-validated drag model to treat the effects of coarse-scale interactions between hair and surrounding fluid, and propose new volume-conserving dripping and absorption strategies to transfer liquid between the reduced and particle-in-cell liquid representations. The synthesis of these techniques yields an effective wet hair simulator, which we use to animate hair flipping, an animal shaking itself dry, a spinning car wash roller brush dunked in liquid, and intricate hair coalescence effects, among several additional scenarios.",
        "countries": [
            "CA"
        ]
    },
    "10.1145/2956233": {
        "doi": "10.1145/2956233",
        "authors": [
            {
                "family": "Thuerey",
                "given": "Nils",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Interpolations of Smoke and Liquid Simulations",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2017,
        "volume": "36",
        "number": "1",
        "pages": "3:1\u20133:16",
        "article_number": "3",
        "number_of_pages": 16,
        "abstract": "We present a novel method to interpolate smoke and liquid simulations in order to perform data-driven fluid simulations. Our approach calculates a dense space-time deformation using grid-based signed-distance functions of the inputs.A key advantage of this implicit Eulerian representation is that it allows us to use powerful techniques from the optical flow area. We employ a five-dimensional optical flow solve. In combination with a projection algorithm, and residual iterations, we achieve a robust matching of the inputs. Once the match is computed, arbitrary in-between variants can be created very efficiently. To concatenate multiple long-range deformations, we propose a novel alignment technique.Our approach has numerous advantages, including automatic matches without user input, volumetric deformations that can be applied to details around the surface, and the inherent handling of topology changes. As a result, we can interpolate swirling smoke clouds, and splashing liquid simulations. We can even match and interpolate phenomena with fundamentally different physics: a drop of liquid, and a blob of heavy smoke.",
        "countries": [
            "DE"
        ]
    },
    "10.1109/tvcg.2023.3341453": {
        "doi": "10.1109/tvcg.2023.3341453",
        "authors": [
            {
                "family": "Li",
                "given": "Chunlei",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Gao",
                "given": "Yang",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "He",
                "given": "Jiayi",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Cheng",
                "given": "Tianwei",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Li",
                "given": "Shuai",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Hao",
                "given": "Aimin",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Qin",
                "given": "Hong",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "A Unified Particle-Based Solver for Non-Newtonian Behaviors Simulation",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "4",
        "pages": "1998\u20132010",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "In this article, we present a unified framework to simulate non-Newtonian behaviors. We combine viscous and elasto-plastic stress into a unified particle solver to achieve various non-Newtonian behaviors ranging from fluid-like to solid-like. Our constitutive model is based on a Generalized Maxwell model, which incorporates viscosity, elasticity and plasticity in one non-linear framework by a unified way. On the one hand, taking advantage of the viscous term, we construct a series of strain-rate dependent models for classical non-Newtonian behaviors such as shear-thickening, shear-thinning, Bingham plastic, etc. On the other hand, benefiting from the elasto-plastic model, we empower our framework with the ability to simulate solid-like non-Newtonian behaviors, i.e., visco-elasticity/plasticity. In addition, we enrich our method with a heat diffusion model to make our method flexible in simulating phase change. Through sufficient experiments, we demonstrate a wide range of non-Newtonian behaviors ranging from viscous fluid to deformable objects. We believe this non-Newtonian model will enhance the realism of physically-based animation, which has great potential for computer graphics.",
        "countries": [
            "CN",
            "US"
        ]
    },
    "10.1109/tvcg.2023.3341990": {
        "doi": "10.1109/tvcg.2023.3341990",
        "authors": [
            {
                "family": "Yao",
                "given": "Lijie",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Vuillemot",
                "given": "Romain",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Bezerianos",
                "given": "Anastasia",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Isenberg",
                "given": "Petra",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Designing for Visualization in Motion: Embedding Visualizations in Swimming Videos",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "3",
        "pages": "1821\u20131836",
        "article_number": "",
        "number_of_pages": 16,
        "abstract": "We report on challenges and considerations for supporting design processes for visualizations in motion embedded in sports videos. We derive our insights from analyzing swimming race visualizations and motion-related data, building a technology probe, as well as a study with designers. Understanding how to design situated visualizations in motion is important for a variety of contexts. Competitive sports coverage, in particular, increasingly includes information on athlete or team statistics and records. Although moving visual representations attached to athletes or other targets are starting to appear, systematic investigations on how to best support their design process in the context of sports videos are still missing. Our work makes several contributions in identifying opportunities for visualizations to be added to swimming competition coverage but, most importantly, in identifying requirements and challenges for designing situated visualizations in motion. Our investigations include the analysis of a survey with swimming enthusiasts on their motion-related information needs, an ideation workshop to collect designs and elicit design challenges, the design of a technology probe that allows to create embedded visualizations in motion based on real data (Fig. 1), and an evaluation with visualization designers that aimed to understand the benefits of designing directly on videos.",
        "countries": [
            "FR"
        ]
    },
    "10.1109/tvcg.2023.3337642": {
        "doi": "10.1109/tvcg.2023.3337642",
        "authors": [
            {
                "family": "Sch\u00e4fer",
                "given": "Marco",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Brich",
                "given": "Nicolas",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "By\u0161ka",
                "given": "Jan",
                "countries": [
                    "CZ"
                ]
            },
            {
                "family": "Marques",
                "given": "S\u00e9rgio M.",
                "countries": [
                    "CZ"
                ]
            },
            {
                "family": "Bedn\u00e1\u0159",
                "given": "David",
                "countries": [
                    "CZ"
                ]
            },
            {
                "family": "Thiel",
                "given": "Philipp",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Kozl\u00edkov\u00e1",
                "given": "Barbora",
                "countries": [
                    "CZ"
                ]
            },
            {
                "family": "Krone",
                "given": "Michael",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "InVADo: Interactive Visual Analysis of Molecular Docking Data",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "4",
        "pages": "1984\u20131997",
        "article_number": "",
        "number_of_pages": 14,
        "abstract": "Molecular docking is a key technique in various fields like structural biology, medicinal chemistry, and biotechnology. It is widely used for virtual screening during drug discovery, computer-assisted drug design, and protein engineering. A general molecular docking process consists of the target and ligand selection, their preparation, and the docking process itself, followed by the evaluation of the results. However, the most commonly used docking software provides no or very basic evaluation possibilities. Scripting and external molecular viewers are often used, which are not designed for an efficient analysis of docking results. Therefore, we developed InVADo, a comprehensive interactive visual analysis tool for large docking data. It consists of multiple linked 2D and 3D views. It filters and spatially clusters the data, and enriches it with post-docking analysis results of protein-ligand interactions and functional groups, to enable well-founded decision-making. In an exemplary case study, domain experts confirmed that InVADo facilitates and accelerates the analysis workflow. They rated it as a convenient, comprehensive, and feature-rich tool, especially useful for virtual screening.",
        "countries": [
            "DE",
            "CZ"
        ]
    },
    "10.1109/tvcg.2023.3345340": {
        "doi": "10.1109/tvcg.2023.3345340",
        "authors": [
            {
                "family": "Yang",
                "given": "Weikai",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Guo",
                "given": "Yukai",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wu",
                "given": "Jing",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Wang",
                "given": "Zheng",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Guo",
                "given": "Lan-Zhe",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Li",
                "given": "Yu-Feng",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Liu",
                "given": "Shixia",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Interactive Reweighting for Mitigating Label Quality Issues",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "3",
        "pages": "1837\u20131852",
        "article_number": "",
        "number_of_pages": 16,
        "abstract": "Label quality issues, such as noisy labels and imbalanced class distributions, have negative effects on model performance. Automatic reweighting methods identify problematic samples with label quality issues by recognizing their negative effects on validation samples and assigning lower weights to them. However, these methods fail to achieve satisfactory performance when the validation samples are of low quality. To tackle this, we develop Reweighter, a visual analysis tool for sample reweighting. The reweighting relationships between validation samples and training samples are modeled as a bipartite graph. Based on this graph, a validation sample improvement method is developed to improve the quality of validation samples. Since the automatic improvement may not always be perfect, a co-cluster-based bipartite graph visualization is developed to illustrate the reweighting relationships and support the interactive adjustments to validation samples and reweighting results. The adjustments are converted into the constraints of the validation sample improvement method to further improve validation samples. We demonstrate the effectiveness of Reweighter in improving reweighting results through quantitative evaluation and two case studies.",
        "countries": [
            "CN",
            "GB"
        ]
    },
    "10.1109/tvcg.2023.3302308": {
        "doi": "10.1109/tvcg.2023.3302308",
        "authors": [
            {
                "family": "Hong",
                "given": "Jiayi",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Maciejewski",
                "given": "Ross",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Trubuil",
                "given": "Alain",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Isenberg",
                "given": "Tobias",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Visualizing and Comparing Machine Learning Predictions to Improve Human-AI Teaming on the Example of Cell Lineage",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "4",
        "pages": "1956\u20131969",
        "article_number": "",
        "number_of_pages": 14,
        "abstract": "We visualize the predictions of multiple machine learning models to help biologists as they interactively make decisions about cell lineage\u2014the development of a (plant) embryo from a single ovum cell. Based on a confocal microscopy dataset, traditionally biologists manually constructed the cell lineage, starting from this observation and reasoning backward in time to establish their inheritance. To speed up this tedious process, we make use of machine learning (ML) models trained on a database of manually established cell lineages to assist the biologist in cell assignment. Most biologists, however, are not familiar with ML, nor is it clear to them which model best predicts the embryo's development. We thus have developed a visualization system that is designed to support biologists in exploring and comparing ML models, checking the model predictions, detecting possible ML model mistakes, and deciding on the most likely embryo development. To evaluate our proposed system, we deployed our interface with six biologists in an observational study. Our results show that the visual representations of machine learning are easily understandable, and our tool, LineageD+, could potentially increase biologists\u2019 working efficiency and enhance the understanding of embryos.",
        "countries": [
            "FR",
            "US"
        ]
    },
    "10.1109/tvcg.2023.3326941": {
        "doi": "10.1109/tvcg.2023.3326941",
        "authors": [
            {
                "family": "He",
                "given": "Tingying",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Zhong",
                "given": "Yuanyang",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Isenberg",
                "given": "Petra",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Isenberg",
                "given": "Tobias",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Design Characterization for Black-and-White Textures in Visualization",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "1",
        "pages": "1019\u20131029",
        "article_number": "",
        "number_of_pages": 11,
        "abstract": "We investigate the use of 2D black-and-white textures for the visualization of categorical data and contribute a summary of texture attributes, and the results of three experiments that elicited design strategies as well as aesthetic and effectiveness measures. Black-and-white textures are useful, for instance, as a visual channel for categorical data on low-color displays, in 2D/3D print, to achieve the aesthetic of historic visualizations, or to retain the color hue channel for other visual mappings. We specifically study how to use what we call geometric and iconic textures. Geometric textures use patterns of repeated abstract geometric shapes, while iconic textures use repeated icons that may stand for data categories. We parameterized both types of textures and developed a tool for designers to create textures on simple charts by adjusting texture parameters. 30 visualization experts used our tool and designed 66 textured bar charts, pie charts, and maps. We then had 150 participants rate these designs for aesthetics. Finally, with the top-rated geometric and iconic textures, our perceptual assessment experiment with 150 participants revealed that textured charts perform about equally well as non-textured charts, and that there are some differences depending on the type of chart.",
        "countries": [
            "FR"
        ]
    },
    "10.1109/tvcg.2023.3330262": {
        "doi": "10.1109/tvcg.2023.3330262",
        "authors": [
            {
                "family": "Sisouk",
                "given": "Keanu",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Delon",
                "given": "Julie",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Tierny",
                "given": "Julien",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Wasserstein Dictionaries of Persistence Diagrams",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "2",
        "pages": "1638\u20131651",
        "article_number": "",
        "number_of_pages": 14,
        "abstract": "This article presents a computational framework for the concise encoding of an ensemble of persistence diagrams, in the form of weighted Wasserstein barycenters Turner et al. (2014), Vidal et al. (2020) of a dictionary of atom diagrams. We introduce a multi-scale gradient descent approach for the efficient resolution of the corresponding minimization problem, which interleaves the optimization of the barycenter weights with the optimization of the atom diagrams. Our approach leverages the analytic expressions for the gradient of both sub-problems to ensure fast iterations and it additionally exploits shared-memory parallelism. Extensive experiments on public ensembles demonstrate the efficiency of our approach, with Wasserstein dictionary computations in the orders of minutes for the largest examples. We show the utility of our contributions in two applications. First, we apply Wassserstein dictionaries to data reduction and reliably compress persistence diagrams by concisely representing them with their weights in the dictionary. Second, we present a dimensionality reduction framework based on a Wasserstein dictionary defined with a small number of atoms (typically three) and encode the dictionary as a low dimensional simplex embedded in a visual space (typically in 2D). In both applications, quantitative experiments assess the relevance of our framework. Finally, we provide a C++ implementation that can be used to reproduce our results.",
        "countries": [
            "FR"
        ]
    },
    "10.1109/tvcg.2023.3323150": {
        "doi": "10.1109/tvcg.2023.3323150",
        "authors": [
            {
                "family": "Le\u00f3n",
                "given": "Gabriela Molina",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Isenberg",
                "given": "Petra",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Breiter",
                "given": "Andreas",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Eliciting Multimodal and Collaborative Interactions for Data Exploration on Large Vertical Displays",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "2",
        "pages": "1624\u20131637",
        "article_number": "",
        "number_of_pages": 14,
        "abstract": "We examined user preferences to combine multiple interaction modalities for collaborative interaction with data shown on large vertical displays. Large vertical displays facilitate visual data exploration and allow the use of diverse interaction modalities by multiple users at different distances from the screen. Yet, how to offer multiple interaction modalities is a non-trivial problem. We conducted an elicitation study with 20 participants that generated 1015 interaction proposals combining touch, speech, pen, and mid-air gestures. Given the opportunity to interact using these four modalities, participants preferred speech interaction in 10 of 15 low-level tasks and direct manipulation for straightforward tasks such as showing a tooltip or selecting. In contrast to previous work, participants most favored unimodal and personal interactions. We identified what we call collaborative synonyms among their interaction proposals and found that pairs of users collaborated either unimodally and simultaneously or multimodally and sequentially. We provide insights into how end-users associate visual exploration tasks with certain modalities and how they collaborate at different interaction distances using specific interaction modalities.1",
        "countries": [
            "DE",
            "FR"
        ]
    },
    "10.1109/tvcg.2023.3322372": {
        "doi": "10.1109/tvcg.2023.3322372",
        "authors": [
            {
                "family": "Lei",
                "given": "Fan",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Fan",
                "given": "Arlen",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "MacEachren",
                "given": "Alan M.",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Maciejewski",
                "given": "Ross",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "GeoLinter: A Linting Framework for Choropleth Maps",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "2",
        "pages": "1592\u20131607",
        "article_number": "",
        "number_of_pages": 16,
        "abstract": "Visualization linting is a proven effective tool in assisting users to follow established visualization guidelines. Despite its success, visualization linting for choropleth maps, one of the most popular visualizations on the internet, has yet to be investigated. In this paper, we present GeoLinter, a linting framework for choropleth maps that assists in creating accurate and robust maps. Based on a set of design guidelines and metrics drawing upon a collection of best practices from the cartographic literature, GeoLinter detects potentially suboptimal design decisions and provides further recommendations on design improvement with explanations at each step of the design process. We perform a validation study to evaluate the proposed framework's functionality with respect to identifying and fixing errors and apply its results to improve the robustness of GeoLinter. Finally, we demonstrate the effectiveness of the GeoLinter - validated through empirical studies - by applying it to a series of case studies using real-world datasets.",
        "countries": [
            "US"
        ]
    },
    "10.1109/tvcg.2023.3326855": {
        "doi": "10.1109/tvcg.2023.3326855",
        "authors": [
            {
                "family": "Neuhauser",
                "given": "Christoph",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Stumpfegger",
                "given": "Josef",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Westermann",
                "given": "R\u00fcdiger",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Adaptive Sampling of 3D Spatial Correlations for Focus+Context Visualization",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "2",
        "pages": "1608\u20131623",
        "article_number": "",
        "number_of_pages": 16,
        "abstract": "Visualizing spatial correlations in 3D ensembles is challenging due to the vast amounts of information that need to be conveyed. Memory and time constraints make it unfeasible to pre-compute and store the correlations between all pairs of domain points. We propose the embedding of adaptive correlation sampling into chord diagrams with hierarchical edge bundling to alleviate these constraints. Entities representing spatial regions are arranged along the circular chord layout via a space-filling curve, and Bayesian optimal sampling is used to efficiently estimate the maximum occurring correlation between any two points from different regions. Hierarchical edge bundling reduces visual clutter and emphasizes the major correlation structures. By selecting an edge, the user triggers a focus diagram in which only the two regions connected via this edge are refined and arranged in a specific way in a second chord layout. For visualizing correlations between two different variables, which are not symmetric anymore, we switch to showing a full correlation matrix. This avoids drawing the same edges twice with different correlation values. We introduce GPU implementations of both linear and non-linear correlation measures to further reduce the time that is required to generate the context and focus views, and to even enable the analysis of correlations in a 1000-member ensemble.",
        "countries": [
            "DE"
        ]
    },
    "10.1109/tvcg.2023.3312127": {
        "doi": "10.1109/tvcg.2023.3312127",
        "authors": [
            {
                "family": "Gan",
                "given": "Wanshui",
                "countries": [
                    "JP"
                ]
            },
            {
                "family": "Xu",
                "given": "Hongbin",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Huang",
                "given": "Yi",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Chen",
                "given": "Shifeng",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Yokoya",
                "given": "Naoto",
                "countries": [
                    "JP"
                ]
            }
        ],
        "title": "V4D: Voxel for 4D Novel View Synthesis",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "2",
        "pages": "1579\u20131591",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "Neural radiance fields have made a remarkable breakthrough in the novel view synthesis task at the 3D static scene. However, for the 4D circumstance (e.g., dynamic scene), the performance of the existing method is still limited by the capacity of the neural network, typically in a multilayer perceptron network (MLP). In this article, we utilize 3D Voxel to model the 4D neural radiance field, short as V4D, where the 3D voxel has two formats. The first one is to regularly model the 3D space and then use the sampled local 3D feature with the time index to model the density field and the texture field by a tiny MLP. The second one is in look-up tables (LUTs) format that is for the pixel-level refinement, where the pseudo-surface produced by the volume rendering is utilized as the guidance information to learn a 2D pixel-level refinement mapping. The proposed LUTs-based refinement module achieves the performance gain with little computational cost and could serve as the plug-and-play module in the novel view synthesis task. Moreover, we propose a more effective conditional positional encoding toward the 4D data that achieves performance gain with negligible computational burdens. Extensive experiments demonstrate that the proposed method achieves state-of-the-art performance at a low computational cost.",
        "countries": [
            "JP",
            "CN"
        ]
    },
    "10.1109/tvcg.2022.3229017": {
        "doi": "10.1109/tvcg.2022.3229017",
        "authors": [
            {
                "family": "Nam",
                "given": "Jung Who",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Isenberg",
                "given": "Tobias",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Keefe",
                "given": "Daniel F.",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "V-Mail: 3D-Enabled Correspondence About Spatial Data on (Almost) All Your Devices",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "4",
        "pages": "1853\u20131867",
        "article_number": "",
        "number_of_pages": 15,
        "abstract": "We present V-Mail, a framework of cross-platform applications, interactive techniques, and communication protocols for improved multi-person correspondence about spatial 3D datasets. Inspired by the daily use of e-mail, V-Mail seeks to enable a similar style of rapid, multi-person communication accessible on any device; however, it aims to do this in the new context of spatial 3D communication, where limited access to 3D graphics hardware typically prevents such communication. The approach integrates visual data storytelling with data exploration, spatial annotations, and animated transitions. V-Mail \u201cdata stories\u201d are exported in a standard video file format to establish a common baseline level of access on (almost) any device. The V-Mail framework also includes a series of complementary client applications and plugins that enable different degrees of story co-authoring and data exploration, adjusted automatically to match the capabilities of various devices. A lightweight, phone-based V-Mail app makes it possible to annotate data by adding captions to the video. These spatial annotations are then immediately accessible to team members running high-end 3D graphics visualization systems that also include a V-Mail client, implemented as a plugin. Results and evaluation from applying V-Mail to assist communication within an interdisciplinary science team studying Antarctic ice sheets confirm the utility of the asynchronous, cross-platform collaborative framework while also highlighting some current limitations and opportunities for future work.",
        "countries": [
            "US",
            "FR"
        ]
    },
    "10.1109/tvcg.2023.3326931": {
        "doi": "10.1109/tvcg.2023.3326931",
        "authors": [
            {
                "family": "Straub",
                "given": "Alexander",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Karadimitriou",
                "given": "Nikolaos",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Reina",
                "given": "Guido",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Frey",
                "given": "Steffen",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Steeb",
                "given": "Holger",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Ertl",
                "given": "Thomas",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Visual Analysis of Displacement Processes in Porous Media using Spatio-Temporal Flow Graphs",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "1",
        "pages": "759\u2013769",
        "article_number": "",
        "number_of_pages": 11,
        "abstract": "We developed a new approach comprised of different visualizations for the comparative spatio-temporal analysis of displacement processes in porous media. We aim to analyze and compare ensemble datasets from experiments to gain insight into the influence of different parameters on fluid flow. To capture the displacement of a defending fluid by an invading fluid, we first condense an input image series to a single time map. From this map, we generate a spatio-temporal flow graph covering the whole process. This graph is further simplified to only reflect topological changes in the movement of the invading fluid. Our interactive tools allow the visual analysis of these processes by visualizing the graph structure and the context of the experimental setup, as well as by providing charts for multiple metrics. We apply our approach to analyze and compare ensemble datasets jointly with domain experts, where we vary either fluid properties or the solid structure of the porous medium. We finally report the generated insights from the domain experts and discuss our contribution's advantages, generality, and limitations.",
        "countries": [
            "DE",
            "NL"
        ]
    },
    "10.1109/tvcg.2023.3326569": {
        "doi": "10.1109/tvcg.2023.3326569",
        "authors": [
            {
                "family": "Atzberger",
                "given": "Daniel",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Cech",
                "given": "Tim",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Trapp",
                "given": "Matthias",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Richter",
                "given": "Rico",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Scheibel",
                "given": "Willy",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "D\u00f6llner",
                "given": "J\u00fcrgen",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Schreck",
                "given": "Tobias",
                "countries": [
                    "AT"
                ]
            }
        ],
        "title": "Large-Scale Evaluation of Topic Models and Dimensionality Reduction Methods for 2D Text Spatialization",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "1",
        "pages": "902\u2013912",
        "article_number": "",
        "number_of_pages": 11,
        "abstract": "Topic models are a class of unsupervised learning algorithms for detecting the semantic structure within a text corpus. Together with a subsequent dimensionality reduction algorithm, topic models can be used for deriving spatializations for text corpora as two-dimensional scatter plots, reflecting semantic similarity between the documents and supporting corpus analysis. Although the choice of the topic model, the dimensionality reduction, and their underlying hyperparameters significantly impact the resulting layout, it is unknown which particular combinations result in high-quality layouts with respect to accuracy and perception metrics. To investigate the effectiveness of topic models and dimensionality reduction methods for the spatialization of corpora as two-dimensional scatter plots (or basis for landscape-type visualizations), we present a large-scale, benchmark-based computational evaluation. Our evaluation consists of (1) a set of corpora, (2) a set of layout algorithms that are combinations of topic models and dimensionality reductions, and (3) quality metrics for quantifying the resulting layout. The corpora are given as document-term matrices, and each document is assigned to a thematic class. The chosen metrics quantify the preservation of local and global properties and the perceptual effectiveness of the two-dimensional scatter plots. By evaluating the benchmark on a computing cluster, we derived a multivariate dataset with over 45 000 individual layouts and corresponding quality metrics. Based on the results, we propose guidelines for the effective design of text spatializations that are based on topic models and dimensionality reductions. As a main result, we show that interpretable topic models are beneficial for capturing the structure of text corpora. We furthermore recommend the use of t-SNE as a subsequent dimensionality reduction.",
        "countries": [
            "DE",
            "AT"
        ]
    },
    "10.1109/tvcg.2023.3274572": {
        "doi": "10.1109/tvcg.2023.3274572",
        "authors": [
            {
                "family": "Gray",
                "given": "Kathryn",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Li",
                "given": "Mingwei",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Ahmed",
                "given": "Reyan",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Rahman",
                "given": "Md. Khaledur",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Azad",
                "given": "Ariful",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Kobourov",
                "given": "Stephen",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "B\u00f6rner",
                "given": "Katy",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "A Scalable Method for Readable Tree Layouts",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "2",
        "pages": "1564\u20131578",
        "article_number": "",
        "number_of_pages": 15,
        "abstract": "Large tree structures are ubiquitous and real-world relational datasets often have information associated with nodes (e.g., labels or other attributes) and edges (e.g., weights or distances) that need to be communicated to the viewers. Yet, scalable, easy to read tree layouts are difficult to achieve. We consider tree layouts to be readable if they meet some basic requirements: node labels should not overlap, edges should not cross, edge lengths should be preserved, and the output should be compact. There are many algorithms for drawing trees, although very few take node labels or edge lengths into account, and none optimizes all requirements above. With this in mind, we propose a new scalable method for readable tree layouts. The algorithm guarantees that the layout has no edge crossings and no label overlaps, and optimizes one of the remaining aspects: desired edge lengths and compactness. We evaluate the performance of the new algorithm by comparison with related earlier approaches using several real-world datasets, ranging from a few thousand nodes to hundreds of thousands of nodes. Tree layout algorithms can be used to visualize large general graphs, by extracting a hierarchy of progressively larger trees. We illustrate this functionality by presenting several map-like visualizations generated by the new tree layout algorithm.",
        "countries": [
            "US"
        ]
    },
    "10.1109/tvcg.2020.3030473": {
        "doi": "10.1109/tvcg.2020.3030473",
        "authors": [
            {
                "family": "Zhou",
                "given": "Liang",
                "countries": [
                    "CN",
                    "US"
                ]
            },
            {
                "family": "Johnson",
                "given": "Chris R.",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Weiskopf",
                "given": "Daniel",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Data-Driven Space-Filling Curves",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "2",
        "pages": "1591\u20131600",
        "article_number": "",
        "number_of_pages": 10,
        "abstract": "We propose a data-driven space-filling curve method for 2D and 3D visualization. Our flexible curve traverses the data elements in the spatial domain in a way that the resulting linearization better preserves features in space compared to existing methods. We achieve such data coherency by calculating a Hamiltonian path that approximately minimizes an objective function that describes the similarity of data values and location coherency in a neighborhood. Our extended variant even supports multiscale data via quadtrees and octrees. Our method is useful in many areas of visualization including multivariate or comparative visualization ensemble visualization of 2D and 3D data on regular grids or multiscale visual analysis of particle simulations. The effectiveness of our method is evaluated with numerical comparisons to existing techniques and through examples of ensemble and multivariate datasets.",
        "countries": [
            "CN",
            "US",
            "DE"
        ]
    },
    "10.1109/tvcg.2022.3171179": {
        "doi": "10.1109/tvcg.2022.3171179",
        "authors": [
            {
                "family": "Mancinelli",
                "given": "Claudio",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Nazzaro",
                "given": "Giacomo",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Pellacini",
                "given": "Fabio",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Puppo",
                "given": "Enrico",
                "countries": [
                    "IT"
                ]
            }
        ],
        "title": "b/Surf: Interactive B\u00e9zier Splines on Surface Meshes",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2023,
        "volume": "29",
        "number": "7",
        "pages": "3419\u20133435",
        "article_number": "",
        "number_of_pages": 17,
        "abstract": "We present a practical framework to port B\u00e9zier curves to surfaces. We support the interactive drawing and editing of B\u00e9zier splines on manifold meshes with millions of triangles, by relying on just repeated manifold averages. We show that direct extensions of the de Casteljau and Bernstein evaluation algorithms to the manifold setting are fragile, and prone to discontinuities when control polygons become large. Conversely, approaches based on subdivision are robust and can be implemented efficiently. We implement manifold extensions of the recursive de Casteljau bisection, and an open-uniform Lane-Riesenfeld subdivision scheme. For both schemes, we present algorithms for curve tracing, point evaluation, and approximated point insertion. We run bulk experiments to test our algorithms for robustness and performance, and we compare them with other methods at the state of the art, always achieving correct results and superior performance. For interactive editing, we port all the basic user interface interactions found in 2D tools directly to the mesh. We also support mapping complex SVG drawings to the mesh and their interactive editing.",
        "countries": [
            "IT"
        ]
    },
    "10.1109/tvcg.2023.3251648": {
        "doi": "10.1109/tvcg.2023.3251648",
        "authors": [
            {
                "family": "Xu",
                "given": "Sen-Zhe",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Liu",
                "given": "Jia-Hong",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wang",
                "given": "Miao",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhang",
                "given": "Fang-Lue",
                "countries": [
                    "NZ"
                ]
            },
            {
                "family": "Zhang",
                "given": "Song-Hai",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Multi-User Redirected Walking in Separate Physical Spaces for Online VR Scenarios",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "4",
        "pages": "1916\u20131926",
        "article_number": "",
        "number_of_pages": 11,
        "abstract": "With the recent rise of Metaverse, online multiplayer VR applications are becoming increasingly prevalent worldwide. However, as multiple users are located in different physical environments, different reset frequencies and timings can lead to serious fairness issues for online collaborative/competitive VR applications. For the fairness of online VR apps/games, an ideal online RDW strategy must make the locomotion opportunities of different users equal, regardless of different physical environment layouts. The existing RDW methods lack the scheme to coordinate multiple users in different PEs, and thus have the issue of triggering too many resets for all the users under the locomotion fairness constraint. We propose a novel multi-user RDW method that is able to significantly reduce the overall reset number and give users a better immersive experience by providing a fair exploration. Our key idea is to first find out the \u201dbottleneck\u201d user that may cause all users to be reset and estimate the time to reset given the users\u2019 next targets, and then redirect all the users to favorable poses during that maximized bottleneck time to ensure the subsequent resets can be postponed as much as possible. More particularly, we develop methods to estimate the time of possibly encountering obstacles and the reachable area for a specific pose to enable the prediction of the next reset caused by any user. Our experiments and user study found that our method outperforms existing RDW methods in online VR applications.",
        "countries": [
            "CN",
            "NZ"
        ]
    },
    "10.1109/tvcg.2023.3261981": {
        "doi": "10.1109/tvcg.2023.3261981",
        "authors": [
            {
                "family": "Maack",
                "given": "Robin G. C.",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Lukasczyk",
                "given": "Jonas",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Tierny",
                "given": "Julien",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Hagen",
                "given": "Hans",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Maciejewski",
                "given": "Ross",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Garth",
                "given": "Christoph",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Parallel Computation of Piecewise Linear Morse-Smale Segmentations",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "4",
        "pages": "1942\u20131955",
        "article_number": "",
        "number_of_pages": 14,
        "abstract": "This article presents a well-scaling parallel algorithm for the computation of Morse-Smale (MS) segmentations, including the region separators and region boundaries. The segmentation of the domain into ascending and descending manifolds, solely defined on the vertices, improves the computational time using path compression and fully segments the border region. Region boundaries and region separators are generated using a multi-label marching tetrahedra algorithm. This enables a fast and simple solution to find optimal parameter settings in preliminary exploration steps by generating an MS complex preview. It also poses a rapid option to generate a fast visual representation of the region geometries for immediate utilization. Two experiments demonstrate the performance of our approach with speedups of over an order of magnitude in comparison to two publicly available implementations. The example section shows the similarity to the MS complex, the useability of the approach, and the benefits of this method with respect to the presented datasets. We provide our implementation with the paper.",
        "countries": [
            "DE",
            "FR",
            "US"
        ]
    },
    "10.1109/tvcg.2022.3214821": {
        "doi": "10.1109/tvcg.2022.3214821",
        "authors": [
            {
                "family": "Liang",
                "given": "Xin",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Di",
                "given": "Sheng",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Cappello",
                "given": "Franck",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Raj",
                "given": "Mukund",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Liu",
                "given": "Chunhui",
                "countries": [
                    "JP"
                ]
            },
            {
                "family": "Ono",
                "given": "Kenji",
                "countries": [
                    "JP"
                ]
            },
            {
                "family": "Chen",
                "given": "Zizhong",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Peterka",
                "given": "Tom",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Guo",
                "given": "Hanqi",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Toward Feature-Preserving Vector Field Compression",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2023,
        "volume": "29",
        "number": "12",
        "pages": "5434\u20135450",
        "article_number": "",
        "number_of_pages": 17,
        "abstract": "The objective of this work is to develop error-bounded lossy compression methods to preserve topological features in 2D and 3D vector fields. Specifically, we explore the preservation of critical points in piecewise linear and bilinear vector fields. We define the preservation of critical points as, without any false positive, false negative, or false type in the decompressed data, (1) keeping each critical point in its original cell and (2) retaining the type of each critical point (e.g., saddle and attracting node). The key to our method is to adapt a vertex-wise error bound for each grid point and to compress input data together with the error bound field using a modified lossy compressor. Our compression algorithm can be also embarrassingly parallelized for large data handling and in situ processing. We benchmark our method by comparing it with existing lossy compressors in terms of false positive/negative/type rates, compression ratio, and various vector field visualizations with several scientific applications.",
        "countries": [
            "US",
            "JP"
        ]
    },
    "10.1109/tvcg.2023.3250166": {
        "doi": "10.1109/tvcg.2023.3250166",
        "authors": [
            {
                "family": "Valdrighi",
                "given": "Giovani",
                "countries": [
                    "BR"
                ]
            },
            {
                "family": "Ferreira",
                "given": "Nivan",
                "countries": [
                    "BR"
                ]
            },
            {
                "family": "Poco",
                "given": "Jorge",
                "countries": [
                    "BR"
                ]
            }
        ],
        "title": "MoReVis: A Visual Summary for Spatiotemporal Moving Regions",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "4",
        "pages": "1927\u20131941",
        "article_number": "",
        "number_of_pages": 15,
        "abstract": "Spatial and temporal interactions are central and fundamental in many activities in our world. A common problem faced when visualizing this type of data is how to provide an overview that helps users navigate efficiently. Traditional approaches use coordinated views or 3D metaphors like the Space-time cube to tackle this problem. However, they suffer from overplotting and often lack spatial context, hindering data exploration. More recent techniques, such as MotionRugs, propose compact temporal summaries based on 1D projection. While powerful, these techniques do not support the situation for which the spatial extent of the objects and their intersections is relevant, such as the analysis of surveillance videos or tracking weather storms. In this article, we propose MoReVis, a visual overview of spatiotemporal data that considers the objects\u2019 spatial extent and strives to show spatial interactions among these objects by displaying spatial intersections. Like previous techniques, our method involves projecting the spatial coordinates to 1D to produce compact summaries. However, our solution's core consists of performing a layout optimization step that sets the size and positions of the visual marks on the summary to resemble the actual values on the original space. We also provide multiple interactive mechanisms to make interpreting the results more straightforward for the user. We perform an extensive experimental evaluation and usage scenarios. Moreover, we evaluated the usefulness of MoReVis in a study with 9 participants. The results point out the effectiveness and suitability of our method in representing different datasets compared to traditional techniques.",
        "countries": [
            "BR"
        ]
    },
    "10.1109/tvcg.2022.3209420": {
        "doi": "10.1109/tvcg.2022.3209420",
        "authors": [
            {
                "family": "H\u00e4gele",
                "given": "David",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Krake",
                "given": "Tim",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Weiskopf",
                "given": "Daniel",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Uncertainty-Aware Multidimensional Scaling",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2023,
        "volume": "29",
        "number": "1",
        "pages": "23\u201332",
        "article_number": "",
        "number_of_pages": 10,
        "abstract": "We present an extension of multidimensional scaling (MDS) to uncertain data, facilitating uncertainty visualization of multidimensional data. Our approach uses local projection operators that map high-dimensional random vectors to low-dimensional space to formulate a generalized stress. In this way, our generic model supports arbitrary distributions and various stress types. We use our uncertainty-aware multidimensional scaling (UAMDS) concept to derive a formulation for the case of normally distributed random vectors and a squared stress. The resulting minimization problem is numerically solved via gradient descent. We complement UAMDS by additional visualization techniques that address the sensitivity and trustworthiness of dimensionality reduction under uncertainty. With several examples, we demonstrate the usefulness of our approach and the importance of uncertainty-aware techniques.",
        "countries": [
            "DE"
        ]
    },
    "10.1109/tvcg.2023.3238008": {
        "doi": "10.1109/tvcg.2023.3238008",
        "authors": [
            {
                "family": "Guillou",
                "given": "Pierre",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Vidal",
                "given": "Jules",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Tierny",
                "given": "Julien",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Discrete Morse Sandwich: Fast Computation of Persistence Diagrams for Scalar Data \u2013 An Algorithm and a Benchmark",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "4",
        "pages": "1897\u20131915",
        "article_number": "",
        "number_of_pages": 19,
        "abstract": "This paper introduces an efficient algorithm for persistence diagram computation, given an input piecewise linear scalar field $f$f defined on a $d$d-dimensional simplicial complex $\\mathcal {K}$K, with $d \\leq 3$d\u22643. Our work revisits the seminal algorithm \u201cPairSimplices\u201d (Edelsbrunner et al. 2002), (Zomorodian, 2010) with discrete Morse theory (DMT) (Forman, 1998), (Robins et al. 2011), which greatly reduces the number of input simplices to consider. Further, we also extend to DMT and accelerate the stratification strategy described in \u201cPairSimplices\u201d (Edelsbrunner et al. 2002), (Zomorodian, 2010) for the fast computation of the $0^{th}$ and $(d-1)^{th}$(d-1)th diagrams, noted $\\mathcal {D}_{0}(f)$D0(f) and $\\mathcal {D}_{d-1}(f)$Dd-1(f). Minima-saddle persistence pairs ($\\mathcal {D}_{0}(f)$D0(f)) and saddle-maximum persistence pairs ($\\mathcal {D}_{d-1}(f)$Dd-1(f)) are efficiently computed by processing, with a Union-Find, the unstable sets of 1-saddles and the stable sets of $(d-1)$(d-1)-saddles. This fast pre-computation for the dimensions 0 and $(d-1)$(d-1) enables an aggressive specialization of (Bauer et al. 2014) to the 3D case, which results in a drastic reduction of the number of input simplices for the computation of $\\mathcal {D}_{1}(f)$D1(f), the intermediate layer of the sandwich. Finally, we document several performance improvements via shared-memory parallelism. We provide an open-source implementation of our algorithm for reproducibility purposes. Extensive experiments indicate that our algorithm improves by two orders of magnitude the time performance of the seminal \u201cPairSimplices\u201d algorithm it extends. Moreover, it also improves memory footprint and time performance over a selection of 14 competing approaches, with a substantial gain over the fastest available approaches, while producing a strictly identical output.",
        "countries": [
            "FR"
        ]
    },
    "10.1109/tvcg.2023.3235277": {
        "doi": "10.1109/tvcg.2023.3235277",
        "authors": [
            {
                "family": "Tetzlaff",
                "given": "Michael",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "High-Fidelity Specular SVBRDF Acquisition From Flash Photographs",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "4",
        "pages": "1885\u20131896",
        "article_number": "",
        "number_of_pages": 12,
        "abstract": "Obtaining accurate SVBRDFs from 2D photographs of shiny, heterogeneous 3D objects is a highly sought-after goal for domains like cultural heritage archiving, where it is critical to document color appearance in high fidelity. In prior work such as the promising framework by Nam et al., the problem is simplified by assuming that specular highlights exhibit symmetry and isotropy about an estimated surface normal. The present work builds on this foundation with several significant modifications. Recognizing the importance of the surface normal as an axis of symmetry, we compare nonlinear optimization for normals with a linear approximation proposed by Nam et al. and find that nonlinear optimization is superior to the linear approximation, while noting that the surface normal estimates generally have a very significant impact on the reconstructed color appearance of the object. We also examine the use of a monotonicity constraint for reflectance and develop a generalization that also enforces continuity and smoothness when optimizing continuous monotonic functions like a microfacet distribution. Finally, we explore the impact of simplifying from an arbitrary 1D basis function to a traditional parametric microfacet distribution (GGX), and we find this to be a reasonable approximation that trades some fidelity for practicality in certain applications. Both representations can be used in existing rendering architectures like game engines or online 3D viewers, while retaining accurate color appearance for fidelity-critical applications like cultural heritage or online sales.",
        "countries": [
            "US"
        ]
    },
    "10.1109/tvcg.2022.3232591": {
        "doi": "10.1109/tvcg.2022.3232591",
        "authors": [
            {
                "family": "Zhao",
                "given": "Henan",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Bryant",
                "given": "Garnett W.",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Griffin",
                "given": "Wesley",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Terrill",
                "given": "Judith E.",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Chen",
                "given": "Jian",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Evaluating Glyph Design for Showing Large-Magnitude-Range Quantum Spins",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "4",
        "pages": "1868\u20131884",
        "article_number": "",
        "number_of_pages": 17,
        "abstract": "We present experimental results to explore a form of bivariate glyphs for representing large-magnitude-range vectors. The glyphs meet two conditions: (1) two visual dimensions are separable; and (2) one of the two visual dimensions uses a categorical representation (e.g., a categorical colormap). We evaluate how much these two conditions determine the bivariate glyphs\u2019 effectiveness. The first experiment asks participants to perform three local tasks requiring reading no more than two glyphs. The second experiment scales up the search space in global tasks when participants must look at the entire scene of hundreds of vector glyphs to get an answer. Our results support that the first condition is necessary for local tasks when a few items are compared. But it is not enough for understanding a large amount of data. The second condition is necessary for perceiving global structures of examining very complex datasets. Participants\u2019 comments reveal that the categorical features in the bivariate glyphs trigger emergent optimal viewers\u2019 behaviors. This work contributes to perceptually accurate glyph representations for revealing patterns from large scientific results. We release source code, quantum physics data, training documents, participants\u2019 answers, and statistical analyses for reproducible science at https://osf.io/4xcf5/?view_only=94123139df9c4ac984a1e0df811cd580.",
        "countries": [
            "US"
        ]
    },
    "10.1109/tvcg.2022.3217008": {
        "doi": "10.1109/tvcg.2022.3217008",
        "authors": [
            {
                "family": "Huang",
                "given": "Danny",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Stavness",
                "given": "Ian",
                "countries": [
                    "CA"
                ]
            }
        ],
        "title": "Large Growth Deformations of Thin Tissue Using Solid-Shells",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2023,
        "volume": "29",
        "number": "3",
        "pages": "1893\u20131909",
        "article_number": "",
        "number_of_pages": 17,
        "abstract": "Simulating large scale expansion of thin structures, such as in growing leaves, is challenging. Solid-shells have a number of potential advantages over conventional thin-shell methods, but have thus far only been investigated for small plastic deformation cases. In response, we present a new general-purpose FEM growth framework for handling a wide range of challenging growth scenarios using the solid-shell element. Solid-shells are a middle-ground between traditional volume and thin-shell elements where volumetric characteristics are retained while being treatable as a 2D manifold much like thin-shells. These elements are adaptable to accommodate the many techniques that are required for simulating large and intricate plastic deformations, including morphogen diffusion, plastic embedding, strain-aware adaptive remeshing, and collision handling. We demonstrate the capabilities of growing solid-shells in reproducing buckling, rippling, curling, and collision deformations, relevant towards animating growing leaves, flowers, and other thin structures. Solid-shells are compared side-by-side with thin-shells to examine their bending behavior and runtime performance. The experiments demonstrate that solid-shells are a viable alternative to thin-shells for simulating large and intricate growth deformations.",
        "countries": [
            "CA"
        ]
    },
    "10.1109/tvcg.2022.3209437": {
        "doi": "10.1109/tvcg.2022.3209437",
        "authors": [
            {
                "family": "Krake",
                "given": "Tim",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Kl\u00f6tzl",
                "given": "Daniel",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Eberhardt",
                "given": "Bernhard",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Weiskopf",
                "given": "Daniel",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Constrained Dynamic Mode Decomposition",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2023,
        "volume": "29",
        "number": "1",
        "pages": "182\u2013192",
        "article_number": "",
        "number_of_pages": 11,
        "abstract": "Frequency-based decomposition of time series data is used in many visualization applications. Most of these decomposition methods (such as Fourier transform or singular spectrum analysis) only provide interaction via pre- and post-processing, but no means to influence the core algorithm. A method that also belongs to this class is Dynamic Mode Decomposition (DMD), a spectral decomposition method that extracts spatio-temporal patterns from data. In this paper, we incorporate frequency-based constraints into DMD for an adaptive decomposition that leads to user-controllable visualizations, allowing analysts to include their knowledge into the process. To accomplish this, we derive an equivalent reformulation of DMD that implicitly provides access to the eigenvalues (and therefore to the frequencies) identified by DMD. By utilizing a constrained minimization problem customized to DMD, we can guarantee the existence of desired frequencies by minimal changes to DMD. We complement this core approach by additional techniques for constrained DMD to facilitate explorative visualization and investigation of time series data. With several examples, we demonstrate the usefulness of constrained DMD and compare it to conventional frequency-based decomposition methods.",
        "countries": [
            "DE"
        ]
    },
    "10.1109/tvcg.2022.3215001": {
        "doi": "10.1109/tvcg.2022.3215001",
        "authors": [
            {
                "family": "Pont",
                "given": "Mathieu",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Vidal",
                "given": "Jules",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Tierny",
                "given": "Julien",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Principal Geodesic Analysis of Merge Trees (and Persistence Diagrams)",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2023,
        "volume": "29",
        "number": "2",
        "pages": "1573\u20131589",
        "article_number": "",
        "number_of_pages": 17,
        "abstract": "This article presents a computational framework for the Principal Geodesic Analysis of merge trees (MT-PGA), a novel adaptation of the celebrated Principal Component Analysis (PCA) framework (K. Pearson 1901) to the Wasserstein metric space of merge trees (Pont et al. 2022). We formulate MT-PGA computation as a constrained optimization problem, aiming at adjusting a basis of orthogonal geodesic axes, while minimizing a fitting energy. We introduce an efficient, iterative algorithm which exploits shared-memory parallelism, as well as an analytic expression of the fitting energy gradient, to ensure fast iterations. Our approach also trivially extends to extremum persistence diagrams. Extensive experiments on public ensembles demonstrate the efficiency of our approach \u2013 with MT-PGA computations in the orders of minutes for the largest examples. We show the utility of our contributions by extending to merge trees two typical PCA applications. First, we apply MT-PGA to data reduction and reliably compress merge trees by concisely representing them by their first coordinates in the MT-PGA basis. Second, we present a dimensionality reduction framework exploiting the first two directions of the MT-PGA basis to generate two-dimensional layouts of the ensemble. We augment these layouts with persistence correlation views, enabling global and local visual inspections of the feature variability in the ensemble. In both applications, quantitative experiments assess the relevance of our framework. Finally, we provide a C++ implementation that can be used to reproduce our results.",
        "countries": [
            "FR"
        ]
    },
    "10.1109/tvcg.2022.3209390": {
        "doi": "10.1109/tvcg.2022.3209390",
        "authors": [
            {
                "family": "He",
                "given": "Tingying",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Isenberg",
                "given": "Petra",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Dachselt",
                "given": "Raimund",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Isenberg",
                "given": "Tobias",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "BeauVis: A Validated Scale for Measuring the Aesthetic Pleasure of Visual Representations",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2023,
        "volume": "29",
        "number": "1",
        "pages": "363\u2013373",
        "article_number": "",
        "number_of_pages": 11,
        "abstract": "We developed and validated a rating scale to assess the aesthetic pleasure (or beauty) of a visual data representation: the BeauVis scale. With our work we offer researchers and practitioners a simple instrument to compare the visual appearance of different visualizations, unrelated to data or context of use. Our rating scale can, for example, be used to accompany results from controlled experiments or be used as informative data points during in-depth qualitative studies. Given the lack of an aesthetic pleasure scale dedicated to visualizations, researchers have mostly chosen their own terms to study or compare the aesthetic pleasure of visualizations. Yet, many terms are possible and currently no clear guidance on their effectiveness regarding the judgment of aesthetic pleasure exists. To solve this problem, we engaged in a multi-step research process to develop the first validated rating scale specifically for judging the aesthetic pleasure of a visualization (osf.io/fxs76). Our final BeauVis scale consists of five items, \u201cenjoyable,\u201d \u201clikable,\u201d \u201cpleasing,\u201d \u201cnice,\u201d and \u201cappealing.\u201d Beyond this scale itself, we contribute (a) a systematic review of the terms used in past research to capture aesthetics, (b) an investigation with visualization experts who suggested terms to use for judging the aesthetic pleasure of a visualization, and (c) a confirmatory survey in which we used our terms to study the aesthetic pleasure of a set of 3 visualizations.",
        "countries": [
            "FR",
            "DE"
        ]
    },
    "10.1109/tvcg.2022.3209383": {
        "doi": "10.1109/tvcg.2022.3209383",
        "authors": [
            {
                "family": "Stokes",
                "given": "Chase",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Setlur",
                "given": "Vidya",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Cogley",
                "given": "Bridget",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Satyanarayan",
                "given": "Arvind",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Hearst",
                "given": "Marti A.",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Striking a Balance: Reader Takeaways and Preferences when Integrating Text and Charts",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2023,
        "volume": "29",
        "number": "1",
        "pages": "1233\u20131243",
        "article_number": "",
        "number_of_pages": 11,
        "abstract": "While visualizations are an effective way to represent insights about information, they rarely stand alone. When designing a visualization, text is often added to provide additional context and guidance for the reader. However, there is little experimental evidence to guide designers as to what is the right amount of text to show within a chart, what its qualitative properties should be, and where it should be placed. Prior work also shows variation in personal preferences for charts versus textual representations. In this paper, we explore several research questions about the relative value of textual components of visualizations. 302 participants ranked univariate line charts containing varying amounts of text, ranging from no text (except for the axes) to a written paragraph with no visuals. Participants also described what information they could take away from line charts containing text with varying semantic content. We find that heavily annotated charts were not penalized. In fact, participants preferred the charts with the largest number of textual annotations over charts with fewer annotations or text alone. We also find effects of semantic content. For instance, the text that describes statistical or relational components of a chart leads to more takeaways referring to statistics or relational comparisons than text describing elemental or encoded components. Finally, we find different effects for the semantic levels based on the placement of the text on the chart; some kinds of information are best placed in the title, while others should be placed closer to the data. We compile these results into four chart design guidelines and discuss future implications for the combination of text and charts.",
        "countries": [
            "US"
        ]
    },
    "10.1109/tvcg.2022.3209422": {
        "doi": "10.1109/tvcg.2022.3209422",
        "authors": [
            {
                "family": "Hao",
                "given": "Hongtao",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Cui",
                "given": "Yumian",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Wang",
                "given": "Zhengxiang",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Kim",
                "given": "Yea-Seul",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Thirty-Two Years of IEEE VIS: Authors, Fields of Study and Citations",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2023,
        "volume": "29",
        "number": "1",
        "pages": "1016\u20131025",
        "article_number": "",
        "number_of_pages": 10,
        "abstract": "The IEEE VIS Conference (VIS) recently rebranded itself as a unified conference and officially positioned itself within the discipline of Data Science. Driven by this movement, we investigated (1) who contributed to VIS, and (2) where VIS stands in the scientific world. We examined the authors and fields of study of 3,240 VIS publications in the past 32 years based on data collected from OpenAlex and IEEE Xplore, among other sources. We also examined the citation flows from referenced papers (i.e., those referenced in VIS) to VIS, and from VIS to citing papers (i.e., those citing VIS). We found that VIS has been becoming increasingly popular and collaborative. The number of publications, of unique authors, and of participating countries have been steadily growing. Both cross-country collaborations, and collaborations between educational and non-educational affiliations, namely \u201ccross-type collaborations\u201d, are increasing. The dominance of the US is decreasing, and authors from China are now an important part of VIS. In terms of author affiliation types, VIS is increasingly dominated by authors from universities. We found that the topics, inspirations, and influences of VIS research is limited such that (1) VIS, and their referenced and citing papers largely fall into the Computer Science domain, and (2) citations flow mostly between the same set of subfields within Computer Science. Our citation analyses showed that award-winning VIS papers had higher citations. Interactive visualizations, replication data, source code and supplementary material are available at https://32vis.hongtaoh.com and https://osf.io/zkvjm.",
        "countries": [
            "US"
        ]
    },
    "10.1109/tvcg.2022.3209412": {
        "doi": "10.1109/tvcg.2022.3209412",
        "authors": [
            {
                "family": "Raynor",
                "given": "Justin",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Crnovrsanin",
                "given": "Tarik",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Bartolomeo",
                "given": "Sara Di",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "South",
                "given": "Laura",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Saffo",
                "given": "David",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Dunne",
                "given": "Cody",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "The State of the Art in BGP Visualization Tools: A Mapping of Visualization Techniques to Cyberattack Types",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2023,
        "volume": "29",
        "number": "1",
        "pages": "1059\u20131069",
        "article_number": "",
        "number_of_pages": 11,
        "abstract": "Internet routing is largely dependent on Border Gateway Protocol (BGP). However, BGP does not have any inherent authentication or integrity mechanisms that help make it secure. Effective security is challenging or infeasible to implement due to high costs, policy employment in these distributed systems, and unique routing behavior. Visualization tools provide an attractive alternative in lieu of traditional security approaches. Several BGP security visualization tools have been developed as a stop-gap in the face of ever-present BGP attacks. Even though the target users, tasks, and domain remain largely consistent across such tools, many diverse visualization designs have been proposed. The purpose of this study is to provide an initial formalization of methods and visualization techniques for BGP cybersecurity analysis. Using PRISMA guidelines, we provide a systematic review and survey of 29 BGP visualization tools with their tasks, implementation techniques, and attacks and anomalies that they were intended for. We focused on BGP visualization tools as the main inclusion criteria to best capture the visualization techniques used in this domain while excluding solely algorithmic solutions and other detection tools that do not involve user interaction or interpretation. We take the unique approach of connecting (1) the actual BGP attacks and anomalies used to validate existing tools with (2) the techniques employed to detect them. In this way, we contribute an analysis of which techniques can be used for each attack type. Furthermore, we can see the evolution of visualization solutions in this domain as new attack types are discovered. This systematic review provides the groundwork for future designers and researchers building visualization tools for providing BGP cybersecurity, including an understanding of the state-of-the-art in this space and an analysis of what techniques are appropriate for each attack type. Our novel security visualization survey methodology\u2014connecting visualization techniques with appropriate attack types\u2014may also assist future researchers conducting systematic reviews of security visualizations. All supplemental materials are available at https://osf.io/tupz6/.",
        "countries": [
            "US"
        ]
    },
    "10.1109/tvcg.2021.3114828": {
        "doi": "10.1109/tvcg.2021.3114828",
        "authors": [
            {
                "family": "Khan",
                "given": "Saiful",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Nguyen",
                "given": "Phong H.",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Abdul-Rahman",
                "given": "Alfie",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Bach",
                "given": "Benjamin",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Chen",
                "given": "Min",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Freeman",
                "given": "Euan",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Turkay",
                "given": "Cagatay",
                "countries": [
                    "GB"
                ]
            }
        ],
        "title": "Propagating Visual Designs to Numerous Plots and Dashboards",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "1",
        "pages": "86\u201395",
        "article_number": "",
        "number_of_pages": 10,
        "abstract": "In the process of developing an infrastructure for providing visualization and visual analytics (VIS) tools to epidemiologists and modeling scientists, we encountered a technical challenge for applying a number of visual designs to numerous datasets rapidly and reliably with limited development resources. In this paper, we present a technical solution to address this challenge. Operationally, we separate the tasks of data management, visual designs, and plots and dashboard deployment in order to streamline the development workflow. Technically, we utilize: an ontology to bring datasets, visual designs, and deployable plots and dashboards under the same management framework; multi-criteria search and ranking algorithms for discovering potential datasets that match a visual design; and a purposely-design user interface for propagating each visual design to appropriate datasets (often in tens and hundreds) and quality-assuring the propagation before the deployment. This technical solution has been used in the development of the RAMPVIS infrastructure for supporting a consortium of epidemiologists and modeling scientists through visualization.",
        "countries": [
            "GB"
        ]
    },
    "10.1109/tvcg.2022.3184186": {
        "doi": "10.1109/tvcg.2022.3184186",
        "authors": [
            {
                "family": "Li",
                "given": "Zhen",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wang",
                "given": "Xiting",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Yang",
                "given": "Weikai",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wu",
                "given": "Jing",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Zhang",
                "given": "Zhengyan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Liu",
                "given": "Zhiyuan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Sun",
                "given": "Maosong",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhang",
                "given": "Hui",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Liu",
                "given": "Shixia",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "A Unified Understanding of Deep NLP Models for Text Classification",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "12",
        "pages": "4980\u20134994",
        "article_number": "",
        "number_of_pages": 15,
        "abstract": "The rapid development of deep natural language processing (NLP) models for text classification has led to an urgent need for a unified understanding of these models proposed individually. Existing methods cannot meet the need for understanding different models in one framework due to the lack of a unified measure for explaining both low-level (e.g., words) and high-level (e.g., phrases) features. We have developed a visual analysis tool, DeepNLPVis, to enable a unified understanding of NLP models for text classification. The key idea is a mutual information-based measure, which provides quantitative explanations on how each layer of a model maintains the information of input words in a sample. We model the intra- and inter-word information at each layer measuring the importance of a word to the final prediction as well as the relationships between words, such as the formation of phrases. A multi-level visualization, which consists of a corpus-level, a sample-level, and a word-level visualization, supports the analysis from the overall training set to individual samples. Two case studies on classification tasks and comparison between models demonstrate that DeepNLPVis can help users effectively identify potential problems caused by samples and model architectures and then make informed improvements.",
        "countries": [
            "CN",
            "GB"
        ]
    },
    "10.1109/tvcg.2022.3209460": {
        "doi": "10.1109/tvcg.2022.3209460",
        "authors": [
            {
                "family": "McNutt",
                "given": "Andrew M.",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "No Grammar to Rule Them All: A Survey of JSON-style DSLs for Visualization",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2023,
        "volume": "29",
        "number": "1",
        "pages": "160\u2013170",
        "article_number": "",
        "number_of_pages": 11,
        "abstract": "There has been substantial growth in the use of JSON-based grammars, as well as other standard data serialization languages, to create visualizations. Each of these grammars serves a purpose: some focus on particular computational tasks (such as animation), some are concerned with certain chart types (such as maps), and some target specific data domains (such as ML). Despite the prominence of this interface form, there has been little detailed analysis of the characteristics of these languages. In this study, we survey and analyze the design and implementation of 57 JSON-style DSLs for visualization. We analyze these languages supported by a collected corpus of examples for each DSL (consisting of 4395 instances) across a variety of axes organized into concerns related to domain, conceptual model, language relationships, affordances, and general practicalities. We identify tensions throughout these areas, such as between formal and colloquial specifications, among types of users, and within the composition of languages. Through this work, we seek to support language implementers by elucidating the choices, opportunities, and tradeoffs in visualization DSL design.",
        "countries": [
            "US"
        ]
    },
    "10.1109/tvcg.2022.3198163": {
        "doi": "10.1109/tvcg.2022.3198163",
        "authors": [
            {
                "family": "Wang",
                "given": "Yao",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Jiao",
                "given": "Chuhan",
                "countries": [
                    "FI"
                ]
            },
            {
                "family": "B\u00e2ce",
                "given": "Mihai",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Bulling",
                "given": "Andreas",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "VisRecall: Quantifying Information Visualisation Recallability via Question Answering",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "12",
        "pages": "4995\u20135005",
        "article_number": "",
        "number_of_pages": 11,
        "abstract": "Despite its importance for assessing the effectiveness of communicating information visually, fine-grained recallability of information visualisations has not been studied quantitatively so far. In this work, we propose a question-answering paradigm to study visualisation recallability and present VisRecall \u2014 a novel dataset consisting of 200 visualisations that are annotated with crowd-sourced human (N = 305) recallability scores obtained from 1,000 questions of five question types. Furthermore, we present the first computational method to predict recallability of different visualisation elements, such as the title or specific data values. We report detailed analyses of our method on VisRecall and demonstrate that it outperforms several baselines in overall recallability and FE-, F-, RV-, and U-question recallability. Our work makes fundamental contributions towards a new generation of methods to assist designers in optimising visualisations.",
        "countries": [
            "DE",
            "FI"
        ]
    },
    "10.1109/tvcg.2022.3190623": {
        "doi": "10.1109/tvcg.2022.3190623",
        "authors": [
            {
                "family": "Arleo",
                "given": "Alessio",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Didimo",
                "given": "Walter",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Liotta",
                "given": "Giuseppe",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Miksch",
                "given": "Silvia",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Montecchiani",
                "given": "Fabrizio",
                "countries": [
                    "IT"
                ]
            }
        ],
        "title": "Influence Maximization With Visual Analytics",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "10",
        "pages": "3428\u20133440",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "In social networks, individuals\u2019 decisions are strongly influenced by recommendations from their friends, acquaintances, and favorite renowned personalities. The popularity of online social networking platforms makes them the prime venues to advertise products and promote opinions. The Influence Maximization (IM) problem entails selecting a seed set of users that maximizes the influence spread, i.e., the expected number of users positively influenced by a stochastic diffusion process triggered by the seeds. Engineering and analyzing IM algorithms remains a difficult and demanding task due to the NP-hardness of the problem and the stochastic nature of the diffusion processes. Despite several heuristics being introduced, they often fail in providing enough information on how the network topology affects the diffusion process, precious insights that could help researchers improve their seed set selection. In this paper, we present VAIM, a visual analytics system that supports users in analyzing, evaluating, and comparing information diffusion processes determined by different IM algorithms. Furthermore, VAIM provides useful insights that the analyst can use to modify the seed set of an IM algorithm, so to improve its influence spread. We assess our system by: $(i)$(i) a qualitative evaluation based on a guided experiment with two domain experts on two different data sets; $(ii)$(ii) a quantitative estimation of the value of the proposed visualization through the ICE-T methodology by Wall et al. (IEEE TVCG - 2018). The twofold assessment indicates that VAIM effectively supports our target users in the visual analysis of the performance of IM algorithms.",
        "countries": [
            "AT",
            "IT"
        ]
    },
    "10.1109/tvcg.2021.3054916": {
        "doi": "10.1109/tvcg.2021.3054916",
        "authors": [
            {
                "family": "Chen",
                "given": "Jian",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Ling",
                "given": "Meng",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Li",
                "given": "Rui",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Isenberg",
                "given": "Petra",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Isenberg",
                "given": "Tobias",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Sedlmair",
                "given": "Michael",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "M\u00f6ller",
                "given": "Torsten",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Laramee",
                "given": "Robert S.",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Shen",
                "given": "Han-Wei",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "W\u00fcnsche",
                "given": "Katharina",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Wang",
                "given": "Qiru",
                "countries": [
                    "GB"
                ]
            }
        ],
        "title": "VIS30K: A Collection of Figures and Tables From IEEE Visualization Conference Publications",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "9",
        "pages": "3826\u20133833",
        "article_number": "",
        "number_of_pages": 8,
        "abstract": "We present the VIS30K dataset, a collection of 29,689 images that represents 30 years of figures and tables from each track of the IEEE Visualization conference series (Vis, SciVis, InfoVis, VAST). VIS30K's comprehensive coverage of the scientific literature in visualization not only reflects the progress of the field but also enables researchers to study the evolution of the state-of-the-art and to find relevant work based on graphical content. We describe the dataset and our semi-automatic collection process, which couples convolutional neural networks (CNN) with curation. Extracting figures and tables semi-automatically allows us to verify that no images are overlooked or extracted erroneously. To improve quality further, we engaged in a peer-search process for high-quality figures from early IEEE Visualization papers. With the resulting data, we also contribute VISImageNavigator (VIN, visimagenavigator.github.io), a web-based tool that facilitates searching and exploring VIS30K by author names, paper keywords, title and abstract, and years.",
        "countries": [
            "US",
            "FR",
            "DE",
            "AT",
            "GB"
        ]
    },
    "10.1109/tvcg.2022.3184993": {
        "doi": "10.1109/tvcg.2022.3184993",
        "authors": [
            {
                "family": "Yao",
                "given": "Lijie",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Bezerianos",
                "given": "Anastasia",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Vuillemot",
                "given": "Romain",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Isenberg",
                "given": "Petra",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Visualization in Motion: A Research Agenda and Two Evaluations",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "10",
        "pages": "3546\u20133562",
        "article_number": "",
        "number_of_pages": 17,
        "abstract": "We contribute a research agenda for visualization in motion and two experiments to understand how well viewers can read data from moving visualizations. We define visualizations in motion as visual data representations that are used in contexts that exhibit relative motion between a viewer and an entire visualization. Sports analytics, video games, wearable devices, or data physicalizations are example contexts that involve different types of relative motion between a viewer and a visualization. To analyze the opportunities and challenges for designing visualization in motion, we show example scenarios and outline a first research agenda. Motivated primarily by the prevalence of and opportunities for visualizations in sports and video games we started to investigate a small aspect of our research agenda: the impact of two important characteristics of motion\u2014speed and trajectory on a stationary viewer's ability to read data from moving donut and bar charts. We found that increasing speed and trajectory complexity did negatively affect the accuracy of reading values from the charts and that bar charts were more negatively impacted. In practice, however, this impact was small: both charts were still read fairly accurately.",
        "countries": [
            "FR"
        ]
    },
    "10.1109/tvcg.2022.3182488": {
        "doi": "10.1109/tvcg.2022.3182488",
        "authors": [
            {
                "family": "Yang",
                "given": "Weikai",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Ye",
                "given": "Xi",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Zhang",
                "given": "Xingxing",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Xiao",
                "given": "Lanxi",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Xia",
                "given": "Jiazhi",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wang",
                "given": "Zhongyuan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhu",
                "given": "Jun",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Pfister",
                "given": "Hanspeter",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Liu",
                "given": "Shixia",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Diagnosing Ensemble Few-Shot Classifiers",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "9",
        "pages": "3292\u20133306",
        "article_number": "",
        "number_of_pages": 15,
        "abstract": "The base learners and labeled samples (shots) in an ensemble few-shot classifier greatly affect the model performance. When the performance is not satisfactory, it is usually difficult to understand the underlying causes and make improvements. To tackle this issue, we propose a visual analysis method, FSLDiagnotor. Given a set of base learners and a collection of samples with a few shots, we consider two problems: 1) finding a subset of base learners that well predict the sample collections; and 2) replacing the low-quality shots with more representative ones to adequately represent the sample collections. We formulate both problems as sparse subset selection and develop two selection algorithms to recommend appropriate learners and shots, respectively. A matrix visualization and a scatterplot are combined to explain the recommended learners and shots in context and facilitate users in adjusting them. Based on the adjustment, the algorithm updates the recommendation results for another round of improvement. Two case studies are conducted to demonstrate that FSLDiagnotor helps build a few-shot classifier efficiently and increases the accuracy by 12% and 21%, respectively.",
        "countries": [
            "CN",
            "US"
        ]
    },
    "10.1109/tvcg.2022.3141605": {
        "doi": "10.1109/tvcg.2022.3141605",
        "authors": [
            {
                "family": "Isenberg",
                "given": "Tobias",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Salazar",
                "given": "Zujany",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Blanco",
                "given": "Rafael",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Plaisant",
                "given": "Catherine",
                "countries": [
                    "US",
                    "FR"
                ]
            }
        ],
        "title": "Do You Believe Your (Social Media) Data? A Personal Story on Location Data Biases, Errors, and Plausibility as Well as Their Visualization",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "9",
        "pages": "3277\u20133291",
        "article_number": "",
        "number_of_pages": 15,
        "abstract": "We present a case study on a journey about a personal data collection of carnivorous plant species habitats, and the resulting scientific exploration of location data biases, data errors, location hiding, and data plausibility. While initially driven by personal interest, our work led to the analysis and development of various means for visualizing threats to insight from geo-tagged social media data. In the course of this endeavor we analyzed local and global geographic distributions and their inaccuracies. We also contribute Motion Plausibility Profiles\u2014a new means for visualizing how believable a specific contributor\u2019s location data is or if it was likely manipulated. We then compared our own repurposed social media dataset with data from a dedicated citizen science project. Compared to biases and errors in the literature on traditional citizen science data, with our visualizations we could also identify some new types or show new aspects for known ones. Moreover, we demonstrate several types of errors and biases for repurposed social media data. Please note that people with color impairments may consider our alternative paper version.",
        "countries": [
            "FR",
            "US"
        ]
    },
    "10.1109/tvcg.2022.3159630": {
        "doi": "10.1109/tvcg.2022.3159630",
        "authors": [
            {
                "family": "Abramov",
                "given": "David",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Burchett",
                "given": "Joseph N.",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Elek",
                "given": "Oskar",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Hummels",
                "given": "Cameron",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Prochaska",
                "given": "J. Xavier",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Forbes",
                "given": "Angus G.",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "CosmoVis: An Interactive Visual Analysis Tool for Exploring Hydrodynamic Cosmological Simulations",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "8",
        "pages": "2909\u20132925",
        "article_number": "",
        "number_of_pages": 17,
        "abstract": "We introduce CosmoVis, an open source web-based visualization tool for the interactive analysis of massive hydrodynamic cosmological simulation data. CosmoVis was designed in close collaboration with astrophysicists to enable researchers and citizen scientists to share and explore these datasets, and to use them to investigate a range of scientific questions. CosmoVis visualizes many key gas, dark matter, and stellar attributes extracted from the source simulations, which typically consist of complex data structures multiple terabytes in size, often requiring extensive data wrangling. CosmoVis introduces a range of features to facilitate real-time analysis of these simulations, including the use of \u201cvirtual skewers,\u201d simulated analogues of absorption line spectroscopy that act as spectral probes piercing the volume of gaseous cosmic medium. We explain how such synthetic spectra can be used to gain insight into the source datasets and to make functional comparisons with observational data. Furthermore, we identify the main analysis tasks that CosmoVis enables and present implementation details of the software interface and the client-server architecture. We conclude by providing details of three contemporary scientific use cases that were conducted by domain experts using the software and by documenting expert feedback from astrophysicists at different career levels.",
        "countries": [
            "US"
        ]
    },
    "10.1109/tvcg.2022.3151227": {
        "doi": "10.1109/tvcg.2022.3151227",
        "authors": [
            {
                "family": "Nickel",
                "given": "Soeren",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Sondag",
                "given": "Max",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Meulemans",
                "given": "Wouter",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Kobourov",
                "given": "Stephen",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Peltonen",
                "given": "Jaakko",
                "countries": [
                    "FI"
                ]
            },
            {
                "family": "N\u00f6llenburg",
                "given": "Martin",
                "countries": [
                    "AT"
                ]
            }
        ],
        "title": "Multicriteria Optimization for Dynamic Demers Cartograms",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "6",
        "pages": "2376\u20132387",
        "article_number": "",
        "number_of_pages": 12,
        "abstract": "Cartograms are popular for visualizing numerical data for administrative regions in thematic maps. When there are multiple data values per region (over time or from different datasets) shown as animated or juxtaposed cartograms, preserving the viewer\u2019s mental map in terms of stability between multiple cartograms is another important criterion alongside traditional cartogram criteria such as maintaining adjacencies. We present a method to compute stable stable Demers cartograms, where each region is shown as a square scaled proportionally to the given numerical data and similar data yield similar cartograms. We enforce orthogonal separation constraints using linear programming, and measure quality in terms of keeping adjacent regions close (cartogram quality) and using similar positions for a region between the different data values (stability). Our method guarantees the ability to connect most lost adjacencies with minimal-length planar orthogonal polylines. Experiments show that our method yields good quality and stability on multiple quality criteria.",
        "countries": [
            "AT",
            "GB",
            "NL",
            "US",
            "FI"
        ]
    },
    "10.1109/tvcg.2022.3152515": {
        "doi": "10.1109/tvcg.2022.3152515",
        "authors": [
            {
                "family": "Wu",
                "given": "Eugene",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "View Composition Algebra for Ad Hoc Comparison",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "6",
        "pages": "2470\u20132485",
        "article_number": "",
        "number_of_pages": 16,
        "abstract": "Comparison is a core task in visual analysis. Although there are numerous guidelines to help users design effective visualizations to aid known comparison tasks, there are few techniques available when users want to make ad hoc comparisons between marks, trends, or charts during data exploration and visual analysis. For instance, to compare voting count maps from different years, two stock trends in a line chart, or a scatterplot of country GDPs with a textual summary of the average GDP. Ideally, users can directly select the comparison targets and compare them, however what elements of a visualization should be candidate targets, which combinations of targets are safe to compare, and what comparison operations make sense? This article proposes a conceptual model that lets users compose combinations of values, marks, legend elements, and charts using a set of composition operators that summarize, compute differences, merge, and model their operands. We further define a View Composition Algebra (VCA) that is compatible with datacube-based visualizations, derive an interaction design based on this algebra that supports ad hoc visual comparisons, and illustrate its utility through several use cases.",
        "countries": [
            "US"
        ]
    },
    "10.1109/tvcg.2022.3155564": {
        "doi": "10.1109/tvcg.2022.3155564",
        "authors": [
            {
                "family": "Ahmed",
                "given": "Reyan",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Luca",
                "given": "Felice De",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Devkota",
                "given": "Sabin",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Kobourov",
                "given": "Stephen",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Li",
                "given": "Mingwei",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Multicriteria Scalable Graph Drawing via Stochastic Gradient Descent, $(SGD)^{2}$(SGD)2",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "6",
        "pages": "2388\u20132399",
        "article_number": "",
        "number_of_pages": 12,
        "abstract": "Readability criteria, such as distance or neighborhood preservation, are often used to optimize node-link representations of graphs to enable the comprehension of the underlying data. With few exceptions, graph drawing algorithms typically optimize one such criterion, usually at the expense of others. We propose a layout approach, Multicriteria Scalable Graph Drawing via Stochastic Gradient Descent, $(SGD)^{2}$(SGD)2, that can handle multiple readability criteria. $(SGD)^{2}$(SGD)2 can optimize any criterion that can be described by a differentiable function. Our approach is flexible and can be used to optimize several criteria that have already been considered earlier (e.g., obtaining ideal edge lengths, stress, neighborhood preservation) as well as other criteria which have not yet been explicitly optimized in such fashion (e.g., node resolution, angular resolution, aspect ratio). The approach is scalable and can handle large graphs. A variation of the underlying approach can also be used to optimize many desirable properties in planar graphs, while maintaining planarity. Finally, we provide quantitative and qualitative evidence of the effectiveness of $(SGD)^{2}$(SGD)2: we analyze the interactions between criteria, measure the quality of layouts generated from $(SGD)^{2}$(SGD)2 as well as the runtime behavior, and analyze the impact of sample sizes. The source code is available on github and we also provide an interactive demo for small graphs.",
        "countries": [
            "US"
        ]
    },
    "10.1109/tvcg.2022.3148197": {
        "doi": "10.1109/tvcg.2022.3148197",
        "authors": [
            {
                "family": "Liu",
                "given": "Zipeng",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wang",
                "given": "Yang",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Bernard",
                "given": "J\u00fcrgen",
                "countries": [
                    "CH"
                ]
            },
            {
                "family": "Munzner",
                "given": "Tamara",
                "countries": [
                    "CA"
                ]
            }
        ],
        "title": "Visualizing Graph Neural Networks With CorGIE: Corresponding a Graph to Its Embedding",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "6",
        "pages": "2500\u20132516",
        "article_number": "",
        "number_of_pages": 17,
        "abstract": "Graph neural networks (GNNs) are a class of powerful machine learning tools that model node relations for making predictions of nodes or links. GNN developers rely on quantitative metrics of the predictions to evaluate a GNN, but similar to many other neural networks, it is difficult for them to understand if the GNN truly learns characteristics of a graph as expected. We propose an approach to corresponding an input graph to its node embedding (aka latent space), a common component of GNNs that is later used for prediction. We abstract the data and tasks, and develop an interactive multi-view interface called CorGIE to instantiate the abstraction. As the key function in CorGIE, we propose the K-hop graph layout to show topological neighbors in hops and their clustering structure. To evaluate the functionality and usability of CorGIE, we present how to use CorGIE in two usage scenarios, and conduct a case study with five GNN experts. Availability: Open-source code at https://github.com/zipengliu/corgie-ui/, supplemental materials & video at https://osf.io/tr3sb/.",
        "countries": [
            "CN",
            "US",
            "CH",
            "CA"
        ]
    },
    "10.1109/tvcg.2021.3071387": {
        "doi": "10.1109/tvcg.2021.3071387",
        "authors": [
            {
                "family": "Deng",
                "given": "Zikun",
                "countries": [
                    "CN",
                    "SG"
                ]
            },
            {
                "family": "Weng",
                "given": "Di",
                "countries": [
                    "CN",
                    "SG"
                ]
            },
            {
                "family": "Liang",
                "given": "Yuxuan",
                "countries": [
                    "SG"
                ]
            },
            {
                "family": "Bao",
                "given": "Jie",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zheng",
                "given": "Yu",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Schreck",
                "given": "Tobias",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Xu",
                "given": "Mingliang",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wu",
                "given": "Yingcai",
                "countries": [
                    "CN",
                    "SG"
                ]
            }
        ],
        "title": "Visual Cascade Analytics of Large-Scale Spatiotemporal Data",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "6",
        "pages": "2486\u20132499",
        "article_number": "",
        "number_of_pages": 14,
        "abstract": "Many spatiotemporal events can be viewed as contagions. These events implicitly propagate across space and time by following cascading patterns, expanding their influence, and generating event cascades that involve multiple locations. Analyzing such cascading processes presents valuable implications in various urban applications, such as traffic planning and pollution diagnostics. Motivated by the limited capability of the existing approaches in mining and interpreting cascading patterns, we propose a visual analytics system called VisCas. VisCas combines an inference model with interactive visualizations and empowers analysts to infer and interpret the latent cascading patterns in the spatiotemporal context. To develop VisCas, we address three major challenges 1) generalized pattern inference; 2) implicit influence visualization; and 3) multifaceted cascade analysis. For the first challenge, we adapt the state-of-the-art cascading network inference technique to general urban scenarios, where cascading patterns can be reliably inferred from large-scale spatiotemporal data. For the second and third challenges, we assemble a set of effective visualizations to support location navigation, influence inspection, and cascading exploration, and facilitate the in-depth cascade analysis. We design a novel influence view based on a three-fold optimization strategy for analyzing the implicit influences of the inferred patterns. We demonstrate the capability and effectiveness of VisCas with two case studies conducted on real-world traffic congestion and air pollution datasets with domain experts.",
        "countries": [
            "CN",
            "SG",
            "AT"
        ]
    },
    "10.1109/tvcg.2022.3141040": {
        "doi": "10.1109/tvcg.2022.3141040",
        "authors": [
            {
                "family": "Chatzimparmpas",
                "given": "Angelos",
                "countries": [
                    "SE"
                ]
            },
            {
                "family": "Martins",
                "given": "Rafael M.",
                "countries": [
                    "SE"
                ]
            },
            {
                "family": "Kucher",
                "given": "Kostiantyn",
                "countries": [
                    "SE"
                ]
            },
            {
                "family": "Kerren",
                "given": "Andreas",
                "countries": [
                    "SE"
                ]
            }
        ],
        "title": "FeatureEnVi: Visual Analytics for Feature Engineering Using Stepwise Selection and Semi-Automatic Extraction Approaches",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "4",
        "pages": "1773\u20131791",
        "article_number": "",
        "number_of_pages": 19,
        "abstract": "The machine learning (ML) life cycle involves a series of iterative steps, from the effective gathering and preparation of the data\u2014including complex feature engineering processes\u2014to the presentation and improvement of results, with various algorithms to choose from in every step. Feature engineering in particular can be very beneficial for ML, leading to numerous improvements such as boosting the predictive results, decreasing computational times, reducing excessive noise, and increasing the transparency behind the decisions taken during the training. Despite that, while several visual analytics tools exist to monitor and control the different stages of the ML life cycle (especially those related to data and algorithms), feature engineering support remains inadequate. In this paper, we present FeatureEnVi, a visual analytics system specifically designed to assist with the feature engineering process. Our proposed system helps users to choose the most important feature, to transform the original features into powerful alternatives, and to experiment with different feature generation combinations. Additionally, data space slicing allows users to explore the impact of features on both local and global scales. FeatureEnVi utilizes multiple automatic feature selection techniques; furthermore, it visually guides users with statistical evidence about the influence of each feature (or subsets of features). The final outcome is the extraction of heavily engineered features, evaluated by multiple validation metrics. The usefulness and applicability of FeatureEnVi are demonstrated with two use cases and a case study. We also report feedback from interviews with two ML experts and a visualization researcher who assessed the effectiveness of our system.",
        "countries": [
            "SE"
        ]
    },
    "10.1109/tvcg.2018.2796591": {
        "doi": "10.1109/tvcg.2018.2796591",
        "authors": [
            {
                "family": "Cuenca",
                "given": "Erick",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Sallaberry",
                "given": "Arnaud",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Wang",
                "given": "Florence Y.",
                "countries": [
                    "AU"
                ]
            },
            {
                "family": "Poncelet",
                "given": "Pascal",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "MultiStream: A Multiresolution Streamgraph Approach to Explore Hierarchical Time Series",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2018,
        "volume": "24",
        "number": "12",
        "pages": "3160\u20133173",
        "article_number": "",
        "number_of_pages": 14,
        "abstract": "Multiple time series are a set of multiple quantitative variables occurring at the same interval. They are present in many domains such as medicine, finance, and manufacturing for analytical purposes. In recent years, streamgraph visualization (evolved from ThemeRiver) has been widely used for representing temporal evolution patterns in multiple time series. However, streamgraph as well as ThemeRiver suffer from scalability problems when dealing with several time series. To solve this problem, multiple time series can be organized into a hierarchical structure where individual time series are grouped hierarchically according to their proximity. In this paper, we present a new streamgraph-based approach to convey the hierarchical structure of multiple time series to facilitate the exploration and comparisons of temporal evolution. Based on a focus+context technique, our method allows time series exploration at different granularities (e.g., from overview to details). To illustrate our approach, two usage examples are presented.",
        "countries": [
            "FR",
            "AU"
        ]
    },
    "10.1109/tvcg.2021.3138933": {
        "doi": "10.1109/tvcg.2021.3138933",
        "authors": [
            {
                "family": "Chen",
                "given": "Changjian",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wu",
                "given": "Jing",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Wang",
                "given": "Xiaohan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Xiang",
                "given": "Shouxing",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhang",
                "given": "Song-Hai",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Tang",
                "given": "Qifeng",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Liu",
                "given": "Shixia",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Towards Better Caption Supervision for Object Detection",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "4",
        "pages": "1941\u20131954",
        "article_number": "",
        "number_of_pages": 14,
        "abstract": "As training high-performance object detectors requires expensive bounding box annotations, recent methods resort to free-available image captions. However, detectors trained on caption supervision perform poorly because captions are usually noisy and cannot provide precise location information. To tackle this issue, we present a visual analysis method, which tightly integrates caption supervision with object detection to mutually enhance each other. In particular, object labels are first extracted from captions, which are utilized to train the detectors. Then, the objects detected from images are fed into caption supervision for further improvement. To effectively loop users into the object detection process, a node-link-based set visualization supported by a multi-type relational co-clustering algorithm is developed to explain the relationships between the extracted labels and the images with detected objects. The co-clustering algorithm clusters labels and images simultaneously by utilizing both their representations and their relationships. Quantitative evaluations and a case study are conducted to demonstrate the efficiency and effectiveness of the developed method in improving the performance of object detectors.",
        "countries": [
            "CN",
            "GB"
        ]
    },
    "10.1109/tvcg.2021.3122388": {
        "doi": "10.1109/tvcg.2021.3122388",
        "authors": [
            {
                "family": "Zhou",
                "given": "Zixia",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zu",
                "given": "Xinrui",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Wang",
                "given": "Yuanyuan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Lelieveldt",
                "given": "Boudewijn P. F.",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Tao",
                "given": "Qian",
                "countries": [
                    "NL"
                ]
            }
        ],
        "title": "Deep Recursive Embedding for High-Dimensional Data",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "2",
        "pages": "1237\u20131248",
        "article_number": "",
        "number_of_pages": 12,
        "abstract": "Embedding high-dimensional data onto a low-dimensional manifold is of both theoretical and practical value. In this article, we propose to combine deep neural networks (DNN) with mathematics-guided embedding rules for high-dimensional data embedding. We introduce a generic deep embedding network (DEN) framework, which is able to learn a parametric mapping from high-dimensional space to low-dimensional space, guided by well-established objectives such as Kullback-Leibler (KL) divergence minimization. We further propose a recursive strategy, called deep recursive embedding (DRE), to make use of the latent data representations for boosted embedding performance. We exemplify the flexibility of DRE by different architectures and loss functions, and benchmarked our method against the two most popular embedding methods, namely, t-distributed stochastic neighbor embedding (t-SNE) and uniform manifold approximation and projection (UMAP). The proposed DRE method can map out-of-sample data and scale to extremely large datasets. Experiments on a range of public datasets demonstrated improved embedding performance in terms of local and global structure preservation, compared with other state-of-the-art embedding methods. Code is available at https://github.com/tao-aimi/DeepRecursiveEmbedding.",
        "countries": [
            "CN",
            "NL"
        ]
    },
    "10.1109/tvcg.2021.3116673": {
        "doi": "10.1109/tvcg.2021.3116673",
        "authors": [
            {
                "family": "Trepkowski",
                "given": "Christina",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Marquardt",
                "given": "Alexander",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Eibich",
                "given": "Tom David",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Shikanai",
                "given": "Yusuke",
                "countries": [
                    "JP"
                ]
            },
            {
                "family": "Maiero",
                "given": "Jens",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Kiyokawa",
                "given": "Kiyoshi",
                "countries": [
                    "JP"
                ]
            },
            {
                "family": "Kruijff",
                "given": "Ernst",
                "countries": [
                    "DE",
                    "CA"
                ]
            },
            {
                "family": "Sch\u00f6ning",
                "given": "Johannes",
                "countries": [
                    "CH"
                ]
            },
            {
                "family": "K\u00f6nig",
                "given": "Peter",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Multisensory Proximity and Transition Cues for Improving Target Awareness in Narrow Field of View Augmented Reality Displays",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "2",
        "pages": "1342\u20131362",
        "article_number": "",
        "number_of_pages": 21,
        "abstract": "Augmented reality applications allow users to enrich their real surroundings with additional digital content. However, due to the limited field of view of augmented reality devices, it can sometimes be difficult to become aware of newly emerging information inside or outside the field of view. Typical visual conflicts like clutter and occlusion of augmentations occur and can be further aggravated especially in the context of dense information spaces. In this article, we evaluate how multisensory cue combinations can improve the awareness for moving out-of-view objects in narrow field of view augmented reality displays. We distinguish between proximity and transition cues in either visual, auditory or tactile manner. Proximity cues are intended to enhance spatial awareness of approaching out-of-view objects while transition cues inform the user that the object just entered the field of view. In study 1, user preference was determined for 6 different cue combinations via forced-choice decisions. In study 2, the 3 most preferred modes were then evaluated with respect to performance and awareness measures in a divided attention reaction task. Both studies were conducted under varying noise levels. We show that on average the Visual-Tactile combination leads to 63% and Audio-Tactile to 65% faster reactions to incoming out-of-view augmentations than their Visual-Audio counterpart, indicating a high usefulness of tactile transition cues. We further show a detrimental effect of visual and audio noise on performance when feedback included visual proximity cues. Based on these results, we make recommendations to determine which cue combination is appropriate for which application.",
        "countries": [
            "DE",
            "JP",
            "CA",
            "CH"
        ]
    },
    "10.1109/tvcg.2021.3101418": {
        "doi": "10.1109/tvcg.2021.3101418",
        "authors": [
            {
                "family": "Tkachev",
                "given": "Gleb",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Frey",
                "given": "Steffen",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Ertl",
                "given": "Thomas",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "S4: Self-Supervised Learning of Spatiotemporal Similarity",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "12",
        "pages": "4713\u20134727",
        "article_number": "",
        "number_of_pages": 15,
        "abstract": "We introduce an ML-driven approach that enables interactive example-based queries for similar behavior in ensembles of spatiotemporal scientific data. This addresses an important use case in the visual exploration of simulation and experimental data, where data is often large, unlabeled and has no meaningful similarity measures available. We exploit the fact that nearby locations often exhibit similar behavior and train a Siamese Neural Network in a self-supervised fashion, learning an expressive latent space for spatiotemporal behavior. This space can be used to find similar behavior with just a few user-provided examples. We evaluate this approach on several ensemble datasets and compare with multiple existing methods, showing both qualitative and quantitative results.",
        "countries": [
            "DE",
            "NL"
        ]
    },
    "10.1109/tvcg.2021.3101854": {
        "doi": "10.1109/tvcg.2021.3101854",
        "authors": [
            {
                "family": "Fennedy",
                "given": "Katherine",
                "countries": [
                    "SG"
                ]
            },
            {
                "family": "Hartmann",
                "given": "Jeremy",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Roy",
                "given": "Quentin",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Perrault",
                "given": "Simon Tangi",
                "countries": [
                    "SG"
                ]
            },
            {
                "family": "Vogel",
                "given": "Daniel",
                "countries": [
                    "CA"
                ]
            }
        ],
        "title": "OctoPocus in VR: Using a Dynamic Guide for 3D Mid-Air Gestures in Virtual Reality",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "12",
        "pages": "4425\u20134438",
        "article_number": "",
        "number_of_pages": 14,
        "abstract": "Bau and Mackays OctoPocus dynamic guide helps novices learn, execute, and remember 2D surface gestures. We adapt OctoPocus to 3D mid-air gestures in Virtual Reality (VR) using an optimization-based recognizer, and by introducing an optional exploration mode to help visualize the spatial complexity of guides in a 3D gesture set. A replication of the original experiment protocol is used to compare OctoPocus in VR with a VR implementation of a crib-sheet. Results show that despite requiring 0.9s more reaction time than crib-sheet, OctoPocus enables participants to execute gestures 1.8s faster with 13.8 percent more accuracy during training, while remembering a comparable number of gestures. Subjective ratings support these results, 75 percent of participants found OctoPocus easier to learn and 83 percent found it more accurate. We contribute an implementation and empirical evidence demonstrating that an adaptation of the OctoPocus guide to VR is feasible and beneficial.",
        "countries": [
            "SG",
            "CA"
        ]
    },
    "10.1109/tvcg.2021.3107597": {
        "doi": "10.1109/tvcg.2021.3107597",
        "authors": [
            {
                "family": "Gao",
                "given": "Yang",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Li",
                "given": "Shuai",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Hao",
                "given": "Aimin",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Qin",
                "given": "Hong",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Simulating Multi-Scale, Granular Materials and Their Transitions With a Hybrid Euler-Lagrange Solver",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "12",
        "pages": "4483\u20134494",
        "article_number": "",
        "number_of_pages": 12,
        "abstract": "Multi-scale granular materials, such as powdered materials and mudslides, are pretty common in nature. Modeling such materials and their phase transitions remains challenging since this task involves the delicate representations of various ranges of particles with multiple scales that cause their property variations among liquid, granular solid (i.e., particles), and smoke-like materials. To effectively animate the complicated yet intriguing natural phenomena involving multi-scale granular materials and their phase transitions in graphics with high fidelity, this article advocates a hybrid Euler-Lagrange solver to handle the behaviors of involved discontinuous fluid-like materials faithfully. At the algorithmic level, we present a unified framework that tightly couples the affine particle-in-cell (APIC) solver with density field to achieve the transformation spanning across granular particles, dust cloud, powders, and their natural mixtures. For example, a part of the granular particles could be transformed into dust cloud while interacting with air and being represented by density field. Meanwhile, the velocity decrease of the involved materials could also result in the transit from the density-field-driven dust to powder particles. Besides, to further enhance our modeling and simulation power to broaden the range of multi-scale materials, we introduce a moisture property for granular particles to control the transitions between particles and viscous liquid. At the geometric level, we devise an additional surface-tracking procedure to simulate the viscous liquid phase. We can arrive at delicate viscous behaviors by controlling the corresponding yield conditions. Through various experiments with the different scenes design being conducted in our unified framework, we can validate the mixed multi-scale materials\u2019 mutual transformation processes. Our unified framework furnished with a hybrid solver can significantly enhance the modeling flexibility and the animation potential of the particle-grid hybrid materials in graphics.",
        "countries": [
            "CN",
            "US"
        ]
    },
    "10.1109/tvcg.2021.3114839": {
        "doi": "10.1109/tvcg.2021.3114839",
        "authors": [
            {
                "family": "Pont",
                "given": "Mathieu",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Vidal",
                "given": "Jules",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Delon",
                "given": "Julie",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Tierny",
                "given": "Julien",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Wasserstein Distances, Geodesics and Barycenters of Merge Trees",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "1",
        "pages": "291\u2013301",
        "article_number": "",
        "number_of_pages": 11,
        "abstract": "This paper presents a unified computational framework for the estimation of distances, geodesics and barycenters of merge trees. We extend recent work on the edit distance [104] and introduce a new metric, called the Wasserstein distance between merge trees, which is purposely designed to enable efficient computations of geodesics and barycenters. Specifically, our new distance is strictly equivalent to the $L$2-Wasserstein distance between extremum persistence diagrams, but it is restricted to a smaller solution space, namely, the space of rooted partial isomorphisms between branch decomposition trees. This enables a simple extension of existing optimization frameworks [110] for geodesics and barycenters from persistence diagrams to merge trees. We introduce a task-based algorithm which can be generically applied to distance, geodesic, barycenter or cluster computation. The task-based nature of our approach enables further accelerations with shared-memory parallelism. Extensive experiments on public ensembles and SciVis contest benchmarks demonstrate the efficiency of our approach - with barycenter computations in the orders of minutes for the largest examples - as well as its qualitative ability to generate representative barycenter merge trees, visually summarizing the features of interest found in the ensemble. We show the utility of our contributions with dedicated visualization applications: feature tracking, temporal reduction and ensemble clustering. We provide a lightweight C++ implementation that can be used to reproduce our results.",
        "countries": [
            "FR"
        ]
    },
    "10.1109/tvcg.2021.3088343": {
        "doi": "10.1109/tvcg.2021.3088343",
        "authors": [
            {
                "family": "Woodin",
                "given": "Greg",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Winter",
                "given": "Bodo",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Padilla",
                "given": "Lace",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Conceptual Metaphor and Graphical Convention Influence the Interpretation of Line Graphs",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "2",
        "pages": "1209\u20131221",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "Many metaphors in language reflect conceptual metaphors that structure thought. In line with metaphorical expressions such as \u2018high number\u2019, experiments show that people associate larger numbers with upward space. Consistent with this metaphor, high numbers are conventionally depicted in high positions on the $y$y-axis of line graphs. People also associate good and bad (emotional valence) with upward and downward locations, in line with metaphorical expressions such as \u2018uplifting\u2019 and \u2018down in the dumps\u2019. Graphs depicting good quantities (e.g., vacation days) are consistent with graphical convention and the valence metaphor, because \u2018more\u2019 of the good quantity is represented by higher $y$y-axis positions. In contrast, graphs depicting bad quantities (e.g., murders) are consistent with graphical convention, but not the valence metaphor, because more of the bad quantity is represented by higher (rather than lower) $y$y-axis positions. We conducted two experiments (N = 300 per experiment) where participants answered questions about line graphs depicting good and bad quantities. For some graphs, we inverted the conventional axis ordering of numbers. Line graphs that aligned (versus misaligned) with valence metaphors (up = good) were easier to interpret, but this beneficial effect did not outweigh the adverse effect of inverting the axis numbering. Line graphs depicting good (versus bad) quantities were easier to interpret, as were graphs that depicted quantity using the $x$x-axis (versus $y$y-axis). Our results suggest that conceptual metaphors matter for the interpretation of line graphs. However, designers of line graphs are warned against subverting graphical convention to align with conceptual metaphors.",
        "countries": [
            "GB",
            "US"
        ]
    },
    "10.1109/tvcg.2021.3067820": {
        "doi": "10.1109/tvcg.2021.3067820",
        "authors": [
            {
                "family": "Cuenca",
                "given": "Erick",
                "countries": [
                    "EC"
                ]
            },
            {
                "family": "Sallaberry",
                "given": "Arnaud",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Ienco",
                "given": "Dino",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Poncelet",
                "given": "Pascal",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "VERTIGo: A Visual Platform for Querying and Exploring Large Multilayer Networks",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "3",
        "pages": "1634\u20131647",
        "article_number": "",
        "number_of_pages": 14,
        "abstract": "Many real world data can be modeled by a graph with a set of nodes interconnected to each other by multiple relationships. Such a rich graph is called multilayer graph or network. Providing useful visualization tools to support the query process for such graphs is challenging. Although many approaches have addressed the visual query construction, few efforts have been done to provide a contextualized exploration of query results and suggestion strategies to refine the original query. This is due to several issues such as i) the size of the graphs ii) the large number of retrieved results and iii) the way they can be organized to facilitate their exploration. In this article, we present VERTIGo, a novel visual platform to query, explore and support the analysis of large multilayer graphs. VERTIGo provides coordinated views to navigate and explore the large set of retrieved results at different granularity levels. In addition, the proposed system supports the refinement of the query by visual suggestions to guide the user through the exploration process. Two examples and a user study demonstrate how VERTIGo can be used to perform visual analysis (query, exploration, and suggestion) on real world multilayer networks.",
        "countries": [
            "EC",
            "FR"
        ]
    },
    "10.1109/tvcg.2021.3084694": {
        "doi": "10.1109/tvcg.2021.3084694",
        "authors": [
            {
                "family": "Chen",
                "given": "Changjian",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wang",
                "given": "Zhaowei",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wu",
                "given": "Jing",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Wang",
                "given": "Xiting",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Guo",
                "given": "Lan-Zhe",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Li",
                "given": "Yu-Feng",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Liu",
                "given": "Shixia",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Interactive Graph Construction for Graph-Based Semi-Supervised Learning",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "9",
        "pages": "3701\u20133716",
        "article_number": "",
        "number_of_pages": 16,
        "abstract": "Semi-supervised learning (SSL) provides a way to improve the performance of prediction models (e.g., classifier) via the usage of unlabeled samples. An effective and widely used method is to construct a graph that describes the relationship between labeled and unlabeled samples. Practical experience indicates that graph quality significantly affects the model performance. In this paper, we present a visual analysis method that interactively constructs a high-quality graph for better model performance. In particular, we propose an interactive graph construction method based on the large margin principle. We have developed a river visualization and a hybrid visualization that combines a scatterplot, a node-link diagram, and a bar chart to convey the label propagation of graph-based SSL. Based on the understanding of the propagation, a user can select regions of interest to inspect and modify the graph. We conducted two case studies to showcase how our method facilitates the exploitation of labeled and unlabeled samples for improving model performance.",
        "countries": [
            "CN",
            "GB"
        ]
    },
    "10.1109/tvcg.2021.3073399": {
        "doi": "10.1109/tvcg.2021.3073399",
        "authors": [
            {
                "family": "Guo",
                "given": "Hanqi",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Lenz",
                "given": "David",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Xu",
                "given": "Jiayi",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Liang",
                "given": "Xin",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "He",
                "given": "Wenbin",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Grindeanu",
                "given": "Iulian R.",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Shen",
                "given": "Han-Wei",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Peterka",
                "given": "Tom",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Munson",
                "given": "Todd",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Foster",
                "given": "Ian",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "FTK: A Simplicial Spacetime Meshing Framework for Robust and Scalable Feature Tracking",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "8",
        "pages": "3463\u20133480",
        "article_number": "",
        "number_of_pages": 18,
        "abstract": "We present the Feature Tracking Kit (FTK), a framework that simplifies, scales, and delivers various feature-tracking algorithms for scientific data. The key of FTK is our simplicial spacetime meshing scheme that generalizes both regular and unstructured spatial meshes to spacetime while tessellating spacetime mesh elements into simplices. The benefits of using simplicial spacetime meshes include (1) reducing ambiguity cases for feature extraction and tracking, (2) simplifying the handling of degeneracies using symbolic perturbations, and (3) enabling scalable and parallel processing. The use of simplicial spacetime meshing simplifies and improves the implementation of several feature-tracking algorithms for critical points, quantum vortices, and isosurfaces. As a software framework, FTK provides end users with VTK/ParaView filters, Python bindings, a command line interface, and programming interfaces for feature-tracking applications. We demonstrate use cases as well as scalability studies through both synthetic data and scientific applications including tokamak, fluid dynamics, and superconductivity simulations. We also conduct end-to-end performance studies on the Summit supercomputer. FTK is open sourced under the MIT license: https://github.com/hguo/ftk.",
        "countries": [
            "US"
        ]
    },
    "10.1109/tvcg.2021.3076875": {
        "doi": "10.1109/tvcg.2021.3076875",
        "authors": [
            {
                "family": "Werner",
                "given": "Kilian",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Garth",
                "given": "Christoph",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Unordered Task-Parallel Augmented Merge Tree Construction",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "8",
        "pages": "3585\u20133596",
        "article_number": "",
        "number_of_pages": 12,
        "abstract": "Contemporary scientific data sets require fast and scalable topological analysis to enable visualization, simplification and interaction. Within this field, parallel merge tree construction has seen abundant recent contributions, with a trend of decentralized, task-parallel or SMP-oriented algorithms dominating in terms of total runtime. However, none of these recent approaches computed complete merge trees on distributed systems, leaving this field to traditional divide & conquer approaches. This article introduces a scalable, parallel and distributed algorithm for merge tree construction outperforming the previously fastest distributed solution by a factor of around three. This is achieved by a task-parallel identification of individual merge tree arcs by growing regions around critical points in the data, without any need for ordered progression or global data structures, based on a novel insight introducing a sufficient local boundary for region growth.",
        "countries": [
            "DE"
        ]
    },
    "10.1109/tvcg.2021.3074607": {
        "doi": "10.1109/tvcg.2021.3074607",
        "authors": [
            {
                "family": "Neuhauser",
                "given": "Christoph",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Wang",
                "given": "Junpeng",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Westermann",
                "given": "R\u00fcdiger",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Interactive Focus+Context Rendering for Hexahedral Mesh Inspection",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "8",
        "pages": "3505\u20133518",
        "article_number": "",
        "number_of_pages": 14,
        "abstract": "The visual inspection of a hexahedral mesh with respect to element quality is difficult due to clutter and occlusions that are produced when rendering all element faces or their edges simultaneously. Current approaches overcome this problem by using focus on specific elements that are then rendered opaque, and carving away all elements occluding their view. In this work, we make use of advanced GPU shader functionality to generate a focus+context rendering that highlights the elements in a selected region and simultaneously conveys the global mesh structure and deformation field. To achieve this, we propose a gradual transition from edge-based focus rendering to volumetric context rendering, by combining fragment shader-based edge and face rendering with per-pixel fragment lists. A fragment shader smoothly transitions between wireframe and face-based rendering, including focus-dependent rendering style and depth-dependent edge thickness and halos, and per-pixel fragment lists are used to blend fragments in correct visibility order. To maintain the global mesh structure in the context regions, we propose a new method to construct a sheet-based level-of-detail hierarchy and smoothly blend it with volumetric information. The user guides the exploration process by moving a lens-like hotspot. Since all operations are performed on the GPU, interactive frame rates are achieved even for large meshes.",
        "countries": [
            "DE"
        ]
    },
    "10.1109/tvcg.2021.3073466": {
        "doi": "10.1109/tvcg.2021.3073466",
        "authors": [
            {
                "family": "Helske",
                "given": "Jouni",
                "countries": [
                    "FI"
                ]
            },
            {
                "family": "Helske",
                "given": "Satu",
                "countries": [
                    "FI"
                ]
            },
            {
                "family": "Cooper",
                "given": "Matthew",
                "countries": [
                    "SE"
                ]
            },
            {
                "family": "Ynnerman",
                "given": "Anders",
                "countries": [
                    "SE"
                ]
            },
            {
                "family": "Besan\u00e7on",
                "given": "Lonni",
                "countries": [
                    "SE"
                ]
            }
        ],
        "title": "Can Visualization Alleviate Dichotomous Thinking? Effects of Visual Representations on the Cliff Effect",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "8",
        "pages": "3397\u20133409",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "Common reporting styles for statistical results in scientific articles, such as p-values and confidence intervals (CI), have been reported to be prone to dichotomous interpretations, especially with respect to the null hypothesis significance testing framework. For example when the p-value is small enough or the CIs of the mean effects of a studied drug and a placebo are not overlapping, scientists tend to claim significant differences while often disregarding the magnitudes and absolute differences in the effect sizes. This type of reasoning has been shown to be potentially harmful to science. Techniques relying on the visual estimation of the strength of evidence have been recommended to reduce such dichotomous interpretations but their effectiveness has also been challenged. We ran two experiments on researchers with expertise in statistical analysis to compare several alternative representations of confidence intervals and used Bayesian multilevel models to estimate the effects of the representation styles on differences in researchers' subjective confidence in the results. We also asked the respondents' opinions and preferences in representation styles. Our results suggest that adding visual information to classic CI representation can decrease the tendency towards dichotomous interpretations - measured as the `cliff effect': the sudden drop in confidence around p-value 0.05 - compared with classic CI visualization and textual representation of the CI with p-values. All data and analyses are publicly available at https://github.com/helske/statvis.",
        "countries": [
            "FI",
            "SE"
        ]
    },
    "10.1109/tvcg.2021.3068337": {
        "doi": "10.1109/tvcg.2021.3068337",
        "authors": [
            {
                "family": "Ajani",
                "given": "Kiran",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Lee",
                "given": "Elsie",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Xiong",
                "given": "Cindy",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Knaflic",
                "given": "Cole Nussbaumer",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Kemper",
                "given": "William",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Franconeri",
                "given": "Steven",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Declutter and Focus: Empirically Evaluating Design Guidelines for Effective Data Communication",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "10",
        "pages": "3351\u20133364",
        "article_number": "",
        "number_of_pages": 14,
        "abstract": "Data visualization design has a powerful effect on which patterns we see as salient and how quickly we see them. The visualization practitioner community prescribes two popular guidelines for creating clear and efficient visualizations: declutter and focus. The declutter guidelines suggest removing non-critical gridlines, excessive labeling of data values, and color variability to improve aesthetics and to maximize the emphasis on the data relative to the design itself. The focus guidelines for explanatory communication recommend including a clear headline that describes the relevant data pattern, highlighting a subset of relevant data values with a unique color, and connecting those values to written annotations that contextualize them in a broader argument. We evaluated how these recommendations impact recall of the depicted information across cluttered, decluttered, and decluttered+focused designs of six graph topics. Undergraduate students were asked to redraw previously seen visualizations, to recall their topics and main conclusions, and to rate the varied designs on aesthetics, clarity, professionalism, and trustworthiness. Decluttering designs led to higher ratings on professionalism, and adding focus to the design led to higher ratings on aesthetics and clarity. They also showed better memory for the highlighted pattern in the data, as reflected across redrawings of the original visualization and typed free-response conclusions, though we do not know whether these results would generalize beyond our memory-based tasks. The results largely empirically validate the intuitions of visualization designers and practitioners. The stimuli, data, analysis code, and Supplementary Materials are available at https://osf.io/wes9u/.",
        "countries": [
            "US"
        ]
    },
    "10.1109/tvcg.2021.3057519": {
        "doi": "10.1109/tvcg.2021.3057519",
        "authors": [
            {
                "family": "Garrison",
                "given": "Laura",
                "countries": [
                    "NO"
                ]
            },
            {
                "family": "M\u00fcller",
                "given": "Juliane",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Schreiber",
                "given": "Stefanie",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Oeltze-Jafra",
                "given": "Steffen",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Hauser",
                "given": "Helwig",
                "countries": [
                    "NO"
                ]
            },
            {
                "family": "Bruckner",
                "given": "Stefan",
                "countries": [
                    "NO"
                ]
            }
        ],
        "title": "DimLift: Interactive Hierarchical Data Exploration Through Dimensional Bundling",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "6",
        "pages": "2908\u20132922",
        "article_number": "",
        "number_of_pages": 15,
        "abstract": "The identification of interesting patterns and relationships is essential to exploratory data analysis. This becomes increasingly difficult in high dimensional datasets. While dimensionality reduction techniques can be utilized to reduce the analysis space, these may unintentionally bury key dimensions within a larger grouping and obfuscate meaningful patterns. With this work we introduce DimLift, a novel visual analysis method for creating and interacting with dimensional bundles. Generated through an iterative dimensionality reduction or user-driven approach, dimensional bundles are expressive groups of dimensions that contribute similarly to the variance of a dataset. Interactive exploration and reconstruction methods via a layered parallel coordinates plot allow users to lift interesting and subtle relationships to the surface, even in complex scenarios of missing and mixed data types. We exemplify the power of this technique in an expert case study on clinical cohort data alongside two additional case examples from nutrition and ecology.",
        "countries": [
            "NO",
            "DE"
        ]
    },
    "10.1109/tvcg.2021.3052167": {
        "doi": "10.1109/tvcg.2021.3052167",
        "authors": [
            {
                "family": "Hu",
                "given": "Ruizhen",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Chen",
                "given": "Bin",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Xu",
                "given": "Juzhan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Kaick",
                "given": "Oliver van",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Deussen",
                "given": "Oliver",
                "countries": [
                    "DE",
                    "CN"
                ]
            },
            {
                "family": "Huang",
                "given": "Hui",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Shape-Driven Coordinate Ordering for Star Glyph Sets via Reinforcement Learning",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "6",
        "pages": "3034\u20133047",
        "article_number": "",
        "number_of_pages": 14,
        "abstract": "We present a neural optimization model trained with reinforcement learning to solve the coordinate ordering problem for sets of star glyphs. Given a set of star glyphs associated to multiple class labels, we propose to use shape context descriptors to measure the perceptual distance between pairs of glyphs, and use the derived silhouette coefficient to measure the perception of class separability within the entire set. To find the optimal coordinate order for the given set, we train a neural network using reinforcement learning to reward orderings with high silhouette coefficients. The network consists of an encoder and a decoder with an attention mechanism. The encoder employs a recurrent neural network (RNN) to encode input shape and class information, while the decoder together with the attention mechanism employs another RNN to output a sequence with the new coordinate order. In addition, we introduce a neural network to efficiently estimate the similarity between shape context descriptors, which allows to speed up the computation of silhouette coefficients and thus the training of the axis ordering network. Two user studies demonstrate that the orders provided by our method are preferred by users for perceiving class separation. We tested our model on different settings to show its robustness and generalization abilities and demonstrate that it allows to order input sets with unseen data size, data dimension, or number of classes. We also demonstrate that our model can be adapted to coordinate ordering of other types of plots such as RadViz by replacing the proposed shape-aware silhouette coefficient with the corresponding quality metric to guide network training.",
        "countries": [
            "CN",
            "CA",
            "DE"
        ]
    },
    "10.1109/tvcg.2021.3060500": {
        "doi": "10.1109/tvcg.2021.3060500",
        "authors": [
            {
                "family": "Vidal",
                "given": "Jules",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Guillou",
                "given": "Pierre",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Tierny",
                "given": "Julien",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "A Progressive Approach to Scalar Field Topology",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "6",
        "pages": "2833\u20132850",
        "article_number": "",
        "number_of_pages": 18,
        "abstract": "This article introduces progressive algorithms for the topological analysis of scalar data. Our approach is based on a hierarchical representation of the input data and the fast identification of topologically invariant vertices, which are vertices that have no impact on the topological description of the data and for which we show that no computation is required as they are introduced in the hierarchy. This enables the definition of efficient coarse-to-fine topological algorithms, which leverage fast update mechanisms for ordinary vertices and avoid computation for the topologically invariant ones. We demonstrate our approach with two examples of topological algorithms (critical point extraction and persistence diagram computation), which generate interpretable outputs upon interruption requests and which progressively refine them otherwise. Experiments on real-life datasets illustrate that our progressive strategy, in addition to the continuous visual feedback it provides, even improves run time performance with regard to non-progressive algorithms and we describe further accelerations with shared-memory parallelism. We illustrate the utility of our approach in batch-mode and interactive setups, where it respectively enables the control of the execution time of complete topological pipelines as well as previews of the topological features found in a dataset, with progressive updates delivered within interactive times.",
        "countries": [
            "FR"
        ]
    },
    "10.1109/tvcg.2021.3055242": {
        "doi": "10.1109/tvcg.2021.3055242",
        "authors": [
            {
                "family": "Coeurjolly",
                "given": "David",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Lachaud",
                "given": "Jacques-Olivier",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Gueth",
                "given": "Pierre",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Digital Surface Regularization With Guarantees",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "6",
        "pages": "2896\u20132907",
        "article_number": "",
        "number_of_pages": 12,
        "abstract": "Voxel based modeling is a very attractive way to represent complex multi-material objects. Beside artistic choices of pixel/voxel arts, representing objects as voxels allows efficient and dynamic interactions with the scene. For geometry processing purposes, many applications in material sciences, medical imaging or numerical simulation rely on a regular partitioning of the space with labeled voxels. In this article, we consider a variational approach to reconstruct interfaces in multi-labeled digital images. This approach efficiently produces piecewise smooth quadrangulated surfaces with some theoretical stability guarantee. Non-manifold parts at intersecting interfaces are handled naturally by our model. We illustrate the strength of our tool for digital surface regularization, as well as voxel art regularization by transferring colorimetric information to regularized quads and computing isotropic geodesic on digital surfaces.",
        "countries": [
            "FR"
        ]
    },
    "10.1109/tvcg.2020.3003823": {
        "doi": "10.1109/tvcg.2020.3003823",
        "authors": [
            {
                "family": "Gao",
                "given": "Lin",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhang",
                "given": "Ling-Xiao",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Meng",
                "given": "Hsien-Yu",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Ren",
                "given": "Yi-Hui",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Lai",
                "given": "Yu-Kun",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Kobbelt",
                "given": "Leif",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "PRS-Net: Planar Reflective Symmetry Detection Net for 3D Models",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "6",
        "pages": "3007\u20133018",
        "article_number": "",
        "number_of_pages": 12,
        "abstract": "In geometry processing, symmetry is a universal type of high-level structural information of 3D models and benefits many geometry processing tasks including shape segmentation, alignment, matching, and completion. Thus it is an important problem to analyze various symmetry forms of 3D shapes. Planar reflective symmetry is the most fundamental one. Traditional methods based on spatial sampling can be time-consuming and may not be able to identify all the symmetry planes. In this article, we present a novel learning framework to automatically discover global planar reflective symmetry of a 3D shape. Our framework trains an unsupervised 3D convolutional neural network to extract global model features and then outputs possible global symmetry parameters, where input shapes are represented using voxels. We introduce a dedicated symmetry distance loss along with a regularization loss to avoid generating duplicated symmetry planes. Our network can also identify generalized cylinders by predicting their rotation axes. We further provide a method to remove invalid and duplicated planes and axes. We demonstrate that our method is able to produce reliable and accurate results. Our neural network based method is hundreds of times faster than the state-of-the-art methods, which are based on sampling. Our method is also robust even with noisy or incomplete input surfaces.",
        "countries": [
            "CN",
            "US",
            "DE"
        ]
    },
    "10.1109/tvcg.2021.3057483": {
        "doi": "10.1109/tvcg.2021.3057483",
        "authors": [
            {
                "family": "B\u00e4uerle",
                "given": "Alex",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Onzenoodt",
                "given": "Christian van",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Ropinski",
                "given": "Timo",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Net2Vis \u2013 A Visual Grammar for Automatically Generating Publication-Tailored CNN Architecture Visualizations",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "6",
        "pages": "2980\u20132991",
        "article_number": "",
        "number_of_pages": 12,
        "abstract": "To convey neural network architectures in publications, appropriate visualizations are of great importance. While most current deep learning papers contain such visualizations, these are usually handcrafted just before publication, which results in a lack of a common visual grammar, significant time investment, errors, and ambiguities. Current automatic network visualization tools focus on debugging the network itself and are not ideal for generating publication visualizations. Therefore, we present an approach to automate this process by translating network architectures specified in Keras into visualizations that can directly be embedded into any publication. To do so, we propose a visual grammar for convolutional neural networks (CNNs), which has been derived from an analysis of such figures extracted from all ICCV and CVPR papers published between 2013 and 2019. The proposed grammar incorporates visual encoding, network layout, layer aggregation, and legend generation. We have further realized our approach in an online system available to the community, which we have evaluated through expert feedback, and a quantitative study. It not only reduces the time needed to generate network visualizations for publications, but also enables a unified and unambiguous visualization design.",
        "countries": [
            "DE"
        ]
    },
    "10.1109/tvcg.2021.3056424": {
        "doi": "10.1109/tvcg.2021.3056424",
        "authors": [
            {
                "family": "M\u00fcller",
                "given": "Juliane",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Garrison",
                "given": "Laura",
                "countries": [
                    "NO"
                ]
            },
            {
                "family": "Ulbrich",
                "given": "Philipp",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Schreiber",
                "given": "Stefanie",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Bruckner",
                "given": "Stefan",
                "countries": [
                    "NO"
                ]
            },
            {
                "family": "Hauser",
                "given": "Helwig",
                "countries": [
                    "NO"
                ]
            },
            {
                "family": "Oeltze-Jafra",
                "given": "Steffen",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Integrated Dual Analysis of Quantitative and Qualitative High-Dimensional Data",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "6",
        "pages": "2953\u20132966",
        "article_number": "",
        "number_of_pages": 14,
        "abstract": "The Dual Analysis framework is a powerful enabling technology for the exploration of high dimensional quantitative data by treating data dimensions as first-class objects that can be explored in tandem with data values. In this article, we extend the Dual Analysis framework through the joint treatment of quantitative (numerical) and qualitative (categorical) dimensions. Computing common measures for all dimensions allows us to visualize both quantitative and qualitative dimensions in the same view. This enables a natural joint treatment of mixed data during interactive visual exploration and analysis. Several measures of variation for nominal qualitative data can also be applied to ordinal qualitative and quantitative data. For example, instead of measuring variability from a mean or median, other measures assess inter-data variation or average variation from a mode. In this work, we demonstrate how these measures can be integrated into the Dual Analysis framework to explore and generate hypotheses about high-dimensional mixed data. A medical case study using clinical routine data of patients suffering from Cerebral Small Vessel Disease (CSVD), conducted with a senior neurologist and a medical student, shows that a joint Dual Analysis approach for quantitative and qualitative data can rapidly lead to new insights based on which new hypotheses may be generated.",
        "countries": [
            "DE",
            "NO"
        ]
    },
    "10.1109/tvcg.2020.3045490": {
        "doi": "10.1109/tvcg.2020.3045490",
        "authors": [
            {
                "family": "Armando",
                "given": "Matthieu",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Franco",
                "given": "Jean-S\u00e9bastien",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Boyer",
                "given": "Edmond",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Mesh Denoising With Facet Graph Convolutions",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "8",
        "pages": "2999\u20133012",
        "article_number": "",
        "number_of_pages": 14,
        "abstract": "We examine the problem of mesh denoising, which consists of removing noise from corrupted 3D meshes while preserving existing geometric features. Most mesh denoising methods require a lot of mesh-specific parameter fine-tuning, to account for specific features and noise types. In recent years, data-driven methods have demonstrated their robustness and effectiveness with respect to noise and feature properties on a wide variety of geometry and image problems. Most existing mesh denoising methods still use hand-crafted features, and locally denoise facets rather than examine the mesh globally. In this work, we propose the use of a fully end-to-end learning strategy based on graph convolutions, where meaningful features are learned directly by our network. It operates on a graph of facets, directly on the existing topology of the mesh, without resampling, and follows a multi-scale design to extract geometric features at different resolution levels. Similar to most recent pipelines, given a noisy mesh, we first denoise face normals with our novel approach, then update vertex positions accordingly. Our method performs significantly better than the current state-of-the-art learning-based methods. Additionally, we show that it can be trained on noisy data, without explicit correspondence between noisy and ground-truth facets. We also propose a multi-scale denoising strategy, better suited to correct noise with a low spatial frequency.",
        "countries": [
            "FR"
        ]
    },
    "10.1109/tvcg.2020.3043487": {
        "doi": "10.1109/tvcg.2020.3043487",
        "authors": [
            {
                "family": "Lyu",
                "given": "Yan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Gao",
                "given": "Fan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wu",
                "given": "I-Shuen",
                "countries": [
                    "SG"
                ]
            },
            {
                "family": "Lim",
                "given": "Brian Y.",
                "countries": [
                    "SG"
                ]
            }
        ],
        "title": "Imma Sort by Two or More Attributes With Interpretable Monotonic Multi-Attribute Sorting",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "4",
        "pages": "2369\u20132384",
        "article_number": "",
        "number_of_pages": 16,
        "abstract": "Many choice problems often involve multiple attributes which are mentally challenging, because only one attribute is neatly sorted while others could be randomly arranged. We hypothesize that perceiving approximately monotonic trends across multiple attributes is key to the overall interpretability of sorted results, because users can easily predict the attribute values of the next items. We extend a ranking principal curve model to tune monotonic trends in attributes and present Imma Sort to sort items by multiple attributes simultaneously by trading-off the monotonicity in the primary sorted attribute to increase the human predictability for other attributes. We characterize how it performs for varying attribute correlations, attribute preferences, list lengths and number of attributes. We further extend Imma Sort with ImmaAnchor and ImmaCenter to improve the learnability and efficiency to search sorted items with conflicting attributes. We demonstrate usage scenarios for two applications and evaluate its learnability, usability, interpretability, and user performance in prediction and search tasks. We find that Imma Sort improves the interpretability and satisfaction of sorting by > 2 attributes. We discuss why, when, where, and how to deploy Imma Sort for real-world applications.",
        "countries": [
            "CN",
            "SG"
        ]
    },
    "10.1109/tvcg.2021.3051013": {
        "doi": "10.1109/tvcg.2021.3051013",
        "authors": [
            {
                "family": "Procopio",
                "given": "Marianne",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Mosca",
                "given": "Ab",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Scheidegger",
                "given": "Carlos",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Wu",
                "given": "Eugene",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Chang",
                "given": "Remco",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Impact of Cognitive Biases on Progressive Visualization",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2022,
        "volume": "28",
        "number": "9",
        "pages": "3093\u20133112",
        "article_number": "",
        "number_of_pages": 20,
        "abstract": "Progressive visualization is fast becoming a technique in the visualization community to help users interact with large amounts of data. With progressive visualization, users can examine intermediate results of complex or long running computations, without waiting for the computation to complete. While this has shown to be beneficial to users, recent research has identified potential risks. For example, users may misjudge the uncertainty in the intermediate results and draw incorrect conclusions or see patterns that are not present in the final results. In this article, we conduct a comprehensive set of studies to quantify the advantages and limitations of progressive visualization. Based on a recent report by Micallef et al., we examine four types of cognitive biases that can occur with progressive visualization: uncertainty bias, illusion bias, control bias, and anchoring bias. The results of the studies suggest a cautious but promising use of progressive visualization \u2013 while there can be significant savings in task completion time, accuracy can be negatively affected in certain conditions. These findings confirm earlier reports of the benefits and drawbacks of progressive visualization and that continued research into mitigating the effects of cognitive biases is necessary.",
        "countries": [
            "US"
        ]
    },
    "10.1109/tvcg.2020.3041745": {
        "doi": "10.1109/tvcg.2020.3041745",
        "authors": [
            {
                "family": "Duncan",
                "given": "Ian K.",
                "countries": [
                    "SG"
                ]
            },
            {
                "family": "Tingsheng",
                "given": "Shi",
                "countries": [
                    "SG"
                ]
            },
            {
                "family": "Perrault",
                "given": "Simon T.",
                "countries": [
                    "SG"
                ]
            },
            {
                "family": "Gastner",
                "given": "Michael T.",
                "countries": [
                    "SG"
                ]
            }
        ],
        "title": "Task-Based Effectiveness of Interactive Contiguous Area Cartograms",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "3",
        "pages": "2136\u20132152",
        "article_number": "",
        "number_of_pages": 17,
        "abstract": "Cartograms are map-based data visualizations in which the area of each map region is proportional to an associated numeric data value (e.g., population or gross domestic product). A cartogram is called contiguous if it conforms to this area principle while also keeping neighboring regions connected. Because of their distorted appearance, contiguous cartograms have been criticized as difficult to read. Some authors have suggested that cartograms may be more legible if they are accompanied by interactive features (e.g., animations, linked brushing, or infotips). We conducted an experiment to evaluate this claim. Participants had to perform visual analysis tasks with interactive and noninteractive contiguous cartograms. The task types covered various aspects of cartogram readability, ranging from elementary lookup tasks to synoptic tasks (i.e., tasks in which participants had to summarize high-level differences between two cartograms). Elementary tasks were carried out equally well with and without interactivity. Synoptic tasks, by contrast, were more difficult without interactive features. With access to interactivity, however, most participants answered even synoptic questions correctly. In a subsequent survey, participants rated the interactive features as \u201ceasy to use\u201d and \u201chelpful.\u201d Our study suggests that interactivity has the potential to make contiguous cartograms accessible even for those readers who are unfamiliar with interactive computer graphics or do not have a prior affinity to working with maps. Among the interactive features, animations had the strongest positive effect, so we recommend them as a minimum of interactivity when contiguous cartograms are displayed on a computer screen.",
        "countries": [
            "SG"
        ]
    },
    "10.1109/tvcg.2020.3036153": {
        "doi": "10.1109/tvcg.2020.3036153",
        "authors": [
            {
                "family": "Nehm\u00e9",
                "given": "Yana",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Dupont",
                "given": "Florent",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Farrugia",
                "given": "Jean-Philippe",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Callet",
                "given": "Patrick Le",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Lavou\u00e9",
                "given": "Guillaume",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Visual Quality of 3D Meshes With Diffuse Colors in Virtual Reality: Subjective and Objective Evaluation",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "3",
        "pages": "2202\u20132219",
        "article_number": "",
        "number_of_pages": 18,
        "abstract": "Surface meshes associated with diffuse texture or color attributes are becoming popular multimedia contents. They provide a high degree of realism and allow six degrees of freedom (6DoF) interactions in immersive virtual reality environments. Just like other types of multimedia, 3D meshes are subject to a wide range of processing, e.g., simplification and compression, which result in a loss of quality of the final rendered scene. Thus, both subjective studies and objective metrics are needed to understand and predict this visual loss. In this work, we introduce a large dataset of 480 animated meshes with diffuse color information, and associated with perceived quality judgments. The stimuli were generated from 5 source models subjected to geometry and color distortions. Each stimulus was associated with 6 hypothetical rendering trajectories (HRTs): combinations of 3 viewpoints and 2 animations. A total of 11520 quality judgments (24 per stimulus) were acquired in a subjective experiment conducted in virtual reality. The results allowed us to explore the influence of source models, animations and viewpoints on both the quality scores and their confidence intervals. Based on these findings, we propose the first metric for quality assessment of 3D meshes with diffuse colors, which works entirely on the mesh domain. This metric incorporates perceptually-relevant curvature-based and color-based features. We evaluate its performance, as well as a number of Image Quality Metrics (IQMs), on two datasets: ours and a dataset of distorted textured meshes. Our metric demonstrates good results and a better stability than IQMs. Finally, we investigated how the knowledge of the viewpoint (i.e., the visible parts of the 3D model) may improve the results of objective metrics.",
        "countries": [
            "FR"
        ]
    },
    "10.1109/tvcg.2020.3032440": {
        "doi": "10.1109/tvcg.2020.3032440",
        "authors": [
            {
                "family": "Cannav\u00f2",
                "given": "Alberto",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Calandra",
                "given": "Davide",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Prattic\u00f2",
                "given": "F. Gabriele",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Gatteschi",
                "given": "Valentina",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Lamberti",
                "given": "Fabrizio",
                "countries": [
                    "IT"
                ]
            }
        ],
        "title": "An Evaluation Testbed for Locomotion in Virtual Reality",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "3",
        "pages": "1871\u20131889",
        "article_number": "",
        "number_of_pages": 19,
        "abstract": "A common operation performed in Virtual Reality (VR) environments is locomotion. Although real walking can represent a natural and intuitive way to manage displacements in such environments, its use is generally limited by the size of the area tracked by the VR system (typically, the size of a room) or requires expensive technologies to cover particularly extended settings. A number of approaches have been proposed to enable effective explorations in VR, each characterized by different hardware requirements and costs, and capable to provide different levels of usability and performance. However, the lack of a well-defined methodology for assessing and comparing available approaches makes it difficult to identify, among the various alternatives, the best solutions for selected application domains. To deal with this issue, this article introduces a novel evaluation testbed which, by building on the outcomes of many separate works reported in the literature, aims to support a comprehensive analysis of the considered design space. An experimental protocol for collecting objective and subjective measures is proposed, together with a scoring system able to rank locomotion approaches based on a weighted set of requirements. Testbed usage is illustrated in a use case requesting to select the technique to adopt in a given application scenario.",
        "countries": [
            "IT"
        ]
    },
    "10.1109/tvcg.2020.3012120": {
        "doi": "10.1109/tvcg.2020.3012120",
        "authors": [
            {
                "family": "Henz",
                "given": "Bernardo",
                "countries": [
                    "BR"
                ]
            },
            {
                "family": "Gastal",
                "given": "Eduardo S. L.",
                "countries": [
                    "BR"
                ]
            },
            {
                "family": "Oliveira",
                "given": "Manuel M.",
                "countries": [
                    "BR"
                ]
            }
        ],
        "title": "Synthesizing Camera Noise Using Generative Adversarial Networks",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "3",
        "pages": "2123\u20132135",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "We present a technique for synthesizing realistic noise for digital photographs. It can adjust the noise level of an input photograph, either increasing or decreasing it, to match a target ISO level. Our solution learns the mappings among different ISO levels from unpaired data using generative adversarial networks. We demonstrate its effectiveness both quantitatively, using Kullback-Leibler divergence and Kolmogorov-Smirnov test, and qualitatively through a large number of examples. We also demonstrate its practical applicability by using its results to significantly improve the performance of a state-of-the-art trainable denoising method. Our technique should benefit several computer-vision applications that seek robustness to noisy scenarios.",
        "countries": [
            "BR"
        ]
    },
    "10.1109/tvcg.2020.3027069": {
        "doi": "10.1109/tvcg.2020.3027069",
        "authors": [
            {
                "family": "Zhang",
                "given": "Dongbo",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Lu",
                "given": "Xuequan",
                "countries": [
                    "AU"
                ]
            },
            {
                "family": "Qin",
                "given": "Hong",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "He",
                "given": "Ying",
                "countries": [
                    "SG"
                ]
            }
        ],
        "title": "Pointfilter: Point Cloud Filtering via Encoder-Decoder Modeling",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "3",
        "pages": "2015\u20132027",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "Point cloud filtering is a fundamental problem in geometry modeling and processing. Despite of significant advancement in recent years, the existing methods still suffer from two issues: 1) they are either designed without preserving sharp features or less robust in feature preservation; and 2) they usually have many parameters and require tedious parameter tuning. In this article, we propose a novel deep learning approach that automatically and robustly filters point clouds by removing noise and preserving their sharp features. Our point-wise learning architecture consists of an encoder and a decoder. The encoder directly takes points (a point and its neighbors) as input, and learns a latent representation vector which goes through the decoder to relate the ground-truth position with a displacement vector. The trained neural network can automatically generate a set of clean points from a noisy input. Extensive experiments show that our approach outperforms the state-of-the-art deep learning techniques in terms of both visual quality and quantitative error metrics. The source code and dataset can be found at https://github.com/dongbo-BUAA-VR/Pointfilter.",
        "countries": [
            "CN",
            "AU",
            "US",
            "SG"
        ]
    },
    "10.1109/tvcg.2020.3011155": {
        "doi": "10.1109/tvcg.2020.3011155",
        "authors": [
            {
                "family": "Ma",
                "given": "Yuxin",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Maciejewski",
                "given": "Ross",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Visual Analysis of Class Separations With Locally Linear Segments",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "1",
        "pages": "241\u2013253",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "High-dimensional labeled data widely exists in many real-world applications such as classification and clustering. One main task in analyzing such datasets is to explore class separations and class boundaries derived from machine learning models. Dimension reduction techniques are commonly applied to support analysts in exploring the underlying decision boundary structures by depicting a low-dimensional representation of the data distributions from multiple classes. However, such projection-based analyses are limited due to their lack of ability to show separations in complex non-linear decision boundary structures and can suffer from heavy distortion and low interpretability. To overcome these issues of separability and interpretability, we propose a visual analysis approach that utilizes the power of explainability from linear projections to support analysts when exploring non-linear separation structures. Our approach is to extract a set of locally linear segments that approximate the original non-linear separations. Unlike traditional projection-based analysis where the data instances are mapped to a single scatterplot, our approach supports the exploration of complex class separations through multiple local projection results. We conduct case studies on two labeled datasets to demonstrate the effectiveness of our approach.",
        "countries": [
            "US"
        ]
    },
    "10.1109/tvcg.2020.3016327": {
        "doi": "10.1109/tvcg.2020.3016327",
        "authors": [
            {
                "family": "Kim",
                "given": "Dongjoon",
                "countries": [
                    "KR"
                ]
            },
            {
                "family": "Kye",
                "given": "Heewon",
                "countries": [
                    "KR"
                ]
            },
            {
                "family": "Lee",
                "given": "Jeongjin",
                "countries": [
                    "KR"
                ]
            },
            {
                "family": "Shin",
                "given": "Yeong-Gil",
                "countries": [
                    "KR"
                ]
            }
        ],
        "title": "Confidence-Controlled Local Isosurfacing",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "1",
        "pages": "29\u201342",
        "article_number": "",
        "number_of_pages": 14,
        "abstract": "This article presents a novel framework that can generate a high-fidelity isosurface model of X-ray computed tomography (CT) data. CT surfaces with subvoxel precision and smoothness can be simply modeled via isosurfacing, where a single CT value represents an isosurface. However, this inevitably results in geometric distortion of the CT data containing CT artifacts. An alternative is to treat this challenge as a segmentation problem. However, in general, segmentation techniques are not robust against noisy data and require heavy computation to handle the artifacts that occur in three-dimensional CT data. Furthermore, the surfaces generated from segmentation results may contain jagged, overly smooth, or distorted geometries. We present a novel local isosurfacing framework that can address these issues simultaneously. The proposed framework exploits two primary techniques: 1) Canny edge approach for obtaining surface candidate boundary points and evaluating their confidence and 2) screened Poisson optimization for fitting a surface to the boundary points in which the confidence term is incorporated. This combination facilitates local isosurfacing that can produce high-fidelity surface models. We also implement an intuitive user interface to alleviate the burden of selecting the appropriate confidence computing parameters. Our experimental results demonstrate the effectiveness of the proposed framework.",
        "countries": [
            "KR"
        ]
    },
    "10.1109/tvcg.2020.3010736": {
        "doi": "10.1109/tvcg.2020.3010736",
        "authors": [
            {
                "family": "Livesu",
                "given": "Marco",
                "countries": [
                    "IT"
                ]
            }
        ],
        "title": "Scalable Mesh Refinement for Canonical Polygonal Schemas of Extremely High Genus Shapes",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2021,
        "volume": "27",
        "number": "1",
        "pages": "254\u2013260",
        "article_number": "",
        "number_of_pages": 7,
        "abstract": "Any closed manifold of genus g can be cut open to form a topological disk and then mapped to a regular polygon with 4g sides. This construction is called the canonical polygonal schema of the manifold, and is a key ingredient for many applications in graphics and engineering, where a parameterization between two shapes with same topology is often needed. The sides of the 4g-gon define on the manifold a system of loops, which all intersect at a single point and are disjoint elsewhere. Computing a shortest system of loops of this kind is NP-hard. A computationally tractable alternative consists of computing a set of shortest loops that are not fully disjoint in polynomial time using the greedy homotopy basis algorithm proposed by Erickson and Whittlesey and then detach them in post processing via mesh refinement. Despite this operation is conceptually simple, known refinement strategies do not scale well for high genus shapes, triggering a mesh growth that may exceed the amount of memory available in modern computers, leading to failures. In this article we study various local refinement operators to detach cycles in a system of loops, and show that there are important differences between them, both in terms of mesh complexity and preservation of the original surface. We ultimately propose two novel refinement approaches: the former greatly reduces the number of new elements in the mesh, possibly at the cost of a deviation from the input geometry. The latter allows to trade mesh complexity for geometric accuracy, bounding deviation from the input surface. Both strategies are trivial to implement, and experiments confirm that they allow to realize canonical polygonal schemas even for extremely high genus shapes where previous methods fail.",
        "countries": [
            "IT"
        ]
    },
    "10.1109/tvcg.2020.3004245": {
        "doi": "10.1109/tvcg.2020.3004245",
        "authors": [
            {
                "family": "Bender",
                "given": "Jan",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Kugelstadt",
                "given": "Tassilo",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Weiler",
                "given": "Marcel",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Koschier",
                "given": "Dan",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Implicit Frictional Boundary Handling for SPH",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2020,
        "volume": "26",
        "number": "10",
        "pages": "2982\u20132993",
        "article_number": "",
        "number_of_pages": 12,
        "abstract": "In this article, we present a novel method for the robust handling of static and dynamic rigid boundaries in Smoothed Particle Hydrodynamics (SPH) simulations. We build upon the ideas of the density maps approach which has been introduced recently by Koschier and Bender. They precompute the density contributions of solid boundaries and store them on a spatial grid which can be efficiently queried during runtime. This alleviates the problems of commonly used boundary particles, like bumpy surfaces and inaccurate pressure forces near boundaries. Our method is based on a similar concept but we precompute the volume contribution of the boundary geometry. This maintains all benefits of density maps but offers a variety of advantages which are demonstrated in several experiments. First, in contrast to the density maps method we can compute derivatives in the standard SPH manner by differentiating the kernel function. This results in smooth pressure forces, even for lower map resolutions, such that precomputation times and memory requirements are reduced by more than two orders of magnitude compared to density maps. Furthermore, this directly fits into the SPH concept so that volume maps can be seamlessly combined with existing SPH methods. Finally, the kernel function is not baked into the map such that the same volume map can be used with different kernels. This is especially useful when we want to incorporate common surface tension or viscosity methods that use different kernels than the fluid simulation.",
        "countries": [
            "DE"
        ]
    },
    "10.1109/tvcg.2020.2966702": {
        "doi": "10.1109/tvcg.2020.2966702",
        "authors": [
            {
                "family": "Nu\u00f1ez-Garcia",
                "given": "Marta",
                "countries": [
                    "ES"
                ]
            },
            {
                "family": "Bernardino",
                "given": "Gabriel",
                "countries": [
                    "ES"
                ]
            },
            {
                "family": "Alarc\u00f3n",
                "given": "Francisco",
                "countries": [
                    "ES"
                ]
            },
            {
                "family": "Caixal",
                "given": "Gala",
                "countries": [
                    "ES"
                ]
            },
            {
                "family": "Mont",
                "given": "Llu\u00eds",
                "countries": [
                    "ES"
                ]
            },
            {
                "family": "Camara",
                "given": "Oscar",
                "countries": [
                    "ES"
                ]
            },
            {
                "family": "Butakoff",
                "given": "Constantine",
                "countries": [
                    "ES"
                ]
            }
        ],
        "title": "Fast Quasi-Conformal Regional Flattening of the Left Atrium",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2020,
        "volume": "26",
        "number": "8",
        "pages": "2591\u20132602",
        "article_number": "",
        "number_of_pages": 12,
        "abstract": "Two-dimensional representation of 3D anatomical structures is a simple and intuitive way for analysing patient information across populations and image modalities. While cardiac ventricles, especially the left ventricle, have an established standard representation (bull's eye plot), the 2D depiction of the left atrium (LA) remains challenging due to its sub-structural complexity including the pulmonary veins (PV) and the left atrial appendage (LAA). Quasi-conformal flattening techniques, successfully applied to cardiac ventricles, require additional constraints in the case of the LA to place the PV and LAA in the same geometrical 2D location for different cases. Some registration-based methods have been proposed but surface registration is time-consuming and prone to errors when the geometries are very different. We propose a novel atrial flattening methodology where a 2D standardised map of the LA is obtained quickly and without errors related to registration. The LA is divided into five regions which are then mapped to their analogue two-dimensional regions. 67 human left atria from magnetic resonance images (MRI) were studied to derive a population-based template representing the averaged relative locations of the PVs and LAA. The clinical application of our methodology is illustrated on different use cases including the integration of MRI and electroanatomical data.",
        "countries": [
            "ES"
        ]
    },
    "10.1109/tvcg.2020.2990315": {
        "doi": "10.1109/tvcg.2020.2990315",
        "authors": [
            {
                "family": "Monica",
                "given": "Riccardo",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Aleotti",
                "given": "Jacopo",
                "countries": [
                    "IT"
                ]
            }
        ],
        "title": "Surfel-Based Incremental Reconstruction of the Boundary Between Known and Unknown Space",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2020,
        "volume": "26",
        "number": "8",
        "pages": "2683\u20132695",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "This article presents the first surfel-based method for multi-view 3D reconstruction of the boundary between known and unknown space. The proposed approach integrates multiple views from a moving depth camera and it generates a set of surfels that encloses observed empty space, i.e., it models both the boundary between empty and occupied space, and the boundary between empty and unknown space. One novelty of the method is that it does not require a persistent voxel map of the environment to distinguish between unknown and empty space. The problem is solved thanks to an incremental algorithm that computes the Boolean union of two surfel bounded volumes: the known volume from previous frames and the space observed from the current depth image. A number of strategies were developed to cope with errors in surfel position and orientation. The method, implemented on CPU and GPU, was evaluated on real data acquired in indoor scenarios, and it was compared against state of the art approaches. Results show that the proposed method has a low number of false positive and false negatives, it is faster than a standard volumetric algorithm, it has a lower memory consumption, and it scales better in large environments.",
        "countries": [
            "IT"
        ]
    },
    "10.1109/tvcg.2020.2988476": {
        "doi": "10.1109/tvcg.2020.2988476",
        "authors": [
            {
                "family": "Jiang",
                "given": "Boyi",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhang",
                "given": "Juyong",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Cai",
                "given": "Jianfei",
                "countries": [
                    "AU"
                ]
            },
            {
                "family": "Zheng",
                "given": "Jianmin",
                "countries": [
                    "SG"
                ]
            }
        ],
        "title": "Disentangled Human Body Embedding Based on Deep Hierarchical Neural Network",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2020,
        "volume": "26",
        "number": "8",
        "pages": "2560\u20132575",
        "article_number": "",
        "number_of_pages": 16,
        "abstract": "Human bodies exhibit various shapes for different identities or poses, but the body shape has certain similarities in structure and thus can be embedded in a low-dimensional space. This article presents an autoencoder-like network architecture to learn disentangled shape and pose embedding specifically for the 3D human body. This is inspired by recent progress of deformation-based latent representation learning. To improve the reconstruction accuracy, we propose a hierarchical reconstruction pipeline for the disentangling process and construct a large dataset of human body models with consistent connectivity for the learning of the neural network. Our learned embedding can not only achieve superior reconstruction accuracy but also provide great flexibility in 3D human body generation via interpolation, bilinear interpolation, and latent space sampling. The results from extensive experiments demonstrate the powerfulness of our learned 3D human body embedding in various applications.",
        "countries": [
            "CN",
            "AU",
            "SG"
        ]
    },
    "10.1109/tvcg.2020.2986996": {
        "doi": "10.1109/tvcg.2020.2986996",
        "authors": [
            {
                "family": "Chatzimparmpas",
                "given": "Angelos",
                "countries": [
                    "SE"
                ]
            },
            {
                "family": "Martins",
                "given": "Rafael M.",
                "countries": [
                    "SE"
                ]
            },
            {
                "family": "Kerren",
                "given": "Andreas",
                "countries": [
                    "SE"
                ]
            }
        ],
        "title": "t-viSNE: Interactive Assessment and Interpretation of t-SNE Projections",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2020,
        "volume": "26",
        "number": "8",
        "pages": "2696\u20132714",
        "article_number": "",
        "number_of_pages": 19,
        "abstract": "t-Distributed Stochastic Neighbor Embedding (t-SNE) for the visualization of multidimensional data has proven to be a popular approach, with successful applications in a wide range of domains. Despite their usefulness, t-SNE projections can be hard to interpret or even misleading, which hurts the trustworthiness of the results. Understanding the details of t-SNE itself and the reasons behind specific patterns in its output may be a daunting task, especially for non-experts in dimensionality reduction. In this article, we present t-viSNE, an interactive tool for the visual exploration of t-SNE projections that enables analysts to inspect different aspects of their accuracy and meaning, such as the effects of hyper-parameters, distance and neighborhood preservation, densities and costs of specific neighborhoods, and the correlations between dimensions and visual patterns. We propose a coherent, accessible, and well-integrated collection of different views for the visualization of t-SNE projections. The applicability and usability of t-viSNE are demonstrated through hypothetical usage scenarios with real data sets. Finally, we present the results of a user study where the tool's effectiveness was evaluated. By bringing to light information that would normally be lost after running t-SNE, we hope to support analysts in using t-SNE and making its results better understandable.",
        "countries": [
            "SE"
        ]
    },
    "10.1109/tvcg.2019.2945961": {
        "doi": "10.1109/tvcg.2019.2945961",
        "authors": [
            {
                "family": "Chen",
                "given": "Zhen",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Panozzo",
                "given": "Daniele",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Dumas",
                "given": "J\u00e9r\u00e9mie",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Half-Space Power Diagrams and Discrete Surface Offsets",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2020,
        "volume": "26",
        "number": "10",
        "pages": "2970\u20132981",
        "article_number": "",
        "number_of_pages": 12,
        "abstract": "We present an efficient, trivially parallelizable algorithm to compute offset surfaces of shapes discretized using a dexel data structure. Our algorithm is based on a two-stage sweeping procedure that is simple to implement and efficient, entirely avoiding volumetric distance field computations typical of existing methods. Our construction is based on properties of half-space power diagrams, where each seed is only visible by a half-space, which were never used before for the computation of surface offsets. The primary application of our method is interactive modeling for digital fabrication. Our technique enables a user to interactively process high-resolution models. It is also useful in a plethora of other geometry processing tasks requiring fast, approximate offsets, such as topology optimization, collision detection, and skeleton extraction. We present experimental timings, comparisons with previous approaches, and provide a reference implementation in the supplemental material, which can be found on the Computer Society Digital Library at http://doi.ieeecomputersociety.org/10.1109/TVCG.2019.2945961.",
        "countries": [
            "CN",
            "US"
        ]
    },
    "10.1109/tvcg.2019.2934256": {
        "doi": "10.1109/tvcg.2019.2934256",
        "authors": [
            {
                "family": "Vidal",
                "given": "Jules",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Budin",
                "given": "Joseph",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Tierny",
                "given": "Julien",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Progressive Wasserstein Barycenters of Persistence Diagrams",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2020,
        "volume": "26",
        "number": "1",
        "pages": "151\u2013161",
        "article_number": "",
        "number_of_pages": 11,
        "abstract": "This paper presents an efficient algorithm for the progressive approximation of Wasserstein barycenters of persistence diagrams, with applications to the visual analysis of ensemble data. Given a set of scalar fields, our approach enables the computation of a persistence diagram which is representative of the set, and which visually conveys the number, data ranges and saliences of the main features of interest found in the set. Such representative diagrams are obtained by computing explicitly the discrete Wasserstein barycenter of the set of persistence diagrams, a notoriously computationally intensive task. In particular, we revisit efficient algorithms for Wasserstein distance approximation [12,51] to extend previous work on barycenter estimation [94]. We present a new fast algorithm, which progressively approximates the barycenter by iteratively increasing the computation accuracy as well as the number of persistent features in the output diagram. Such a progressivity drastically improves convergence in practice and allows to design an interruptible algorithm, capable of respecting computation time constraints. This enables the approximation of Wasserstein barycenters within interactive times. We present an application to ensemble clustering where we revisit the k-means algorithm to exploit our barycenters and compute, within execution time constraints, meaningful clusters of ensemble data along with their barycenter diagram. Extensive experiments on synthetic and real-life data sets report that our algorithm converges to barycenters that are qualitatively meaningful with regard to the applications, and quantitatively comparable to previous techniques, while offering an order of magnitude speedup when run until convergence (without time constraint). Our algorithm can be trivially parallelized to provide additional speedups in practice on standard workstations. We provide a lightweight C++ implementation of our approach that can be used to reproduce our results.",
        "countries": [
            "FR"
        ]
    },
    "10.1109/tvcg.2019.2892483": {
        "doi": "10.1109/tvcg.2019.2892483",
        "authors": [
            {
                "family": "Huang",
                "given": "Zhaosong",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Lu",
                "given": "Yafeng",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Mack",
                "given": "Elizabeth A.",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Chen",
                "given": "Wei",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Maciejewski",
                "given": "Ross",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Exploring the Sensitivity of Choropleths under Attribute Uncertainty",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2020,
        "volume": "26",
        "number": "8",
        "pages": "2576\u20132590",
        "article_number": "",
        "number_of_pages": 15,
        "abstract": "The choropleth map is an essential tool for spatial data analysis. However, the underlying attribute values of a spatial unit greatly influence the statistical analyses and map classification procedures when generating a choropleth map. If the attribute values incorporate a range of uncertainty, a critical task is determining how much the uncertainty impacts both the map visualization and the statistical analysis. In this paper, we present a visual analytics system that enhances our understanding of the impact of attribute uncertainty on data visualization and statistical analyses of these data. Our system consists of a parallel coordinates-based uncertainty specification view, an impact river and impact matrix visualization for region-based and simulation-based analysis, and a dual-choropleth map and t-SNE plot for visualizing the changes in classification and spatial autocorrelation over the range of uncertainty in the attribute values. We demonstrate our system through three use cases illustrating the impact of attribute uncertainty in geographic analysis.",
        "countries": [
            "CN",
            "US"
        ]
    },
    "10.1109/tvcg.2018.2864432": {
        "doi": "10.1109/tvcg.2018.2864432",
        "authors": [
            {
                "family": "Favelier",
                "given": "Guillaume",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Faraj",
                "given": "Noura",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Summa",
                "given": "Brian",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Tierny",
                "given": "Julien",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Persistence Atlas for Critical Point Variability in Ensembles",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2019,
        "volume": "25",
        "number": "1",
        "pages": "1152\u20131162",
        "article_number": "",
        "number_of_pages": 11,
        "abstract": "This paper presents a new approach for the visualization and analysis of the spatial variability of features of interest represented by critical points in ensemble data. Our framework, called Persistence Atlas, enables the visualization of the dominant spatial patterns of critical points, along with statistics regarding their occurrence in the ensemble. The persistence atlas represents in the geometrical domain each dominant pattern in the form of a confidence map for the appearance of critical points. As a by-product, our method also provides 2-dimensional layouts of the entire ensemble, highlighting the main trends at a global level. Our approach is based on the new notion of Persistence Map, a measure of the geometrical density in critical points which leverages the robustness to noise of topological persistence to better emphasize salient features. We show how to leverage spectral embedding to represent the ensemble members as points in a low-dimensional Euclidean space, where distances between points measure the dissimilarities between critical point layouts and where statistical tasks, such as clustering, can be easily carried out. Further, we show how the notion of mandatory critical point can be leveraged to evaluate for each cluster confidence regions for the appearance of critical points. Most of the steps of this framework can be trivially parallelized and we show how to efficiently implement them. Extensive experiments demonstrate the relevance of our approach. The accuracy of the confidence regions provided by the persistence atlas is quantitatively evaluated and compared to a baseline strategy using an off-the-shelf clustering approach. We illustrate the importance of the persistence atlas in a variety of real-life datasets, where clear trends in feature layouts are identified and analyzed. We provide a lightweight VTK-based C++ implementation of our approach that can be used for reproduction purposes.",
        "countries": [
            "FR",
            "US"
        ]
    },
    "10.1109/tvcg.2018.2828818": {
        "doi": "10.1109/tvcg.2018.2828818",
        "authors": [
            {
                "family": "Yadav",
                "given": "Sunil Kumar",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Reitebuch",
                "given": "Ulrich",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Polthier",
                "given": "Konrad",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Robust and High Fidelity Mesh Denoising",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2019,
        "volume": "25",
        "number": "6",
        "pages": "2304\u20132310",
        "article_number": "",
        "number_of_pages": 7,
        "abstract": "This paper presents a simple and effective two-stage mesh denoising algorithm, where in the first stage, face normal filtering is done by using bilateral normal filtering in a robust statistics framework. Tukey's bi-weight function is used as similarity function in the bilateral weighting, which is a robust estimator and stops the diffusion at sharp edges to retain features and removes noise from flat regions effectively. In the second stage, an edge-weighted Laplace operator is introduced to compute a differential coordinate. This differential coordinate helps the algorithm to produce a high-quality mesh without any face normal flips and makes the method robust against high-intensity noise.",
        "countries": [
            "DE"
        ]
    },
    "10.1111/cgf.14910": {
        "doi": "10.1111/cgf.14910",
        "authors": [
            {
                "family": "Lachaud",
                "given": "Jacques-Olivier",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Coeurjolly",
                "given": "David",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Labart",
                "given": "C\u00e9line",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Romon",
                "given": "Pascal",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Thibert",
                "given": "Boris",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Lightweight Curvature Estimation on Point Clouds with Randomized Corrected Curvature Measures",
        "journal": "Computer Graphics Forum",
        "publication_year": 2023,
        "volume": "42",
        "number": "5",
        "pages": "e14910:1\u2013e14910:12",
        "article_number": "e14910",
        "number_of_pages": 12,
        "abstract": "The estimation of differential quantities on oriented point cloud is a classical step for many geometry processing tasks in computer graphics and vision. Even if many solutions exist to estimate such quantities, they usually fail at satisfying both a stable estimation with theoretical guarantee, and the efficiency of the associated algorithm. Relying on the notion of corrected curvature measures [LRT22, LRTC20] designed for surfaces, the method introduced in this paper meets both requirements. Given a point of interest and a few nearest neighbours, our method estimates the whole curvature tensor information by generating random triangles within these neighbours and normalising the corrected curvature measures by the corrected area measure. We provide a stability theorem showing that our pointwise curvatures are accurate and convergent, provided the noise in position and normal information has a variance smaller than the radius of neighbourhood. Experiments and comparisons with the state-of-the-art confirm that our approach is more accurate and much faster than alternatives. The method is fully parallelizable, requires only one nearest neighbour request per point of computation, and is trivial to implement.",
        "countries": [
            "FR"
        ]
    },
    "10.1111/cgf.14747": {
        "doi": "10.1111/cgf.14747",
        "authors": [
            {
                "family": "Schmidt",
                "given": "Patrick",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Pieper",
                "given": "D\u00f6rte",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Kobbelt",
                "given": "Leif",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Surface Maps via Adaptive Triangulations",
        "journal": "Computer Graphics Forum",
        "publication_year": 2023,
        "volume": "42",
        "number": "2",
        "pages": "103\u2013117",
        "article_number": "",
        "number_of_pages": 15,
        "abstract": "We present a new method to compute continuous and bijective maps (surface homeomorphisms) between two or more genus-0 triangle meshes. In contrast to previous approaches, we decouple the resolution at which a map is represented from the resolution of the input meshes. We discretize maps via common triangulations that approximate the input meshes while remaining in bijective correspondence to them. Both the geometry and the connectivity of these triangulations are optimized with respect to a single objective function that simultaneously controls mapping distortion, triangulation quality, and approximation error. A discrete-continuous optimization algorithm performs both energy-based remeshing as well as global second-order optimization of vertex positions, parametrized via the sphere. With this, we combine the disciplines of compatible remeshing and surface map optimization in a unified formulation and make a contribution in both fields. While existing compatible remeshing algorithms often operate on a fixed pre-computed surface map, we can now globally update this correspondence during remeshing. On the other hand, bijective surface-to-surface map optimization previously required computing costly overlay meshes that are inherently tied to the input mesh resolution. We achieve significant complexity reduction by instead assessing distortion between the approximating triangulations. This new map representation is inherently more robust than previous overlay-based approaches, is less intricate to implement, and naturally supports mapping between more than two surfaces. Moreover, it enables adaptive multi-resolution schemes that, e.g., first align corresponding surface regions at coarse resolutions before refining the map where needed. We demonstrate significant speedups and increased flexibility over state-of-the art mapping algorithms at similar map quality, and also provide a reference implementation of the method.",
        "countries": [
            "DE"
        ]
    },
    "10.1111/cgf.14784": {
        "doi": "10.1111/cgf.14784",
        "authors": [
            {
                "family": "Ande",
                "given": "Abhijath",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Subhash",
                "given": "Varshini",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Natarajan",
                "given": "Vijay",
                "countries": [
                    "IN"
                ]
            }
        ],
        "title": "<scp>tachyon</scp>: Efficient Shared Memory Parallel Computation of Extremum Graphs",
        "journal": "Computer Graphics Forum",
        "publication_year": 2023,
        "volume": "42",
        "number": "6",
        "pages": "e14784:1\u2013e14784:13",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "The extremum graph is a succinct representation of the Morse decomposition of a scalar field. It has increasingly become a useful data structure that supports topological feature-directed visualization of 2D/3D scalar fields, and enables dimensionality reduction together with exploratory analysis of high-dimensional scalar fields. Current methods that employ the extremum graph compute it either using a simple sequential algorithm for computing the Morse decomposition or by computing the more detailed Morse\u2013Smale complex. Both approaches are typically limited to two and three-dimensional scalar fields. We describe a GPU\u2013CPU hybrid parallel algorithm for computing the extremum graph of scalar fields in all dimensions. The proposed shared memory algorithm utilizes both fine-grained parallelism and task parallelism to achieve efficiency. An open source software library, tachyon, that implements the algorithm exhibits superior performance and good scaling\u00a0behaviour.",
        "countries": [
            "IN"
        ]
    },
    "10.1111/cgf.14734": {
        "doi": "10.1111/cgf.14734",
        "authors": [
            {
                "family": "Ghorbani",
                "given": "Saeed",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Ferstl",
                "given": "Ylva",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Holden",
                "given": "Daniel",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Troje",
                "given": "Nikolaus F.",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Carbonneau",
                "given": "Marc-Andr\u00e9",
                "countries": [
                    "CA"
                ]
            }
        ],
        "title": "ZeroEGGS: Zero-shot Example-based Gesture Generation from Speech",
        "journal": "Computer Graphics Forum",
        "publication_year": 2023,
        "volume": "42",
        "number": "1",
        "pages": "206\u2013216",
        "article_number": "",
        "number_of_pages": 11,
        "abstract": "We present ZeroEGGS, a neural network framework for speech-driven gesture generation with zero-shot style control by example. This means style can be controlled via only a short example motion clip, even for motion styles unseen during training. Our model uses a Variational framework to learn a style embedding, making it easy to modify style through latent space manipulation or blending and scaling of style embeddings. The probabilistic nature of our framework further enables the generation of a variety of outputs given the input, addressing the stochastic nature of gesture motion. In a series of experiments, we first demonstrate the flexibility and generalizability of our model to new speakers and styles. In a user study, we then show that our model outperforms previous state-of-the-art techniques in naturalness of motion, appropriateness for speech, and style portrayal. Finally, we release a high-quality dataset of full-body gesture motion including fingers, with speech, spanning across 19 different styles. Our code and data are publicly available at https://github.com/ubisoft/ubisoft-laforge-ZeroEGGS.",
        "countries": [
            "CA"
        ]
    },
    "10.1111/cgf.14693": {
        "doi": "10.1111/cgf.14693",
        "authors": [
            {
                "family": "Grenier",
                "given": "Charline",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Sauvage",
                "given": "Basile",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Dischler",
                "given": "Jean-Michel",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Thery",
                "given": "Sylvain",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Color-mapped noise vector fields for generating procedural micro-patterns",
        "journal": "Computer Graphics Forum",
        "publication_year": 2022,
        "volume": "41",
        "number": "7",
        "pages": "477\u2013487",
        "article_number": "",
        "number_of_pages": 11,
        "abstract": "Stochastic micro-patterns successfully enhance the realism of virtual scenes. Procedural models using noise combined with transfer functions are extremely efficient. However, most patterns produced today employ 1D transfer functions, which assign color, transparency, or other material attributes, based solely on the single scalar quantity of noise. Multi-dimensional transfer functions have received widespread attention in other fields, such as scientific volume rendering. But their potential has not yet been well explored for modeling micro-patterns in the field of procedural texturing. We propose a new procedural model for stochastic patterns, defined as the composition of a bi-dimensional transfer function (a.k.a. color-map) with a stochastic vector field. Our model is versatile, as it encompasses several existing procedural noises, including Gaussian noise and phasor noise. It also generates a much larger gamut of patterns, including locally structured patterns which are notoriously difficult to reproduce. We leverage the Gaussian assumption and a tiling and blending algorithm to provide real-time generation and filtering. A key contribution is a real-time approximation of the second order statistics over an arbitrary pixel footprint, which enables, in addition, the filtering of procedural normal maps. We exhibit a wide variety of results, including Gaussian patterns, profiled waves, concentric and non-concentric patterns.",
        "countries": [
            "FR"
        ]
    },
    "10.1111/cgf.14487": {
        "doi": "10.1111/cgf.14487",
        "authors": [
            {
                "family": "Metzer",
                "given": "Gal",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Hanocka",
                "given": "Rana",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Giryes",
                "given": "Raja",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Mitra",
                "given": "Nilroy J.",
                "countries": [
                    "GB",
                    "IN"
                ]
            },
            {
                "family": "Cohen-Or",
                "given": "Daniel",
                "countries": [
                    "IL"
                ]
            }
        ],
        "title": "Z2P: Instant Visualization of Point Clouds",
        "journal": "Computer Graphics Forum",
        "publication_year": 2022,
        "volume": "41",
        "number": "2",
        "pages": "461\u2013471",
        "article_number": "",
        "number_of_pages": 11,
        "abstract": "We present a technique for visualizing point clouds using a neural network. Our technique allows for an instant preview of any point cloud, and bypasses the notoriously difficult surface reconstruction problem or the need to estimate oriented normals for splat-based rendering. We cast the preview problem as a conditional image-to-image translation task, and design a neural network that translates point depth-map directly into an image, where the point cloud is visualized as though a surface was reconstructed from it. Furthermore, the resulting appearance of the visualized point cloud can be, optionally, conditioned on simple control variables (e.g., color and light). We demonstrate that our technique instantly produces plausible images, and can, on-the-fly effectively handle noise, non-uniform sampling, and thin surfaces sheets.",
        "countries": [
            "IL",
            "US",
            "GB",
            "IN"
        ]
    },
    "10.1111/cgf.14609": {
        "doi": "10.1111/cgf.14609",
        "authors": [
            {
                "family": "Bukenberger",
                "given": "Dennis R.",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Buchin",
                "given": "Kevin",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Botsch",
                "given": "Mario",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Constructing <i>L</i><sub>\u221e</sub> Voronoi Diagrams in 2D and 3D",
        "journal": "Computer Graphics Forum",
        "publication_year": 2022,
        "volume": "41",
        "number": "5",
        "pages": "135\u2013147",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "Voronoi diagrams and their computation are well known in the Euclidean L2 space. They are easy to sample and render in generalized Lp spaces but nontrivial to construct geometrically. Especially the limit of this norm with p \u2192 \u221e lends itself to many quad- and hex-meshing related applications as the level-set in this space is a hypercube. Many application scenarios circumvent the actual computation of L\u221e diagrams altogether as known concepts for these diagrams are limited to 2D, uniformly weighted and axis-aligned sites. Our novel algorithm allows for the construction of generalized L\u221e Voronoi diagrams. Although parts of the developed concept theoretically extend to higher dimensions it is herein presented and evaluated for the 2D and 3D case. It further supports individually oriented sites and allows for generating weighted diagrams with anisotropic weight vectors for individual sites. The algorithm is designed around individual sites, and initializes their cells with a simple meshed representation of a site's level-set. Hyperplanes between adjacent cells cut the initialization geometry into convex polyhedra. Non-cell geometry is filtered out based on the L\u221e Voronoi criterion, leaving only the non-convex cell geometry. Eventually we conclude with discussions on the algorithms complexity, numerical precision and analyze the applicability of our generalized L\u221e diagrams for the construction of Centroidal Voronoi Tessellations (CVT) using Lloyd's algorithm.",
        "countries": [
            "DE"
        ]
    },
    "10.1111/cgf.14615": {
        "doi": "10.1111/cgf.14615",
        "authors": [
            {
                "family": "Arleo",
                "given": "Alessio",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Miksch",
                "given": "Silvia",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Archambault",
                "given": "Daniel",
                "countries": [
                    "GB"
                ]
            }
        ],
        "title": "Event-based Dynamic Graph Drawing without the Agonizing Pain",
        "journal": "Computer Graphics Forum",
        "publication_year": 2022,
        "volume": "41",
        "number": "6",
        "pages": "226\u2013244",
        "article_number": "",
        "number_of_pages": 19,
        "abstract": "Temporal networks can naturally model real-world complex phenomena such as contact networks, information dissemination and physical proximity. However, nodes and edges bear real-time coordinates, making it difficult to organize them into discrete timeslices, without a loss of temporal information due to projection. Event-based dynamic graph drawing rejects the notion of a timeslice and allows each node and edge to retain its own real-valued time coordinate. While existing work has demonstrated clear advantages for this approach, they come at a running time cost. We investigate the problem of accelerating event-based layout to make it more competitive with existing layout techniques. In this paper, we describe the design, implementation and experimental evaluation of MultiDynNoS, the first multi-level event-based graph layout algorithm. We consider three operators for coarsening and placement, inspired by Walshaw, GRIP and FM3, which we couple with an event-based graph drawing algorithm. We also propose two extensions to the core algorithm: AutoTau and Bend Transfer. We perform two experiments: first, we compare MultiDynNoS variants to existing state-of-the-art dynamic graph layout approaches; second, we investigate the impact of each of the proposed algorithm extensions. MultiDynNoS proves to be competitive with existing approaches, and the proposed extensions achieve their design goals and contribute in opening new research directions.",
        "countries": [
            "AT",
            "GB"
        ]
    },
    "10.1111/cgf.14550": {
        "doi": "10.1111/cgf.14550",
        "authors": [
            {
                "family": "Sereno",
                "given": "Mickael",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Gosset",
                "given": "St\u00e9phane",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Besan\u00e7on",
                "given": "Lonni",
                "countries": [
                    "SE"
                ]
            },
            {
                "family": "Isenberg",
                "given": "Tobias",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Hybrid Touch/Tangible Spatial Selection in Augmented Reality",
        "journal": "Computer Graphics Forum",
        "publication_year": 2022,
        "volume": "41",
        "number": "3",
        "pages": "403\u2013415",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "We study tangible touch tablets combined with Augmented Reality Head-Mounted Displays (AR-HMDs) to perform spatial 3D selections. We are primarily interested in the exploration of 3D unstructured datasets such as cloud points or volumetric datasets. AR-HMDs immerse users by showing datasets stereoscopically, and tablets provide a set of 2D exploration tools. Because AR-HMDs merge the visualization, interaction, and the users' physical spaces, users can also use the tablets as tangible objects in their 3D space. Nonetheless, the tablets' touch displays provide their own visualization and interaction spaces, separated from those of the AR-HMD. This raises several research questions compared to traditional setups. In this paper, we theorize, discuss, and study different available mappings for manual spatial selections using a tangible tablet within an AR-HMD space. We then study the use of this tablet within a 3D AR environment, compared to its use with a 2D external screen.",
        "countries": [
            "FR",
            "SE"
        ]
    },
    "10.1111/cgf.14607": {
        "doi": "10.1111/cgf.14607",
        "authors": [
            {
                "family": "Schmidt",
                "given": "Patrick",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Born",
                "given": "Janis",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Bommes",
                "given": "David",
                "countries": [
                    "CH"
                ]
            },
            {
                "family": "Campen",
                "given": "Marcel",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Kobbelt",
                "given": "Leif",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "TinyAD: Automatic Differentiation in Geometry Processing Made Simple",
        "journal": "Computer Graphics Forum",
        "publication_year": 2022,
        "volume": "41",
        "number": "5",
        "pages": "113\u2013124",
        "article_number": "",
        "number_of_pages": 12,
        "abstract": "Non-linear optimization is essential to many areas of geometry processing research. However, when experimenting with different problem formulations or when prototyping new algorithms, a major practical obstacle is the need to figure out derivatives of objective functions, especially when second-order derivatives are required. Deriving and manually implementing gradients and Hessians is both time-consuming and error-prone. Automatic differentiation techniques address this problem, but can introduce a diverse set of obstacles themselves, e.g. limiting the set of supported language features, imposing restrictions on a program's control flow, incurring a significant run time overhead, or making it hard to exploit sparsity patterns common in geometry processing. We show that for many geometric problems, in particular on meshes, the simplest form of forward-mode automatic differentiation is not only the most flexible, but also actually the most efficient choice. We introduce TinyAD: a lightweight C++ library that automatically computes gradients and Hessians, in particular of sparse problems, by differentiating small (tiny) sub-problems. Its simplicity enables easy integration; no restrictions on, e.g., looping and branching are imposed. TinyAD provides the basic ingredients to quickly implement first and second order Newton-style solvers, allowing for flexible adjustment of both problem formulations and solver details. By showcasing compact implementations of methods from parametrization, deformation, and direction field design, we demonstrate how TinyAD lowers the barrier to exploring non-linear optimization techniques. This enables not only fast prototyping of new research ideas, but also improves replicability of existing algorithms in geometry processing. TinyAD is available to the community as an open source library.",
        "countries": [
            "DE",
            "CH"
        ]
    },
    "10.1111/cgf.14533": {
        "doi": "10.1111/cgf.14533",
        "authors": [
            {
                "family": "Hong",
                "given": "Jiayi",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Trubuil",
                "given": "Alain",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Isenberg",
                "given": "Tobias",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "LineageD: An Interactive Visual System for Plant Cell Lineage Assignments based on Correctable Machine Learning",
        "journal": "Computer Graphics Forum",
        "publication_year": 2022,
        "volume": "41",
        "number": "3",
        "pages": "195\u2013207",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "We describe LineageD\u2014a hybrid web-based system to predict, visualize, and interactively adjust plant embryo cell lineages. Currently, plant biologists explore the development of an embryo and its hierarchical cell lineage manually, based on a 3D dataset that represents the embryo status at one point in time. This human decision-making process, however, is time-consuming, tedious, and error-prone due to the lack of integrated graphical support for specifying the cell lineage. To fill this gap, we developed a new system to support the biologists in their tasks using an interactive combination of 3D visualization, abstract data visualization, and correctable machine learning to modify the proposed cell lineage. We use existing manually established cell lineages to obtain a neural network model. We then allow biologists to use this model to repeatedly predict assignments of a single cell division stage. After each hierarchy level prediction, we allow them to interactively adjust the machine learning based assignment, which we then integrate into the pool of verified assignments for further predictions. In addition to building the hierarchy this way in a bottom-up fashion, we also offer users to divide the whole embryo and create the hierarchy tree in a top-down fashion for a few steps, improving the ML-based assignments by reducing the potential for wrong predictions. We visualize the continuously updated embryo and its hierarchical development using both 3D spatial and abstract tree representations, together with information about the model's confidence and spatial properties. We conducted case study validations with five expert biologists to explore the utility of our approach and to assess the potential for LineageD to be used in their daily workflow. We found that the visualizations of both 3D representations and abstract representations help with decision making and the hierarchy tree top-down building approach can reduce assignments errors in real practice.",
        "countries": [
            "FR"
        ]
    },
    "10.1111/cgf.14402": {
        "doi": "10.1111/cgf.14402",
        "authors": [
            {
                "family": "Pan",
                "given": "Junjun",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wang",
                "given": "Siyuan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Bai",
                "given": "Junxuan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Dai",
                "given": "Ju",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Diverse Dance Synthesis via Keyframes with Transformer Controllers",
        "journal": "Computer Graphics Forum",
        "publication_year": 2021,
        "volume": "40",
        "number": "7",
        "pages": "71\u201383",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "Existing keyframe-based motion synthesis mainly focuses on the generation of cyclic actions or short-term motion, such as walking, running, and transitions between close postures. However, these methods will significantly degrade the naturalness and diversity of the synthesized motion when dealing with complex and impromptu movements , e.g., dance performance and martial arts. In addition, current research lacks fine-grained control over the generated motion, which is essential for intelligent human-computer interaction and animation creation. In this paper, we propose a novel keyframe-based motion generation network based on multiple constraints, which can achieve diverse dance synthesis via learned knowledge. Specifically, the algorithm is mainly formulated based on the recurrent neural network (RNN) and the Transformer architecture. The backbone of our network is a hierarchical RNN module composed of two long short-term memory (LSTM) units, in which the first LSTM is utilized to embed the posture information of the historical frames into a latent space, and the second one is employed to predict the human posture for the next frame. Moreover, our framework contains two Transformer-based controllers, which are used to model the constraints of the root trajectory and the velocity factor respectively, so as to better utilize the temporal context of the frames and achieve fine-grained motion control. We verify the proposed approach on a dance dataset containing a wide range of contemporary dance. The results of three quantitative analyses validate the superiority of our algorithm. The video and qualitative experimental results demonstrate that the complex motion sequences generated by our algorithm can achieve diverse and smooth motion transitions between keyframes, even for long-term synthesis.",
        "countries": [
            "CN"
        ]
    },
    "10.1111/cgf.14420": {
        "doi": "10.1111/cgf.14420",
        "authors": [
            {
                "family": "Paris",
                "given": "Axel",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Gu\u00e9rin",
                "given": "Eric",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Peytavie",
                "given": "Adrien",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Collon",
                "given": "Pauline",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Galin",
                "given": "Eric",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Synthesizing Geologically Coherent Cave Networks",
        "journal": "Computer Graphics Forum",
        "publication_year": 2021,
        "volume": "40",
        "number": "7",
        "pages": "277\u2013287",
        "article_number": "",
        "number_of_pages": 11,
        "abstract": "We present a geologically-based method to generate complex karstic networks. Karsts are a type of landscape formed by the dissolution of highly soluble rocks (generally limestones). In particular, they are characterized by complex underground networks made of varieties of tunnels and breakout chambers with stalagmites and stalactites. Our method computes skeletons of karstic networks by using a gridless anisotropic shortest path algorithm according to field data of the underground system (such as inlets and outlets), geomorphological features and parameters such as faults, inception horizons, fractures, and permeability contrasts. From this skeleton, we define the geometry of the conduits as a signed distance function construction tree combining primitives with blending and warping operators. Our framework provides multiple levels of control, allowing us to author both the structure of the karstic network and the geometric cross-section shapes and details of the generated conduits.",
        "countries": [
            "FR"
        ]
    },
    "10.1111/cgf.14488": {
        "doi": "10.1111/cgf.14488",
        "authors": [
            {
                "family": "Bedel",
                "given": "Adrien",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Coudert-Osmont",
                "given": "Yoann",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Mart\u00ednez",
                "given": "Jon\u00e0s",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Nishat",
                "given": "Rahnuma Islam",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Whitesides",
                "given": "Sue",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Lefebvre",
                "given": "Sylvain",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Closed space-filling curves with controlled orientation for 3D printing",
        "journal": "Computer Graphics Forum",
        "publication_year": 2022,
        "volume": "41",
        "number": "2",
        "pages": "473\u2013492",
        "article_number": "",
        "number_of_pages": 20,
        "abstract": "We explore the optimization of closed space-filling curves under orientation objectives. By solidifying material along the closed curve, solid layers of 3D prints can be manufactured in a single continuous extrusion motion. The control over orientation enables the deposition to align with specific directions in different areas, or to produce a locally uniform distribution of orientations, patterning the solidified volume in a precisely controlled manner. Our optimization framework proceeds in two steps. First, we cast a combinatorial problem, optimizing Hamiltonian cycles within a specially constructed graph. We rely on a stochastic optimization process based on local operators that modify a cycle while preserving its Hamiltonian property. Second, we use the result to initialize a geometric optimizer that improves the smoothness and uniform coverage of the cycle while further optimizing for alignment and orientation objectives.",
        "countries": [
            "FR",
            "CA"
        ]
    },
    "10.1111/cgf.13815": {
        "doi": "10.1111/cgf.13815",
        "authors": [
            {
                "family": "Paris",
                "given": "Axel",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Peytavie",
                "given": "Adrien",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Gu\u00e9rin",
                "given": "Eric",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Argudo",
                "given": "Oscar",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Galin",
                "given": "Eric",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Desertscape Simulation",
        "journal": "Computer Graphics Forum",
        "publication_year": 2019,
        "volume": "38",
        "number": "7",
        "pages": "47\u201355",
        "article_number": "",
        "number_of_pages": 9,
        "abstract": "We present an interactive aeolian simulation to author hot desert scenery. Wind is an important erosion agent in deserts which, despite its importance, has been neglected in computer graphics. Our framework overcomes this and allows generating a variety of sand dunes, including barchans, longitudinal and anchored dunes, and simulates abrasion which erodes bedrock and sculpts complex landforms. Given an input time varying high altitude wind field, we compute the wind field at the surface of the terrain according to the relief, and simulate the transport of sand blown by the wind. The user can interactively model complex desert landscapes, and control their evolution throughout time either by using a variety of interactive brushes or by prescribing events along a user-defined time-line.",
        "countries": [
            "FR"
        ]
    },
    "10.1111/cgf.13951": {
        "doi": "10.1111/cgf.13951",
        "authors": [
            {
                "family": "Galin",
                "given": "Eric",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Gu\u00e9rin",
                "given": "Eric",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Paris",
                "given": "Axel",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Peytavie",
                "given": "Adrien",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Segment Tracing Using Local Lipschitz Bounds",
        "journal": "Computer Graphics Forum",
        "publication_year": 2020,
        "volume": "39",
        "number": "2",
        "pages": "545\u2013554",
        "article_number": "",
        "number_of_pages": 10,
        "abstract": "We introduce Segment Tracing, a new algorithm that accelerates the classical Sphere Tracing method for computing the intersection between a ray and an implicit surface. Our approach consists in computing the Lipschitz bound locally over a segment to improve the marching step computation and accelerate the overall process. We describe the computation of the Lipschitz bound for different operators and primitives. We demonstrate that our algorithm significantly reduces the number of field function queries compared to previous methods, without the need for additional accelerating data-structures. Our method can be applied to a vast variety of implicit models ranging from hierarchical procedural objects built from complex primitives, to simulation-generated implicit surfaces created from many particles.",
        "countries": [
            "FR"
        ]
    },
    "10.1111/cgf.14460": {
        "doi": "10.1111/cgf.14460",
        "authors": [
            {
                "family": "Gu\u00e9rin",
                "given": "Eric",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Peytavie",
                "given": "Adrien",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Masnou",
                "given": "Simon",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Digne",
                "given": "Julie",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Sauvage",
                "given": "Basile",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Gain",
                "given": "James",
                "countries": [
                    "ZA"
                ]
            },
            {
                "family": "Galin",
                "given": "Eric",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Gradient Terrain Authoring",
        "journal": "Computer Graphics Forum",
        "publication_year": 2022,
        "volume": "41",
        "number": "2",
        "pages": "85\u201395",
        "article_number": "",
        "number_of_pages": 11,
        "abstract": "Digital terrains are a foundational element in the computer-generated depiction of natural scenes. Given the variety and complexity of real-world landforms, there is a need for authoring solutions that achieve perceptually realistic outcomes without sacrificing artistic control. In this paper, we propose setting aside the elevation domain in favour of modelling in the gradient domain. Such a slope-based representation is height independent and allows a seamless blending of disparate landforms from procedural, simulation, and real-world sources. For output, an elevation model can always be recovered using Poisson reconstruction, which can include Dirichlet conditions to constrain the elevation of points and curves. In terms of authoring our approach has numerous benefits. It provides artists with a complete toolbox, including: cut-and-paste operations that support warping as needed to fit the destination terrain, brushes to modify region characteristics, and sketching to provide point and curve constraints on both elevation and gradient. It is also a unifying representation that enables the inclusion of tools from the spectrum of existing procedural and simulation methods, such as painting localised high-frequency noise or hydraulic erosion, without breaking the formalism. Finally, our constrained reconstruction is GPU optimized and executes in real-time, which promotes productive cycles of iterative authoring.",
        "countries": [
            "FR",
            "ZA"
        ]
    },
    "10.1111/cgf.142632": {
        "doi": "10.1111/cgf.142632",
        "authors": [
            {
                "family": "Born",
                "given": "Janis",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Schmidt",
                "given": "Patrick",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Kobbelt",
                "given": "Leif",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Layout Embedding via Combinatorial Optimization",
        "journal": "Computer Graphics Forum",
        "publication_year": 2021,
        "volume": "40",
        "number": "2",
        "pages": "277\u2013290",
        "article_number": "",
        "number_of_pages": 14,
        "abstract": "We consider the problem of injectively embedding a given graph connectivity (a layout) into a target surface. Starting from prescribed positions of layout vertices, the task is to embed all layout edges as intersection-free paths on the surface. Besides merely geometric choices (the shape of paths) this problem is especially challenging due to its topological degrees of freedom (how to route paths around layout vertices). The problem is typically addressed through a sequence of shortest path insertions, ordered by a greedy heuristic. Such insertion sequences are not guaranteed to be optimal: Early path insertions can potentially force later paths into unexpected homotopy classes. We show how common greedy methods can easily produce embeddings of dramatically bad quality, rendering such methods unsuitable for automatic processing pipelines. Instead, we strive to find the optimal order of insertions, i.e. the one that minimizes the total path length of the embedding. We demonstrate that, despite the vast combinatorial solution space, this problem can be effectively solved on simply-connected domains via a custom-tailored branch-and-bound strategy. This enables directly using the resulting embeddings in downstream applications which cannot recover from initializations in a wrong homotopy class. We demonstrate the robustness of our method on a shape dataset by embedding a common template layout per category, and show applications in quad meshing and inter-surface mapping.",
        "countries": [
            "DE"
        ]
    },
    "10.1111/cgf.14367": {
        "doi": "10.1111/cgf.14367",
        "authors": [
            {
                "family": "Born",
                "given": "Janis",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Schmidt",
                "given": "Patrick",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Campen",
                "given": "Marcel",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Kobbelt",
                "given": "Leif",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Surface Map Homology Inference",
        "journal": "Computer Graphics Forum",
        "publication_year": 2021,
        "volume": "40",
        "number": "5",
        "pages": "193\u2013204",
        "article_number": "",
        "number_of_pages": 12,
        "abstract": "A homeomorphism between two surfaces not only defines a (continuous and bijective) geometric correspondence of points but also (by implication) an identification of topological features, i.e. handles and tunnels, and how the map twists around them. However, in practice, surface maps are often encoded via sparse correspondences or fuzzy representations that merely approximate a homeomorphism and are therefore inherently ambiguous about map topology. In this work, we show a way to infer topological information from an imperfect input map between two shapes. In particular, we compute a homology map, a linear map that transports homology classes of cycles from one surface to the other, subject to a global consistency constraint. Our inference robustly handles imperfect (e.g., partial, sparse, fuzzy, noisy, outlier-ridden, non-injective) input maps and is guaranteed to produce homology maps that are compatible with true homeomorphisms between the input shapes. Homology maps inferred by our method can be directly used to transfer homological information between shapes, or serve as foundation for the construction of a proper homeomorphism guided by the input map, e.g., via compatible surface decomposition.",
        "countries": [
            "DE"
        ]
    },
    "10.1111/cgf.14368": {
        "doi": "10.1111/cgf.14368",
        "authors": [
            {
                "family": "Lejemble",
                "given": "Thibault",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Coeurjolly",
                "given": "David",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Barthe",
                "given": "Lo\u00efc",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Mellado",
                "given": "Nicolas",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Stable and efficient differential estimators on oriented point clouds",
        "journal": "Computer Graphics Forum",
        "publication_year": 2021,
        "volume": "40",
        "number": "5",
        "pages": "205\u2013216",
        "article_number": "",
        "number_of_pages": 12,
        "abstract": "Point clouds are now ubiquitous in computer graphics and computer vision. Differential properties of the point-sampled surface, such as principal curvatures, are important to estimate in order to locally characterize the scanned shape. To approximate the surface from unstructured points equipped with normal vectors, we rely on the Algebraic Point Set Surfaces (APSS) [GG07] for which we provide convergence and stability proofs for the mean curvature estimator. Using an integral invariant viewpoint, this first contribution links the algebraic sphere regression involved in the APSS algorithm to several surface derivatives of different orders. As a second contribution, we propose an analytic method to compute the shape operator and its principal curvatures from the fitted algebraic sphere. We compare our method to the state-of-the-art with several convergence and robustness tests performed on a synthetic sampled surface. Experiments show that our curvature estimations are more accurate and stable while being faster to compute compared to previous methods. Our differential estimators are easy to implement with little memory footprint and only require a unique range neighbors query per estimation. Its highly parallelizable nature makes it appropriate for processing large acquired data, as we show in several real-world experiments.",
        "countries": [
            "FR"
        ]
    },
    "10.1111/cgf.142625": {
        "doi": "10.1111/cgf.142625",
        "authors": [
            {
                "family": "Nuvoli",
                "given": "Stefano",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Tola",
                "given": "Alessandro",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Muntoni",
                "given": "Alessandro",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Pietroni",
                "given": "Nico",
                "countries": [
                    "AU"
                ]
            },
            {
                "family": "Gobbetti",
                "given": "Enrico",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Scateni",
                "given": "Riccardo",
                "countries": [
                    "IT"
                ]
            }
        ],
        "title": "Automatic Surface Segmentation for Seamless Fabrication Using 4-axis Milling Machines",
        "journal": "Computer Graphics Forum",
        "publication_year": 2021,
        "volume": "40",
        "number": "2",
        "pages": "191\u2013203",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "We introduce a novel geometry-processing pipeline to guide the fabrication of complex shapes from a single block of material using 4-axis CNC milling machines. This setup extends classical 3-axis CNC machining with an extra degree of freedom to rotate the object around a fixed axis. The first step of our pipeline identifies the rotation axis that maximizes the overall fabrication accuracy. Then we identify two height-field regions at the rotation axis's extremes used to secure the block on the rotation tool. We segment the remaining portion of the mesh into a set of height-fields whose principal directions are orthogonal to the rotation axis. The segmentation balances the approximation quality, the boundary smoothness, and the total number of patches. Additionally, the segmentation process takes into account the object's geometric features, as well as saliency information. The output is a set of meshes ready to be processed by off-the-shelf software for the 3-axis tool-path generation. We present several results to demonstrate the quality and efficiency of our approach to a range of inputs.",
        "countries": [
            "IT",
            "AU"
        ]
    },
    "10.1111/cgf.142659": {
        "doi": "10.1111/cgf.142659",
        "authors": [
            {
                "family": "Ohrhallinger",
                "given": "Stefan",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Peethambaran",
                "given": "Jiju",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Parakkat",
                "given": "Amal Dev",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Dey",
                "given": "Tamal K.",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Muthuganapathy",
                "given": "Ramanathan",
                "countries": [
                    "IN"
                ]
            }
        ],
        "title": "2D Points Curve Reconstruction Survey and Benchmark",
        "journal": "Computer Graphics Forum",
        "publication_year": 2021,
        "volume": "40",
        "number": "2",
        "pages": "611\u2013632",
        "article_number": "",
        "number_of_pages": 22,
        "abstract": "Curve reconstruction from unstructured points in a plane is a fundamental problem with many applications that has generated research interest for decades. Involved aspects like handling open, sharp, multiple and non-manifold outlines, run-time and provability as well as potential extension to 3D for surface reconstruction have led to many different algorithms. We survey the literature on 2D curve reconstruction and then present an open-sourced benchmark for the experimental study. Our unprecedented evaluation of a selected set of planar curve reconstruction algorithms aims to give an overview of both quantitative analysis and qualitative aspects for helping users to select the right algorithm for specific problems in the field. Our benchmark framework is available online to permit reproducing the results and easy integration of new algorithms.",
        "countries": [
            "AT",
            "CA",
            "IN",
            "US"
        ]
    },
    "10.1111/cgf.142654": {
        "doi": "10.1111/cgf.142654",
        "authors": [
            {
                "family": "Rohmer",
                "given": "Damien",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Tarini",
                "given": "Marco",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Kalyanasundaram",
                "given": "Niranjan",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Moshfeghifar",
                "given": "Faezeh",
                "countries": [
                    "DK"
                ]
            },
            {
                "family": "Cani",
                "given": "Marie-Paule",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Zordan",
                "given": "Victor",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Velocity Skinning for Real-time Stylized Skeletal Animation",
        "journal": "Computer Graphics Forum",
        "publication_year": 2021,
        "volume": "40",
        "number": "2",
        "pages": "549\u2013561",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "Secondary animation effects are essential for liveliness. We propose a simple, real-time solution for adding them on top of standard skinning, enabling artist-driven stylization of skeletal motion. Our method takes a standard skeleton animation as input, along with a skin mesh and rig weights. It then derives per-vertex deformations from the different linear and angular velocities along the skeletal hierarchy. We highlight two specific applications of this general framework, namely the cartoon-like \u201csquashy\u201d and \u201cfloppy\u201d effects, achieved from specific combinations of velocity terms. As our results show, combining these effects enables to mimic, enhance and stylize physical-looking behaviours within a standard animation pipeline, for arbitrary skinned characters. Interactive on CPU, our method allows for GPU implementation, yielding real-time performances even on large meshes. Animator control is supported through a simple interface toolkit, enabling to refine the desired type and magnitude of deformation at relevant vertices by simply painting weights. The resulting rigged character automatically responds to new skeletal animation, without further input.",
        "countries": [
            "FR",
            "IT",
            "US",
            "DK"
        ]
    },
    "10.1111/cgf.13910": {
        "doi": "10.1111/cgf.13910",
        "authors": [
            {
                "family": "Lejemble",
                "given": "Thibault",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Mura",
                "given": "Claudio",
                "countries": [
                    "CH"
                ]
            },
            {
                "family": "Barthe",
                "given": "Lo\u00efc",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Mellado",
                "given": "Nicolas",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Persistence Analysis of Multi-scale Planar Structure Graph in Point Clouds",
        "journal": "Computer Graphics Forum",
        "publication_year": 2020,
        "volume": "39",
        "number": "2",
        "pages": "35\u201350",
        "article_number": "",
        "number_of_pages": 16,
        "abstract": "Modern acquisition techniques generate detailed point clouds that sample complex geometries. For instance, we are able to produce millimeter-scale acquisition of whole buildings. Processing and exploring geometrical information within such point clouds requires scalability, robustness to acquisition defects and the ability to model shapes at different scales. In this work, we propose a new representation that enriches point clouds with a multi-scale planar structure graph. We define the graph nodes as regions computed with planar segmentations at increasing scales and the graph edges connect regions that are similar across scales. Connected components of the graph define the planar structures present in the point cloud within a scale interval. For instance, with this information, any point is associated to one or several planar structures existing at different scales. We then use topological data analysis to filter the graph and provide the most prominent planar structures. Our representation naturally encodes a large range of information. We show how to efficiently extract geometrical details (e.g. tiles of a roof), arrangements of simple shapes (e.g. steps and mean ramp of a staircase), and large-scale planar proxies (e.g. walls of a building) and present several interactive tools to visualize, select and reconstruct planar primitives directly from raw point clouds. The effectiveness of our approach is demonstrated by an extensive evaluation on a variety of input data, as well as by comparing against state-of-the-art techniques and by showing applications to polygonal mesh reconstruction.",
        "countries": [
            "FR",
            "CH"
        ]
    },
    "10.1111/cgf.14061": {
        "doi": "10.1111/cgf.14061",
        "authors": [
            {
                "family": "Guehl",
                "given": "Pascal",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "All\u00e8gre",
                "given": "R\u00e9mi",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Dischler",
                "given": "Jean-Michel",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Benes",
                "given": "Bedrich",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Galin",
                "given": "Eric",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Semi-Procedural Textures Using Point Process Texture Basis Functions",
        "journal": "Computer Graphics Forum",
        "publication_year": 2020,
        "volume": "39",
        "number": "4",
        "pages": "159\u2013171",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "We introduce a novel semi-procedural approach that avoids drawbacks of procedural textures and leverages advantages of data-driven texture synthesis. We split synthesis in two parts: 1) structure synthesis, based on a procedural parametric model and 2) color details synthesis, being data-driven. The procedural model consists of a generic Point Process Texture Basis Function (PPTBF), which extends sparse convolution noises by defining rich convolution kernels. They consist of a window function multiplied with a correlated statistical mixture of Gabor functions, both designed to encapsulate a large span of common spatial stochastic structures, including cells, cracks, grains, scratches, spots, stains, and waves. Parameters can be prescribed automatically by supplying binary structure exemplars. As for noise-based Gaussian textures, the PPTBF is used as stand-alone function, avoiding classification tasks that occur when handling multiple procedural assets. Because the PPTBF is based on a single set of parameters it allows for continuous transitions between different visual structures and an easy control over its visual characteristics. Color is consistently synthesized from the exemplar using a multiscale parallel texture synthesis by numbers, constrained by the PPTBF. The generated textures are parametric, infinite and avoid repetition. The data-driven part is automatic and guarantees strong visual resemblance with inputs.",
        "countries": [
            "FR",
            "US"
        ]
    },
    "10.1111/cgf.13592": {
        "doi": "10.1111/cgf.13592",
        "authors": [
            {
                "family": "Sell\u00e1n",
                "given": "Silvia",
                "countries": [
                    "ES"
                ]
            },
            {
                "family": "Cheng",
                "given": "Herng Yi",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Ma",
                "given": "Yuming",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Dembowski",
                "given": "Mitchell",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Jacobson",
                "given": "Alec",
                "countries": [
                    "CA"
                ]
            }
        ],
        "title": "Solid Geometry Processing on Deconstructed Domains",
        "journal": "Computer Graphics Forum",
        "publication_year": 2018,
        "volume": "38",
        "number": "1",
        "pages": "564\u2013579",
        "article_number": "",
        "number_of_pages": 16,
        "abstract": "Many tasks in geometry processing are modelled as variational problems solved numerically using the finite element method. For solid shapes, this requires a volumetric discretization, such as a boundary conforming tetrahedral mesh. Unfortunately, tetrahedral meshing remains an open challenge and existing methods either struggle to conform to complex boundary surfaces or require manual intervention to prevent failure. Rather than create a single volumetric mesh for the entire shape, we advocate for solid geometry processing on deconstructed domains, where a large and complex shape is composed of overlapping solid subdomains. As each smaller and simpler part is now easier to tetrahedralize, the question becomes how to account for overlaps during problem modelling and how to couple solutions on each subdomain together algebraically. We explore how and why previous coupling methods fail, and propose a method that couples solid domains only along their boundary surfaces. We demonstrate the superiority of this method through empirical convergence tests and qualitative applications to solid geometry processing on a variety of popular second-order and fourth-order partial differential equations.",
        "countries": [
            "ES",
            "US",
            "CA"
        ]
    },
    "10.1111/cgf.13934": {
        "doi": "10.1111/cgf.13934",
        "authors": [
            {
                "family": "Mlakar",
                "given": "Daniel",
                "countries": [
                    "DE",
                    "AT"
                ]
            },
            {
                "family": "Winter",
                "given": "Martin",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Stadlbauer",
                "given": "Pascal",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Seidel",
                "given": "Hans-Peter",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Steinberger",
                "given": "Markus",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Zayer",
                "given": "Rhaleb",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Subdivision-Specialized Linear Algebra Kernels for Static and Dynamic Mesh Connectivity on the GPU",
        "journal": "Computer Graphics Forum",
        "publication_year": 2020,
        "volume": "39",
        "number": "2",
        "pages": "335\u2013349",
        "article_number": "",
        "number_of_pages": 15,
        "abstract": "Subdivision surfaces have become an invaluable asset in production environments. While progress over the last years has allowed the use of graphics hardware to meet performance demands during animation and rendering, high-performance is limited to immutable mesh connectivity scenarios. Motivated by recent progress in mesh data structures, we show how the complete Catmull-Clark subdivision scheme can be abstracted in the language of linear algebra. While this high-level formulation allows for a fully parallel implementation with significant performance gains, the underlying algebraic operations require further specialization for modern parallel hardware. Integrating domain knowledge about the mesh matrix data structure, we replace costly general linear algebra operations like matrix-matrix multiplication by specialized kernels. By further considering innate properties of Catmull-Clark subdivision, like the quad-only structure after refinement, we achieve an additional order of magnitude in performance and significantly reduce memory footprints. Our approach can be adapted seamlessly for different use cases, such as regular subdivision of dynamic meshes, fast evaluation for immutable topology and feature-adaptive subdivision for efficient rendering of animated models. In this way, patchwork solutions are avoided in favor of a streamlined solution with consistent performance gains throughout the production pipeline. The versatility of the sparse matrix linear algebra abstraction underlying our work is further demonstrated by extension to other schemes such as <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"graphic/cgf13934-math-0033.png\" xlink:title=\"Image\" /> and Loop subdivision.",
        "countries": [
            "DE",
            "AT"
        ]
    },
    "10.1111/cgf.13492": {
        "doi": "10.1111/cgf.13492",
        "authors": [
            {
                "family": "Sung",
                "given": "Minhyuk",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Dubrovina",
                "given": "Anastasia",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Kim",
                "given": "Vladimir G.",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Guibas",
                "given": "Leonidas",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Learning Fuzzy Set Representations of Partial Shapes on Dual Embedding Spaces",
        "journal": "Computer Graphics Forum",
        "publication_year": 2018,
        "volume": "37",
        "number": "5",
        "pages": "71\u201381",
        "article_number": "",
        "number_of_pages": 11,
        "abstract": "Modeling relations between components of 3D objects is essential for many geometry editing tasks. Existing techniques commonly rely on labeled components, which requires substantial annotation effort and limits components to a dictionary of predefined semantic parts. We propose a novel framework based on neural networks that analyzes an uncurated collection of 3D models from the same category and learns two important types of semantic relations among full and partial shapes: complementarity and interchangeability. The former helps to identify which two partial shapes make a complete plausible object, and the latter indicates that interchanging two partial shapes from different objects preserves the object plausibility. Our key idea is to jointly encode both relations by embedding partial shapes as fuzzy sets in dual embedding spaces. We model these two relations as fuzzy set operations performed across the dual embedding spaces, and within each space, respectively. We demonstrate the utility of our method for various retrieval tasks that are commonly needed in geometric modeling interfaces.",
        "countries": [
            "US"
        ]
    },
    "10.1111/cgf.13395": {
        "doi": "10.1111/cgf.13395",
        "authors": [
            {
                "family": "Ohrhallinger",
                "given": "Stefan",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Wimmer",
                "given": "Michael",
                "countries": [
                    "AT"
                ]
            }
        ],
        "title": "FitConnect: Connecting Noisy 2D Samples by Fitted Neighbourhoods",
        "journal": "Computer Graphics Forum",
        "publication_year": 2018,
        "volume": "38",
        "number": "1",
        "pages": "126\u2013137",
        "article_number": "",
        "number_of_pages": 12,
        "abstract": "We propose a parameter-free method to recover manifold connectivity in unstructured 2D point clouds with high noise in terms of the local feature size. This enables us to capture the features which emerge out of the noise. To achieve this, we extend the reconstruction algorithm HNN-Crust , which connects samples to two (noise-free) neighbours and has been proven to output a manifold for a relaxed sampling condition. Applying this condition to noisy samples by projecting their k-nearest neighbourhoods onto local circular fits leads to multiple candidate neighbour pairs and thus makes connecting them consistently an NP-hard problem. To solve this efficiently, we design an algorithm that searches that solution space iteratively on different scales of k. It achieves linear time complexity in terms of point count plus quadratic time in the size of noise clusters. Our algorithm FitConnect extends HNN-Crust  seamlessly to connect both samples with and without noise, performs as local as the recovered features and can output multiple open or closed piecewise curves. Incidentally, our method simplifies the output geometry by eliminating all but a representative point from noisy clusters. Since local neighbourhood fits overlap consistently, the resulting connectivity represents an ordering of the samples along a manifold. This permits us to simply blend the local fits for denoising with the locally estimated noise extent. Aside from applications like reconstructing silhouettes of noisy sensed data, this lays important groundwork to improve surface reconstruction in 3D. Our open-source algorithm is available online.",
        "countries": [
            "AT"
        ]
    },
    "10.1111/cgf.13253": {
        "doi": "10.1111/cgf.13253",
        "authors": [
            {
                "family": "Huang",
                "given": "Ruqi",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Ovsjanikov",
                "given": "Maks",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Adjoint Map Representation for Shape Analysis and Matching",
        "journal": "Computer Graphics Forum",
        "publication_year": 2017,
        "volume": "36",
        "number": "5",
        "pages": "151\u2013163",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "In this paper, we propose to consider the adjoint operators of functional maps, and demonstrate their utility in several tasks in geometry processing. Unlike a functional map, which represents a correspondence simply using the pull-back of function values, the adjoint operator reflects both the map and its distortion with respect to given inner products. We argue that this property of adjoint operators and especially their relation to the map inverse under the choice of different inner products, can be useful in applications including bi-directional shape matching, shape exploration, and pointwise map recovery among others. In particular, in this paper, we show that the adjoint operators can be used within the cycle-consistency framework to encode and reveal the presence or lack of consistency between distortions in a collection, in a way that is complementary to the previously used purely map-based consistency measures. We also show how the adjoint can be used for matching pairs of shapes, by accounting for maps in both directions, can help in recovering point-to-point maps from their functional counterparts, and describe how it can shed light on the role of functional basis selection.",
        "countries": [
            "FR"
        ]
    },
    "10.1111/cgf.12979": {
        "doi": "10.1111/cgf.12979",
        "authors": [
            {
                "family": "Bennett",
                "given": "Huck",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Papadopoulou",
                "given": "Evanthia",
                "countries": [
                    "CH"
                ]
            },
            {
                "family": "Yap",
                "given": "Chee",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Planar Minimization Diagrams via Subdivision with Applications to Anisotropic Voronoi Diagrams",
        "journal": "Computer Graphics Forum",
        "publication_year": 2016,
        "volume": "35",
        "number": "5",
        "pages": "229\u2013247",
        "article_number": "",
        "number_of_pages": 19,
        "abstract": "Let X = {f1, \u2026, fn} be a set of scalar functions of the form fi : \u211d2 \u2192 \u211d which satisfy some natural properties. We describe a subdivision algorithm for computing a clustered \u03b5-isotopic approximation of the minimization diagram of X. By exploiting soft predicates and clustering of Voronoi vertices, our algorithm is the first that can handle arbitrary degeneracies in X, and allow scalar functions which are piecewise smooth, and not necessarily semi-algebraic. We apply these ideas to the computation of anisotropic Voronoi diagram of polygonal sets; this is a natural generalization of anisotropic Voronoi diagrams of point sites, which extends multiplicatively weighted Voronoi diagrams. We implement a prototype of our anisotropic algorithm and provide experimental results.",
        "countries": [
            "US",
            "CH"
        ]
    },
    "10.1111/cgf.12974": {
        "doi": "10.1111/cgf.12974",
        "authors": [
            {
                "family": "Parakkat",
                "given": "Amal Dev",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Muthuganapathy",
                "given": "Ramanathan",
                "countries": [
                    "IN"
                ]
            }
        ],
        "title": "Crawl through Neighbors: A Simple Curve Reconstruction Algorithm",
        "journal": "Computer Graphics Forum",
        "publication_year": 2016,
        "volume": "35",
        "number": "5",
        "pages": "177\u2013186",
        "article_number": "",
        "number_of_pages": 10,
        "abstract": "Given a planar point set sampled from an object boundary, the process of approximating the original shape is called curve reconstruction. In this paper, a novel non-parametric curve reconstruction algorithm based on Delaunay triangulation has been proposed and it has been theoretically proved that the proposed method reconstructs the original curve under \u03b5-sampling. Starting from an initial Delaunay seed edge, the algorithm proceeds by finding an appropriate neighbouring point and adding an edge between them. Experimental results show that the proposed algorithm is capable of reconstructing curves with different features like sharp corners, outliers, multiple objects, objects with holes, etc. The proposed method also works for open curves. Based on a study by a few users, the paper also discusses an application of the proposed algorithm for reconstructing hand drawn skip stroke sketches, which will be useful in various sketch based interfaces.",
        "countries": [
            "IN"
        ]
    },
    "10.1111/cgf.12970": {
        "doi": "10.1111/cgf.12970",
        "authors": [
            {
                "family": "Litany",
                "given": "Or",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Rodol\u00e0",
                "given": "Emanuele",
                "countries": [
                    "CH"
                ]
            },
            {
                "family": "Bronstein",
                "given": "Alex M.",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Bronstein",
                "given": "Michael M.",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Cremers",
                "given": "Daniel",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Non-Rigid Puzzles",
        "journal": "Computer Graphics Forum",
        "publication_year": 2016,
        "volume": "35",
        "number": "5",
        "pages": "135\u2013143",
        "article_number": "",
        "number_of_pages": 9,
        "abstract": "Shape correspondence is a fundamental problem in computer graphics and vision, with applications in various problems including animation, texture mapping, robotic vision, medical imaging, archaeology and many more. In settings where the shapes are allowed to undergo non-rigid deformations and only partial views are available, the problem becomes very challenging. To this end, we present a non-rigid multi-part shape matching algorithm. We assume to be given a reference shape and its multiple parts undergoing a non-rigid deformation. Each of these query parts can be additionally contaminated by clutter, may overlap with other parts, and there might be missing parts or redundant ones. Our method simultaneously solves for the segmentation of the reference model, and for a dense correspondence to (subsets of) the parts. Experimental results on synthetic as well as real scans demonstrate the effectiveness of our method in dealing with this challenging matching scenario.",
        "countries": [
            "DE",
            "CH",
            "IL"
        ]
    },
    "10.1111/cgf.12975": {
        "doi": "10.1111/cgf.12975",
        "authors": [
            {
                "family": "Grosso",
                "given": "Roberto",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Construction of Topologically Correct and Manifold Isosurfaces",
        "journal": "Computer Graphics Forum",
        "publication_year": 2016,
        "volume": "35",
        "number": "5",
        "pages": "187\u2013196",
        "article_number": "",
        "number_of_pages": 10,
        "abstract": "We present a simple method to describe the geometry and topologically classify the intersection of level sets of trilinear interpolants with a reference unit cell. The solutions of three quadratic equations are used to correctly triangulate the level set within the cell satisfying the conditions imposed by the asymptotic decider. This way the triangulation of isosurfaces across cells borders is manifold and topologically correct. The algorithm presented is intuitive and easy to implement.",
        "countries": [
            "DE"
        ]
    },
    "10.1111/cgf.12973": {
        "doi": "10.1111/cgf.12973",
        "authors": [
            {
                "family": "Ohrhallinger",
                "given": "Stefan",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Mitchell",
                "given": "Scott A.",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Wimmer",
                "given": "Michael",
                "countries": [
                    "AT"
                ]
            }
        ],
        "title": "Curve Reconstruction with Many Fewer Samples",
        "journal": "Computer Graphics Forum",
        "publication_year": 2016,
        "volume": "35",
        "number": "5",
        "pages": "167\u2013176",
        "article_number": "",
        "number_of_pages": 10,
        "abstract": "We consider the problem of sampling points from a collection of smooth curves in the plane, such that the C rust  family of proximity-based reconstruction algorithms can rebuild the curves. Reconstruction requires a dense sampling of local features, i.e., parts of the curve that are close in Euclidean distance but far apart geodesically. We show that \u03b5 &lt; 0.47-sampling is sufficient for our proposed HNN-C rust variant, improving upon the state-of-the-art requirement of \u03b5 &lt; <jats:inline-graphic xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"graphic/cgf12973-math-0001.png\" xlink:title=\"Image\" />-sampling. Thus we may reconstruct curves with many fewer samples. We also present a new sampling scheme that reduces the required density even further than \u03b5 &lt; 0.47-sampling. We achieve this by better controlling the spacing between geodesically consecutive points. Our novel sampling condition is based on the reach, the minimum local feature size along intervals between samples. This is mathematically closer to the reconstruction density requirements, particularly near sharp-angled features. We prove lower and upper bounds on reach \u03c1-sampling density in terms of lfs \u03b5-sampling and demonstrate that we typically reduce the required number of samples for reconstruction by more than half.",
        "countries": [
            "AT",
            "US"
        ]
    },
    "10.1111/cgf.12962": {
        "doi": "10.1111/cgf.12962",
        "authors": [
            {
                "family": "Chen",
                "given": "Renjie",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Gotsman",
                "given": "Craig",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Complex Transfinite Barycentric Mappings with Similarity Kernels",
        "journal": "Computer Graphics Forum",
        "publication_year": 2016,
        "volume": "35",
        "number": "5",
        "pages": "41\u201353",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "Transfinite barycentric kernels are the continuous version of traditional barycentric coordinates and are used to define interpolants of values given on a smooth planar contour. When the data is two-dimensional, i.e. the boundary of a planar map, these kernels may be conveniently expressed using complex number algebra, simplifying much of the notation and results. In this paper we develop some of the basic complex-valued algebra needed to describe these planar maps, and use it to define similarity kernels, a natural alternative to the usual barycentric kernels. We develop the theory behind similarity kernels, explore their properties, and show that the transfinite versions of the popular three-point barycentric coordinates (Laplace, mean value and Wachspress) have surprisingly simple similarity kernels. We furthermore show how similarity kernels may be used to invert injective transfinite barycentric mappings using an iterative algorithm which converges quite rapidly. This is useful for rendering images deformed by planar barycentric mappings.",
        "countries": [
            "DE",
            "US"
        ]
    },
    "10.1016/j.cag.2024.01.001": {
        "doi": "10.1016/j.cag.2024.01.001",
        "authors": [
            {
                "family": "Tang",
                "given": "Kaiyuan",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Wang",
                "given": "Chaoli",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "STSR-INR: Spatiotemporal super-resolution for multivariate time-varying volumetric data via implicit neural representation",
        "journal": "Computers & Graphics",
        "publication_year": 2024,
        "volume": "119",
        "number": "",
        "pages": "103874:1\u2013103874:11",
        "number_of_pages": 11,
        "article_number": "103874",
        "abstract": "Implicit neural representation (INR) has surfaced as a promising direction for solving different scientific visualization tasks due to its continuous representation and flexible input and output settings. We present STSR-INR, an INR solution for generating simultaneous spatiotemporal super-resolution for multivariate time-varying volumetric data. Inheriting the benefits of the INR-based approach, STSR-INR supports unsupervised learning and permits data upscaling with arbitrary spatial and temporal scale factors. Unlike existing GAN- or INR-based super-resolution methods, STSR-INR focuses on tackling variables or ensembles and enabling joint training across datasets of various spatiotemporal resolutions. We achieve this capability via a variable embedding scheme that learns latent vectors for different variables. In conjunction with a modulated structure in the network design, we employ a variational auto-decoder to optimize the learnable latent vectors to enable latent-space interpolation. To combat the slow training of INR, we leverage a multi-head strategy to improve training and inference speed with significant speedup. We demonstrate the effectiveness of STSR-INR with multiple scalar field datasets and compare it with conventional tricubic+linear interpolation and state-of-the-art deep-learning-based solutions (STNet and CoordNet).",
        "countries": [
            "US"
        ]
    },
    "10.1016/j.cag.2023.08.012": {
        "doi": "10.1016/j.cag.2023.08.012",
        "authors": [
            {
                "family": "Zhang",
                "given": "Jia-Qi",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Duan",
                "given": "Hao-Bin",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Chen",
                "given": "Jun-Long",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Shamir",
                "given": "Ariel",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Wang",
                "given": "Miao",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "HoughLaneNet: Lane detection with deep hough transform and dynamic convolution",
        "journal": "Computers & Graphics",
        "publication_year": 2023,
        "volume": "116",
        "number": "",
        "pages": "82\u201392",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "The task of lane detection has garnered considerable attention in the field of autonomous driving due to its complexity. Lanes can present difficulties for detection, as they can be narrow, fragmented, and often obscured by heavy traffic. However, it has been observed that the lanes have a geometrical structure that resembles a straight line, leading to improved lane detection results when utilizing this characteristic. To address this challenge, we propose a hierarchical Deep Hough Transform (DHT) approach that combines all lane features in an image into the Hough parameter space. Additionally, we refine the point selection method and incorporate a Dynamic Convolution Module to effectively differentiate between lanes in the original image. Our network architecture comprises a backbone network, either a ResNet or Pyramid Vision Transformer, a Feature Pyramid Network as the neck to extract multi-scale features, and a hierarchical DHT-based feature aggregation head to accurately segment each lane. By utilizing the lane features in the Hough parameter space, the network learns dynamic convolution kernel parameters corresponding to each lane, allowing the Dynamic Convolution Module to effectively differentiate between lane features. Subsequently, the lane features are fed into the feature decoder, which predicts the final position of the lane. Our proposed network structure demonstrates improved performance in detecting heavily occluded or worn lane images, as evidenced by our extensive experimental results, which show that our method outperforms or is on par with state-of-the-art techniques.",
        "countries": [
            "CN",
            "IL"
        ]
    },
    "10.1016/j.cag.2023.08.009": {
        "doi": "10.1016/j.cag.2023.08.009",
        "authors": [
            {
                "family": "Wang",
                "given": "Yi",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Cheng",
                "given": "Jing-Song",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Feng",
                "given": "Qiao",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Tao",
                "given": "Wen-Yuan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Lai",
                "given": "Yu-Kun",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Li",
                "given": "Kun",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "TSNeRF: Text-driven stylized neural radiance fields via semantic contrastive learning",
        "journal": "Computers & Graphics",
        "publication_year": 2023,
        "volume": "116",
        "number": "",
        "pages": "102\u2013114",
        "number_of_pages": 13,
        "article_number": "",
        "abstract": "3D scene stylization aims to generate impressive stylized images from arbitrary novel views based on the stylistic reference. Existing image-driven 3D scene stylization methods require a specific style reference to be given, and lack the ability to produce diverse stylization results by combining style information from different aspects. In this paper, we propose a text-driven 3D scene stylization method based on semantic contrast learning, which takes Neural Radiance Fields (NeRF) as the 3D scene representation and generates diverse 3D stylized scenes by leveraging the semantic capabilities of the Contrastive Language-Image Pre-Training (CLIP) model. For comprehensively exploiting the semantic knowledge to generate finely stylized results, we design a CLIP-based semantic contrast estimation loss, which can avoid the global stylistic inconsistency caused by the NeRF ray sampling method and avoid the tendency to stylize neutral descriptions due to the semantic averaging of the CLIP space. In addition, to reduce the memory burden arising from NeRF ray sampling, we propose a novel ray sampling method with gradient accumulation to optimize the NeRF rendering process. The experimental results indicate that our method generates high-quality and plausible results with cross-view consistency. Moreover, our method enables the creation of new styles that match the target text by combining multiple domains. The code will be available at .",
        "countries": [
            "CN",
            "GB"
        ]
    },
    "10.1016/j.cag.2023.08.014": {
        "doi": "10.1016/j.cag.2023.08.014",
        "authors": [
            {
                "family": "Jiang",
                "given": "Pengfei",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Yang",
                "given": "Xiaoyan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Chen",
                "given": "Yuanjie",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Song",
                "given": "Wenjie",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Li",
                "given": "Yang",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "AdaptMVSNet: Efficient Multi-View Stereo with adaptive convolution and attention fusion",
        "journal": "Computers & Graphics",
        "publication_year": 2023,
        "volume": "116",
        "number": "",
        "pages": "128\u2013138",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "Multi-View Stereo\u00a0(MVS) is a crucial technique for reconstructing the geometric structure of a scene, given the known camera parameters. Previous deep learning-based MVS methods have mainly focused on improving the reconstruction quality but overlooked the running efficiency during the actual algorithm deployment. For example, deformable convolutions have been introduced to improve the accuracy of the reconstruction results further, however, its inability for parallel optimization caused low inference speed. In this paper, we propose AdaptMVSNet which is device-friendly and reconstruction-efficient, while preserving the original results. To this end, adaptive convolution is introduced to significantly improve the efficiency in speed and metrics compared to current methods. In addition, an attention fusion module is proposed to blend features from adaptive convolution and the feature pyramid network. Our experiments demonstrate that our proposed approach achieves state-of-the-art performance and is almost 2\u00d7 faster than the recent fastest MVS method. We will release our source code.",
        "countries": [
            "CN"
        ]
    },
    "10.1016/j.cag.2023.07.034": {
        "doi": "10.1016/j.cag.2023.07.034",
        "authors": [
            {
                "family": "Chen",
                "given": "Xiyu",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Jia",
                "given": "Tao",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Xiao",
                "given": "Jiangjian",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhuang",
                "given": "Jiayan",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Real-time self-supervised tone curve estimation for HDR image",
        "journal": "Computers & Graphics",
        "publication_year": 2023,
        "volume": "115",
        "number": "",
        "pages": "461\u2013471",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "High dynamic range (HDR) image acquisition technology can record real-scene information. However, most display devices only support standard dynamic range images; therefore, dynamic range compression via tone mapping operators is a key technology for HDR image visualization. Recently, deep learning has achieved significantly better results than traditional methods in tone mapping; however, some problems remain. On the one hand, the labels of datasets are usually selected from the results of existing traditional methods, which limit the quality of newly generated results. On the other hand, these algorithms require huge computational resources and cannot be practically applied. As the dynamic range can be compressed using an intuitive and simple sigmoid curve mapping, a lightweight network is designed in this study to estimate the patch-wise tone curve parameters for HDR images. Simultaneously, the differentiable approximation of tone mapped image quality assessment is introduced as a self-supervised loss term so that the method only needs HDR data as training data. Experimental results demonstrate that the proposed method achieves better results than existing methods in both objective and subjective metrics at a low computational cost.",
        "countries": [
            "CN"
        ]
    },
    "10.1016/j.cag.2023.06.013": {
        "doi": "10.1016/j.cag.2023.06.013",
        "authors": [
            {
                "family": "Guan",
                "given": "Yanran",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Chubarau",
                "given": "Andrei",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Rao",
                "given": "Ruby",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Nowrouzezahrai",
                "given": "Derek",
                "countries": [
                    "CA"
                ]
            }
        ],
        "title": "Learning neural implicit representations with surface signal parameterizations",
        "journal": "Computers & Graphics",
        "publication_year": 2023,
        "volume": "114",
        "number": "",
        "pages": "257\u2013264",
        "number_of_pages": 8,
        "article_number": "",
        "abstract": "Neural implicit surface representations have recently emerged as popular alternative to explicit 3D object encodings, such as polygonal meshes, tabulated points, or voxels. While significant work has improved the geometric fidelity of these representations, much less attention is given to their final appearance. Traditional explicit object representations commonly couple the 3D shape data with auxiliary surface-mapped image data, such as diffuse color textures and fine-scale geometric details in normal maps that typically require a mapping of the 3D surface onto a plane, i.e., a surface parameterization; implicit representations, on the other hand, cannot be easily textured due to lack of configurable surface parameterization. Inspired by this digital content authoring methodology, we design a neural network architecture that implicitly encodes the underlying surface parameterization suitable for appearance data. As such, our model remains compatible with existing mesh-based digital content with appearance data. Motivated by recent work that overfits compact networks to individual 3D objects, we present a new weight-encoded neural implicit representation that extends the capability of neural implicit surfaces to enable various common and important applications of texture mapping. Our method outperforms reasonable baselines and state-of-the-art alternatives.",
        "countries": [
            "CA"
        ]
    },
    "10.1016/j.cag.2023.05.025": {
        "doi": "10.1016/j.cag.2023.05.025",
        "authors": [
            {
                "family": "Gisbert",
                "given": "Guillaume",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Chaine",
                "given": "Rapha\u00eblle",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Coeurjolly",
                "given": "David",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Inpainting holes in folded fabric meshes",
        "journal": "Computers & Graphics",
        "publication_year": 2023,
        "volume": "114",
        "number": "",
        "pages": "201\u2013209",
        "number_of_pages": 9,
        "article_number": "",
        "abstract": "When scanning real shapes, occlusion issues may lead to holes in the reconstructed surface which must be solved using an inpainting technique. When dealing with fabrics with folds, reconstruction gets even more challenging because these occlusion problems become almost inevitable and strong assumptions are implied on the physical model of the inpainted surface. We propose a framework to fill holes in triangle mesh surfaces representing fabrics. The method leverages the developable nature of fabrics to recover the intrinsic geometry of the missing patch in 2D. Our inpainting strategy is then based on a variational method to smoothly incorporate the patch into the surface by minimizing an isometric energy. The proposed approach allows us to produce folds and creases which are difficult to obtain with general purpose hole filling techniques. Moreover, our approach remains relevant in the case where the model is not provided by the digitization of a real fabric as for the acquisition from ancient statues with draperies.",
        "countries": [
            "FR"
        ]
    },
    "10.1016/j.cag.2023.07.035": {
        "doi": "10.1016/j.cag.2023.07.035",
        "authors": [
            {
                "family": "Le",
                "given": "Trung-Nghia",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nguyen",
                "given": "Tam V.",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Le",
                "given": "Minh-Quan",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nguyen",
                "given": "Trong-Thuan",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Huynh",
                "given": "Viet-Tham",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Do",
                "given": "Trong-Le",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Le",
                "given": "Khanh-Duy",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Tran",
                "given": "Mai-Khiem",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Hoang-Xuan",
                "given": "Nhat",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nguyen-Ho",
                "given": "Thang-Long",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nguyen",
                "given": "Vinh-Tiep",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Le-Pham",
                "given": "Nhat-Quynh",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Pham",
                "given": "Huu-Phuc",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Hoang",
                "given": "Trong-Vu",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nguyen",
                "given": "Quang-Binh",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nguyen-Mau",
                "given": "Trong-Hieu",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Huynh",
                "given": "Tuan-Luc",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Le",
                "given": "Thanh-Danh",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nguyen-Ha",
                "given": "Ngoc-Linh",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Truong-Thuy",
                "given": "Tuong-Vy",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Phong",
                "given": "Truong Hoai",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Diep",
                "given": "Tuong-Nghiem",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Ho",
                "given": "Khanh-Duy",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nguyen",
                "given": "Xuan-Hieu",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Tran",
                "given": "Thien-Phuc",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Yang",
                "given": "Tuan-Anh",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Tran",
                "given": "Kim-Phat",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Hoang",
                "given": "Nhu-Vinh",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nguyen",
                "given": "Minh-Quang",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Vo",
                "given": "Hoai-Danh",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Doan",
                "given": "Minh-Hoa",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nguyen",
                "given": "Hai-Dang",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Sugimoto",
                "given": "Akihiro",
                "countries": [
                    "JP"
                ]
            },
            {
                "family": "Tran",
                "given": "Minh-Triet",
                "countries": [
                    "VN"
                ]
            }
        ],
        "title": "SketchANIMAR: Sketch-based 3D animal fine-grained retrieval",
        "journal": "Computers & Graphics",
        "publication_year": 2023,
        "volume": "116",
        "number": "",
        "pages": "150\u2013161",
        "number_of_pages": 12,
        "article_number": "",
        "abstract": "The retrieval of 3D objects has gained significant importance in recent years due to its broad range of applications in computer vision, computer graphics, virtual reality, and augmented reality. However, the retrieval of 3D objects presents significant challenges due to the intricate nature of 3D models, which can vary in shape, size, and texture, and have numerous polygons and vertices. To this end, we introduce a novel SHREC challenge track that focuses on retrieving relevant 3D animal models from a dataset using sketch queries and expedites accessing 3D models through available sketches. Furthermore, a new dataset named ANIMAR was constructed in this study, comprising a collection of 711 unique 3D animal models and 140 corresponding sketch queries. Our contest requires participants to retrieve 3D models based on complex and detailed sketches. We receive satisfactory results from eight teams and 204 runs. Although further improvement is necessary, the proposed task has the potential to incentivize additional research in the domain of 3D object retrieval, potentially yielding benefits for a wide range of applications. We also provide insights into potential areas of future research, such as improving techniques for feature extraction and matching and creating more diverse datasets to evaluate retrieval performance.",
        "countries": [
            "VN",
            "US",
            "JP"
        ]
    },
    "10.1016/j.cag.2023.08.008": {
        "doi": "10.1016/j.cag.2023.08.008",
        "authors": [
            {
                "family": "Chen",
                "given": "Ruizhao",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Yi",
                "given": "Ran",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wang",
                "given": "Tuanfeng Yang",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Ma",
                "given": "Lizhuang",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Neural 3D face rendering conditioned on 2D appearance via GAN disentanglement method",
        "journal": "Computers & Graphics",
        "publication_year": 2023,
        "volume": "116",
        "number": "",
        "pages": "336\u2013344",
        "number_of_pages": 9,
        "article_number": "",
        "abstract": "Previewing the shaded output of 3D models has been a long-standing requirement in the field. Typically, this is achieved by applying common materials; however, this approach is often labor-intensive and can yield only rough results in the trial stage. Conventional 2D style transfer methods are unsuitable for 3D-to-2D cross-domain conversion, and they cannot accurately reflect the mesh\u2019s geometry. Inspired by StyleGAN2\u2019s related research, we propose a method for rendering 2D images of 3D face meshes directly controlled by a single 2D reference image, using GAN disentanglement. Our approach involves an input of a 3D mesh and a reference image, where encoders extract geometric features from the mesh and appearance features from the reference image. These features control the StyleGAN2 generator to obtain a generated image that preserves the 3D mesh\u2019s geometry and the reference image\u2019s appearance. Our experiments demonstrate that this method performs well in generating images while maintaining geometric consistency.",
        "countries": [
            "CN",
            "US"
        ]
    },
    "10.1016/j.cag.2023.06.023": {
        "doi": "10.1016/j.cag.2023.06.023",
        "authors": [
            {
                "family": "Raffo",
                "given": "Andrea",
                "countries": [
                    "NO"
                ]
            },
            {
                "family": "Fugacci",
                "given": "Ulderico",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Biasotti",
                "given": "Silvia",
                "countries": [
                    "IT"
                ]
            }
        ],
        "title": "GEO-Nav: A geometric dataset of voltage-gated sodium channels",
        "journal": "Computers & Graphics",
        "publication_year": 2023,
        "volume": "115",
        "number": "",
        "pages": "285\u2013295",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "Voltage-gated sodium (Nav) channels constitute a prime target for drug design and discovery, given their implication in various diseases such as epilepsy, migraine and ataxia to name a few. In this regard, performing morphological analysis is a crucial step in comprehensively understanding their biological function and mechanism, as well as in uncovering subtle details of their mechanism that may be elusive to experimental observations. Despite their tremendous therapeutic potential, drug design resources are deficient, particularly in terms of accurate and comprehensive geometric information. This paper presents a geometric dataset of molecular surfaces that are representative of Nav channels in mammals. For each structure we provide three representations and a number of geometric measures, including length, volume and straightness of the recognized channels. To demonstrate the effective use of GEO-Nav, we have tested it on two methods belonging to two different categories of approaches: a sphere-based and a tessellation-based method.",
        "countries": [
            "NO",
            "IT"
        ]
    },
    "10.1016/j.cag.2023.07.001": {
        "doi": "10.1016/j.cag.2023.07.001",
        "authors": [
            {
                "family": "Lemeunier",
                "given": "Cl\u00e9ment",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Denis",
                "given": "Florence",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Lavou\u00e9",
                "given": "Guillaume",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Dupont",
                "given": "Florent",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "SpecTrHuMS: Spectral transformer for human mesh sequence learning",
        "journal": "Computers & Graphics",
        "publication_year": 2023,
        "volume": "115",
        "number": "",
        "pages": "191\u2013203",
        "number_of_pages": 13,
        "article_number": "",
        "abstract": "We present SpecTrHuMS, a Spectral Transformer for 3D triangular Human Mesh Sequence learning which combines known deep learning models with spectral mesh processing to capture characteristics of 3D shapes as well as temporal dependencies between the frames. Unlike previous works in this field, our approach is able to work directly with a compressed representation of the geometry, the spectral coefficients, rather than relying solely on skeleton joints that does not contain surface information. The vertices of each mesh of a sequence are first projected on the eigenvectors of the Graph Laplacian computed from the common triangulation. A convolutional encoder then encodes each frame into lower dimensional latent variables that preserve as much as possible the spectral information. These latent variables are next passed through a transformer architecture so that the model understands the context of the sequence and learns temporal dependencies between the frames. Each frame of the transformer\u2019s output is then decoded by a convolutional decoder which aims to reconstruct the input spectral coefficients. Finally, all frames are transformed back into the spatial domain, resulting in a general process able to treat 4D surfaces with a constant connectivity. Our method is evaluated on a prediction task on AMASS, a dataset of human surface sequences, showing the ability of our model to produce realistic movements while preserving the identity of a subject, and showing that this work is a significant step towards efficient and high-quality representation of triangular mesh sequences with constant connectivity. Additional experiments show that our model can be easily extended to other tasks such as long term prediction, completion and that it is generalizable to other datasets with constant connectivity. This work opens up new possibilities for applications in the fields of animation, virtual reality, and computer graphics. Pretrained models, the code to train them and the code to create datasets will be made publicly available.",
        "countries": [
            "FR"
        ]
    },
    "10.1016/j.cag.2023.07.021": {
        "doi": "10.1016/j.cag.2023.07.021",
        "authors": [
            {
                "family": "Acevedo",
                "given": "Pedro",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Rekabdar",
                "given": "Banafsheh",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Mousas",
                "given": "Christos",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Optimizing retroreflective marker set for motion capturing props",
        "journal": "Computers & Graphics",
        "publication_year": 2023,
        "volume": "115",
        "number": "",
        "pages": "181\u2013190",
        "number_of_pages": 10,
        "article_number": "",
        "abstract": "One of the most widely used motion capture (MoCap) methods depends on retroreflective markers placed on an object. Through cameras, the MoCap system captures the moving prop\u2019s (3D object) motion. However, noise in MoCap data caused by the shape of the captured volume, motion between frames, ghost points, and markers\u2019 self-occlusion could impact the quality of the captured data. To improve the quality of capturing the motion of props, we tackle the problem of finding an optimal marker set configuration for a given input prop while considering various constraints. By \u201cprops,\u201d we mean any objects or handheld items of different shapes and sizes on which markers can be precisely placed to reduce MoCap errors. We propose an approach to optimize the placement of optical (retroreflective) markers over props while encountering various constraints, such as the visibility of markers, the number of makers used, the symmetry of the marker set, and markers\u2019 overlapping. We solve the marker set configuration problem using an optimization-based method, the reversible-jump Markov chain Monte Carlo. We provide marker set configurations for various props and constraints obtained through several simulations we ran to evaluate the performance of our method.",
        "countries": [
            "US"
        ]
    },
    "10.1016/j.cag.2023.07.028": {
        "doi": "10.1016/j.cag.2023.07.028",
        "authors": [
            {
                "family": "Peng",
                "given": "Hao-Yang",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Guo",
                "given": "Meng-Hao",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Liu",
                "given": "Zheng-Ning",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Yang",
                "given": "Yong-Liang",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Mu",
                "given": "Tai-Jiang",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "MWFormer: Mesh Understanding with Window-based Transformer",
        "journal": "Computers & Graphics",
        "publication_year": 2023,
        "volume": "115",
        "number": "",
        "pages": "382\u2013391",
        "number_of_pages": 10,
        "article_number": "",
        "abstract": "Polygonal mesh has been proven to be a powerful representation of 3D shapes, given its efficiency in expressing shape surface while maintaining geometric and topological information. Increasing efforts have been made to design elaborate deep convolutional neural networks for meshes. However, these methods naturally ignore the global connectivity among mesh primitives due to the locality nature of convolution operations. In this paper, we introduce a transformer-like self-attention mechanism with down-sampling architectures for mesh learning to capture both the global and local relationships among mesh faces. To achieve this, we propose BFS-Pooling, which can convert a connected mesh into discrete tokens (i.e., a set of adjacent faces) with breath-first-search (BFS) and naturally build hierarchical architectures for mesh learning by pooling mesh tokens. Benefiting from BFS-Pooling, we design a hierarchical transformer architecture with a window-based local attention mechanism, Mesh Window Transformer (MWFormer). Experimental results demonstrate that MWFormer achieves the best or competitive performance in both mesh classification and mesh segmentation tasks. Code will be available.",
        "countries": [
            "CN",
            "GB"
        ]
    },
    "10.1016/j.cag.2023.05.006": {
        "doi": "10.1016/j.cag.2023.05.006",
        "authors": [
            {
                "family": "Campana",
                "given": "Jose Luis Flores",
                "countries": [
                    "BR"
                ]
            },
            {
                "family": "Decker",
                "given": "Lu\u00eds Gustavo Lorgus",
                "countries": [
                    "BR"
                ]
            },
            {
                "family": "Souza",
                "given": "Marcos Roberto e",
                "countries": [
                    "BR"
                ]
            },
            {
                "family": "Maia",
                "given": "Helena de Almeida",
                "countries": [
                    "BR"
                ]
            },
            {
                "family": "Pedrini",
                "given": "Helio",
                "countries": [
                    "BR"
                ]
            }
        ],
        "title": "Variable-hyperparameter visual transformer for efficient image inpainting",
        "journal": "Computers & Graphics",
        "publication_year": 2023,
        "volume": "113",
        "number": "",
        "pages": "57\u201368",
        "number_of_pages": 12,
        "article_number": "",
        "abstract": "Image inpainting has shown a great evolution in the reconstruction of damaged regions or holes since the advent of deep neural networks. Recently, transformers have been used in the field of computer vision to capture global information about the image, which cannot be done with convolutional neural networks due to the limitation of their local receptive fields. Therefore, the transformer may be essential to achieve realistic results when damaged regions cover a large part of the image. However, the quadratic computational and memory costs in the self-attention layer have led to its prohibited usage in high-resolution images and restricted devices, especially for image inpainting when the method must deal with large masks. To overcome this problem, we propose a variable-hyperparameter visual transformer architecture that (i) subdivides the feature maps into a variable number of multi-scale patches, (ii) distributes the feature map into a variable number of heads to balance the complexity of the self-attention operation, and (iii) includes a new strategy based on depth-wise convolution to reduce the number of channels of the feature map sent to each transformer block. We conduct experiments on three datasets from the literature. Our experiments show that our method consistently achieved the best results for the FID and LPIPS metrics on the CelebA dataset. We obtained competitive results for Places2 and Paris StreetView datasets compared to state-of-the-art methods. Moreover, our model presents the best performance in terms of model size, number of parameters, and FLOPS. Our qualitative results indicate that our proposed method is capable of reconstructing semantic content, such as parts of human faces.",
        "countries": [
            "BR"
        ]
    },
    "10.1016/j.cag.2023.06.031": {
        "doi": "10.1016/j.cag.2023.06.031",
        "authors": [
            {
                "family": "Cui",
                "given": "Jiahao",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Li",
                "given": "Shuai",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Hou",
                "given": "Fei",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Hao",
                "given": "Aimin",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Qin",
                "given": "Hong",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Analyzing part functionality via multi-modal latent space embedding and interweaving",
        "journal": "Computers & Graphics",
        "publication_year": 2023,
        "volume": "115",
        "number": "",
        "pages": "1\u201312",
        "number_of_pages": 12,
        "article_number": "",
        "abstract": "In this paper, we advocate a novel method for analyzing the functionality of parts in 3D objects. In contrast to prior research, our method no longer characterizes the functionality of an object part using its single type of qualities (or attributes), e.g., geometry or interactions, nor by weighing the significance of various qualities. Instead, we consider the latent space of part functions as a semantic feature space comprehensively defined by part qualities. To learn such a space by parameterizing and encoding semantic features from multi-channel, we begin by learning multi-modal latent space using shapes, textures, and interaction scenes. Next, the latent space of part functions is generated by embedding and interweaving these multi-modal spaces into a space with a higher dimension. We devise loss functions to direct the embedding and interweaving of multi-modal spaces while preserving their manifolds. Consequently, the learned functionality latent space can capture the similarities between semantic features related to functionality and encode them into high-level functional representations. We assess this innovative approach on diverse categories of textured 3D shapes. Extensive experiments have exhibited our method\u2019s parametric and encoding capability towards functionality-centric shape analysis and synthesis, including shape functionality analysis, functionally-similar shape retrieval, and functionality-aware modeling, all of which are of the essence to new graphics techniques and applications.",
        "countries": [
            "CN",
            "US"
        ]
    },
    "10.1016/j.cag.2023.06.014": {
        "doi": "10.1016/j.cag.2023.06.014",
        "authors": [
            {
                "family": "Xiao",
                "given": "Yanyang",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Cao",
                "given": "Juan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Xu",
                "given": "Shaoping",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Chen",
                "given": "Zhonggui",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Meshless power diagrams",
        "journal": "Computers & Graphics",
        "publication_year": 2023,
        "volume": "114",
        "number": "",
        "pages": "247\u2013256",
        "number_of_pages": 10,
        "article_number": "",
        "abstract": "The computation of power diagrams (or weighted Voronoi diagrams) is a fundamental task in computational geometry and computer graphics. To accomplish the computation, we provide a different way from the existing ones for lifting the weighted seeds to a set of points in the space of one dimension higher, then the power cells can be directly obtained by computing the intersections of the Voronoi cells of these lifting points and the original space. This property enables us to apply the method based on the k-nearest neighbors query to the generation of power diagrams. Each power cell is obtained by sequentially clipping the input domain using the bisectors between its seed and the k-nearest neighbors. Experimental results demonstrate that our method outperforms the state-of-the-art one based on regular triangulation in terms of efficiency for general cases in the 2D and 3D spaces.",
        "countries": [
            "CN"
        ]
    },
    "10.1016/j.cag.2023.06.012": {
        "doi": "10.1016/j.cag.2023.06.012",
        "authors": [
            {
                "family": "Cl\u00e9mot",
                "given": "Matt\u00e9o",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Digne",
                "given": "Julie",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Neural skeleton: Implicit neural representation away from the surface",
        "journal": "Computers & Graphics",
        "publication_year": 2023,
        "volume": "114",
        "number": "",
        "pages": "368\u2013378",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "Implicit Neural Representations are powerful tools for representing 3D shapes. They encode an implicit field in the parameters of a Neural Network, leveraging the power of auto-differentiation for optimizing the implicit function and avoiding the need for a manually crafted function. So far, Implicit Neural Representations have been mainly designed to extract or render object surfaces and methods primarily focus on improving the implicit function near the surface. In this paper we argue that implicit fields are useful for other shape analysis tasks, in particular skeleton (medial axis) extraction. Indeed, a medial axis is defined through distances to the surface, which can be provided by an implicit neural representation, making it robust to noise and missing data. However this requires the implicit field to be reliable away from the surface, something most representations are not optimized for. To achieve this, inspired by variational image denoising techniques, we propose to add a Total Variation term, to regularize the implicit field. We further design a skeleton sampling method working directly on the GPU, and link the extracted points using a coverage formulation. We show that our resulting neural skeleton is more robust to sample defects such as noise or missing data compared to other medial axis extraction methods.",
        "countries": [
            "FR"
        ]
    },
    "10.1016/j.cag.2023.06.017": {
        "doi": "10.1016/j.cag.2023.06.017",
        "authors": [
            {
                "family": "Yildiz",
                "given": "Tolga",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Akleman",
                "given": "Ergun",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Krishnamurthy",
                "given": "Vinayak",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Ebert",
                "given": "Matthew",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "A modular approach for creation of any bi-axial woven structure with congruent tiles",
        "journal": "Computers & Graphics",
        "publication_year": 2023,
        "volume": "114",
        "number": "",
        "pages": "357\u2013367",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "Modularity is a fundamental and intriguing property of fabrics. Given the same set of threads, one can construct different geometries and therefore physical behavior simply by changing how those threads are linked to each other. As a result, fabrics have been studied with great interest in engineering applications. However, most engineering applications model fabrics as composite structures reinforced with a secondary material that fills the gaps between thread elements. In this work, we first show the existence of threads that are space-filling without the need for other materials. We then introduce a simple approach to construct such space-filling threads by using a single modular element that can be obtained by partitioning a cube into two yin-yang type identical pieces. These yin-yang type congruent tiles can directly be constructed by using a parametric approach. Another property of these tiles is that they are foldable, i.e., they can be constructed by folding planar materials. We show that there exist infinitely many such congruent tiles. We further demonstrate that any 2-way 2-fold woven structure can be constructed by translated and rotated versions of such congruent tiles.",
        "countries": [
            "US"
        ]
    },
    "10.1016/j.cag.2023.06.015": {
        "doi": "10.1016/j.cag.2023.06.015",
        "authors": [
            {
                "family": "\u010comi\u0107",
                "given": "Lidija",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Magillo",
                "given": "Paola",
                "countries": [
                    "RS"
                ]
            }
        ],
        "title": "Crossing-free paths in the square grid",
        "journal": "Computers & Graphics",
        "publication_year": 2023,
        "volume": "114",
        "number": "",
        "pages": "296\u2013305",
        "number_of_pages": 10,
        "article_number": "",
        "abstract": "We consider paths in the 2D square grid, composed of grid edges, given as a sequence of moves in the four cardinal compass directions, without U-turns, but possibly passing several times through the same vertex or the same edge (if the path is open, it cannot pass twice through its starting vertex). We propose an algorithm which reports a self-crossing if there is one, or otherwise draws the path without self-crossings. The algorithm follows the intuitive idea naturally applied by humans to draw a curve: at each vertex that has already been visited, it tries to insert two new segments in such a way that they do not cross the existing ones. If this is not possible, a self-crossing is reported. This procedure is supported by a data structure combining a doubly-linked circular list and a skip list. The time and space complexity is linear in the length of the path.",
        "countries": [
            "IT",
            "RS"
        ]
    },
    "10.1016/j.cag.2023.04.007": {
        "doi": "10.1016/j.cag.2023.04.007",
        "authors": [
            {
                "family": "Song",
                "given": "Xiaogang",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Liu",
                "given": "Wanbo",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Liang",
                "given": "Li",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Shi",
                "given": "Weiwei",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Xie",
                "given": "Guo",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Lu",
                "given": "Xiaofeng",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Hei",
                "given": "Xinhong",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Image super-resolution with multi-scale fractal residual attention network",
        "journal": "Computers & Graphics",
        "publication_year": 2023,
        "volume": "113",
        "number": "",
        "pages": "21\u201331",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "Deep neural networks can significantly improve the quality of super-resolution. However, previous work has made insufficient use of low-resolution scale features and channel-wise information, hence hindering the representational ability of CNNs. To address these issues, a multi-scale fractal residual attention network (MFRAN) is proposed. Specifically, MFRAN consists of fractal residual blocks (FRBs), dual-enhanced channel attention (DECA), and dilated residual attention blocks (DRABs). Among them, FRB applies multi-scale extension rule to continuously expand into a fractal structure that detects multi-scale features; DRAB constructs a combined dilated convolution to learn a generalizable and expressive feature space with a larger receptive field; DECA employs one-dimensional convolution to achieve cross-channel information interaction, and enhance the flow of information between groups by channel shuffling. Then, we integrate horizontal feature representations via local residual and feature fusion. Extensive quantitative and qualitative evaluations of benchmark datasets show that our proposed approach outperforms state-of-the-art methods in terms of quantitative metrics and visual results.",
        "countries": [
            "CN"
        ]
    },
    "10.1016/j.cag.2022.10.008": {
        "doi": "10.1016/j.cag.2022.10.008",
        "authors": [
            {
                "family": "Stumpfegger",
                "given": "Josef",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "H\u00f6hlein",
                "given": "Kevin",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Craig",
                "given": "George",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Westermann",
                "given": "R\u00fcdiger",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "GPU accelerated scalable parallel coordinates plots",
        "journal": "Computers & Graphics",
        "publication_year": 2022,
        "volume": "109",
        "number": "",
        "pages": "111\u2013120",
        "number_of_pages": 10,
        "article_number": "",
        "abstract": "Parallel coordinates are a powerful technique to visually analyze multi-parameter data, i.e., sets of datapoints with potentially many associated parameter values per datapoint. When these sets are large, line rendering becomes a severe performance bottleneck, and since many lines fall into the same pixel the numerical precision of the color buffer is quickly reached. We propose a scalable GPU realization of parallel coordinates building upon 2D pairwise attribute bins, to significantly reduce the number of lines to be rendered. Our approach comprises a GPU compute pipeline that combines shader-based scattering with atomic increment operations to efficiently count how often a line is drawn. These counts are then used to draw all pairwise sub-plots in the parallel coordinates plot, by analytically calculating the opacity for each count and rendering a line with end points determined by the 2D coordinates of the bin. In this way, framebuffer precision issues that are paramount in classical approaches can be overcome. We demonstrate the efficiency of the proposed realization for visualizing a weather forecast ensemble comprising 2.7 billion datapoints, each carrying 7 prognostic floating-point variables like temperature, precipitation and pressure, plus spatial and simulation input variables. We compare our pipeline to a rasterization-based approach regarding performance, and demonstrate interactive brushing at 4 s per frame at full HD viewport resolution.",
        "countries": [
            "DE"
        ]
    },
    "10.1016/j.cag.2022.09.003": {
        "doi": "10.1016/j.cag.2022.09.003",
        "authors": [
            {
                "family": "Novello",
                "given": "Tiago",
                "countries": [
                    "BR"
                ]
            },
            {
                "family": "Schardong",
                "given": "Guilherme",
                "countries": [
                    "PT"
                ]
            },
            {
                "family": "Schirmer",
                "given": "Luiz",
                "countries": [
                    "PT"
                ]
            },
            {
                "family": "da Silva",
                "given": "Vin\u00edcius",
                "countries": [
                    "BR"
                ]
            },
            {
                "family": "Lopes",
                "given": "H\u00e9lio",
                "countries": [
                    "BR"
                ]
            },
            {
                "family": "Velho",
                "given": "Luiz",
                "countries": [
                    "BR"
                ]
            }
        ],
        "title": "Exploring differential geometry in neural implicits",
        "journal": "Computers & Graphics",
        "publication_year": 2022,
        "volume": "108",
        "number": "",
        "pages": "49\u201360",
        "number_of_pages": 12,
        "article_number": "",
        "abstract": "We introduce a neural implicit framework that exploits the differentiable properties of neural networks and the discrete geometry of point-sampled surfaces to approximate them as the level sets of neural implicit functions. To train a neural implicit function, we propose a loss functional that approximates a signed distance function, and allows terms with high-order derivatives, such as the alignment between the principal directions of curvature, to learn more geometric details. During training, we consider a non-uniform sampling strategy based on the curvatures of the point-sampled surface to prioritize points with more geometric details. This sampling implies faster learning while preserving geometric\u00a0accuracy when compared with previous approaches. We also use the analytical derivatives of a neural implicit function to estimate the differential measures of the underlying point-sampled surface.",
        "countries": [
            "BR",
            "PT"
        ]
    },
    "10.1016/j.cag.2022.08.003": {
        "doi": "10.1016/j.cag.2022.08.003",
        "authors": [
            {
                "family": "Mello",
                "given": "Claudio Dornelles",
                "countries": [
                    "BR"
                ]
            },
            {
                "family": "Moreira",
                "given": "Bryan Umpierre",
                "countries": [
                    "BR"
                ]
            },
            {
                "family": "de Oliveira Evald",
                "given": "Paulo Jefferson Dias",
                "countries": [
                    "BR"
                ]
            },
            {
                "family": "Drews",
                "given": "Paulo Jorge Lilles",
                "countries": [
                    "BR"
                ]
            },
            {
                "family": "da Costa Botelho",
                "given": "Silvia Silva",
                "countries": [
                    "BR"
                ]
            }
        ],
        "title": "Underwater enhancement based on a self-learning strategy and attention mechanism for high-intensity regions",
        "journal": "Computers & Graphics",
        "publication_year": 2022,
        "volume": "107",
        "number": "",
        "pages": "264\u2013276",
        "number_of_pages": 13,
        "article_number": "",
        "abstract": "Images acquired during underwater activities suffer from environmental properties of the water, such as turbidity and light attenuation. These phenomena cause color distortion, blurring, and contrast reduction. In addition, irregular ambient light distribution causes color channel unbalance and regions with high-intensity pixels. Recent works related to underwater image enhancement, and based on deep learning approaches, tackle the lack of paired datasets generating synthetic ground-truth. In this paper, we present a self-supervised learning methodology for underwater image enhancement based on deep learning that requires no paired datasets. The proposed method estimates the degradation present in underwater images. Besides, an autoencoder reconstructs this image, and its output image is degraded using the estimated degradation information. Therefore, the strategy replaces the output image with the degraded version in the loss function during the training phase. This procedure misleads the neural network that learns to compensate the additional degradation. As a result, the reconstructed image is an enhanced version of the input image. Also, the algorithm presents an attention module to reduce high-intensity areas generated in enhanced images by color channel unbalances and outlier regions. Furthermore, the proposed methodology requires no ground-truth. Besides, only real underwater images were used to train the neural network, and the results indicate the effectiveness of the method in terms of color preservation, color cast reduction, and contrast improvement.",
        "countries": [
            "BR"
        ]
    },
    "10.1016/j.cag.2022.07.018": {
        "doi": "10.1016/j.cag.2022.07.018",
        "authors": [
            {
                "family": "Moscoso Thompson",
                "given": "Elia",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Ranieri",
                "given": "Andrea",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Biasotti",
                "given": "Silvia",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Chicchon",
                "given": "Miguel",
                "countries": [
                    "PE"
                ]
            },
            {
                "family": "Sipiran",
                "given": "Ivan",
                "countries": [
                    "CL"
                ]
            },
            {
                "family": "Pham",
                "given": "Minh-Khoi",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nguyen-Ho",
                "given": "Thang-Long",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nguyen",
                "given": "Hai-Dang",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Tran",
                "given": "Minh-Triet",
                "countries": [
                    "VN"
                ]
            }
        ],
        "title": "SHREC 2022: Pothole and crack detection in the road pavement using images and RGB-D data",
        "journal": "Computers & Graphics",
        "publication_year": 2022,
        "volume": "107",
        "number": "",
        "pages": "161\u2013171",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "This paper describes the methods submitted for evaluation to the SHREC 2022 track on pothole and crack detection in the road pavement. A total of 7 different runs for the semantic segmentation of the road surface are compared, 6 from the participants plus a baseline method. All methods exploit Deep Learning techniques and their performance is tested using the same environment (i.e., a single Jupyter notebook). A training set, composed of 3836 semantic segmentation image/mask pairs and 797 RGB-D video clips collected with the latest depth cameras was made available to the participants. The methods are then evaluated on the 496 image/masks pairs in the validation set, on the 504 pairs in the test set and finally on 8 video clips. The analysis of the results is based on quantitative metrics for image segmentation and qualitative analysis of the video clips. The participation and the results show that the scenario is of great interest and that the use of RGB-D data is still challenging in this context.",
        "countries": [
            "IT",
            "PE",
            "CL",
            "VN"
        ]
    },
    "10.1016/j.cag.2022.07.020": {
        "doi": "10.1016/j.cag.2022.07.020",
        "authors": [
            {
                "family": "Feng",
                "given": "Yifan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Gao",
                "given": "Yue",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhao",
                "given": "Xibin",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Guo",
                "given": "Yandong",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Bagewadi",
                "given": "Nihar",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Bui",
                "given": "Nhat-Tan",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Dao",
                "given": "Hieu",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Gangisetty",
                "given": "Shankar",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Guan",
                "given": "Ripeng",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Han",
                "given": "Xie",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Hua",
                "given": "Cong",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Hunakunti",
                "given": "Chidambar",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Jiang",
                "given": "Yu",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Jiao",
                "given": "Shichao",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Ke",
                "given": "Yuqi",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Kuang",
                "given": "Liqun",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Liu",
                "given": "Anan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Nguyen",
                "given": "Dinh-Huan",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nguyen",
                "given": "Hai-Dang",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nie",
                "given": "Weizhi",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Pham",
                "given": "Bang-Dang",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Raikar",
                "given": "Karthik",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Tang",
                "given": "Qingmei",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Tran",
                "given": "Minh-Triet",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Wan",
                "given": "Jialong",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Yan",
                "given": "Chenggang",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "You",
                "given": "Haoxuan",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Zhu",
                "given": "Difei",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "SHREC\u201922 track: Open-Set 3D Object Retrieval",
        "journal": "Computers & Graphics",
        "publication_year": 2022,
        "volume": "107",
        "number": "",
        "pages": "231\u2013240",
        "number_of_pages": 10,
        "article_number": "",
        "abstract": "This paper reports the results of the SHREC\u201922 track: Open-Set 3D Object Retrieval, the goal of which is to evaluate the performance of different retrieval algorithms under the Open-Set setting and modality-missing setting, respectively. Since objects from unseen categories are very common in real-world applications, we design the open-set 3D object retrieval to expand the application of traditional 3D object retrieval. In this track, we generate open-set 3D object retrieval datasets OS-MN40 and OS-MN40-Miss based on the ModelNet40 dataset, which are collected for the open-set setting and both open-set setting and modality-missing setting, respectively. Both the two datasets include the training set (2822 objects from 8 categories) and the retrieval set (960 query objects and 8527 target objects from the other 32 categories). The categories of retrieval (query/target) sets are not seen in the training set. For each object in the OS-MN40, four types of modalities, including mesh, point cloud, multi-view, and voxel, are provided. Each object in the OS-MN40-Miss is represented with incomplete modality information, which is collected to simulate the retrieval task in the real world. This track attracted eight participants from four countries and 191 runs of all submissions. The evaluation results show a promising scenario about open-set retrieval on 3D objects with multi-modal and multi-resolution representation and reveal interesting insights in dealing with retrieving 3D objects in unknown-category objects.",
        "countries": [
            "CN",
            "IN",
            "VN",
            "CN",
            "US"
        ]
    },
    "10.1016/j.cag.2022.07.011": {
        "doi": "10.1016/j.cag.2022.07.011",
        "authors": [
            {
                "family": "Lemeunier",
                "given": "Cl\u00e9ment",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Denis",
                "given": "Florence",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Lavou\u00e9",
                "given": "Guillaume",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Dupont",
                "given": "Florent",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Representation learning of 3D meshes using an Autoencoder in the spectral domain",
        "journal": "Computers & Graphics",
        "publication_year": 2022,
        "volume": "107",
        "number": "",
        "pages": "131\u2013143",
        "number_of_pages": 13,
        "article_number": "",
        "abstract": "Learning on surfaces is a difficult task: the data being non-Euclidean makes the transfer of known techniques such as convolutions and pooling non trivial. Common methods deploy processes to apply deep learning operations to triangular meshes either in the spatial domain by defining weights between nodes, or in the spectral domain using first order Chebyshev polynomials followed by a return in the spatial domain. In this study, we present a Spectral Autoencoder (SAE) enabling the application of deep learning techniques to 3D meshes by directly giving spectral coefficients obtained with a spectral transform as inputs. With a dataset composed of surfaces having the same connectivity, it is possible with the Graph Laplacian to express the geometry of all samples in the frequency domain. Then, by using an Autoencoder architecture, we are able to extract important features from spectral coefficients without going back to the spatial domain. Finally, a latent space is built from which reconstruction and interpolation is possible. This method allows the treatment of meshes with more vertices by keeping the same architecture, and allows to learn on big datasets with short computation times. Through experiments, we demonstrate that this architecture is able to give better results than state of the art methods in a faster way.",
        "countries": [
            "FR"
        ]
    },
    "10.1016/j.cag.2022.07.004": {
        "doi": "10.1016/j.cag.2022.07.004",
        "authors": [
            {
                "family": "Romanengo",
                "given": "Chiara",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Raffo",
                "given": "Andrea",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Biasotti",
                "given": "Silvia",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Falcidieno",
                "given": "Bianca",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Fotis",
                "given": "Vlassis",
                "countries": [
                    "GR"
                ]
            },
            {
                "family": "Romanelis",
                "given": "Ioannis",
                "countries": [
                    "GR"
                ]
            },
            {
                "family": "Psatha",
                "given": "Eleftheria",
                "countries": [
                    "GR"
                ]
            },
            {
                "family": "Moustakas",
                "given": "Konstantinos",
                "countries": [
                    "GR"
                ]
            },
            {
                "family": "Sipiran",
                "given": "Ivan",
                "countries": [
                    "CL"
                ]
            },
            {
                "family": "Nguyen",
                "given": "Quang-Thuc",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Chu",
                "given": "Chi-Bien",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nguyen-Ngoc",
                "given": "Khoi-Nguyen",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Vo",
                "given": "Dinh-Khoi",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "To",
                "given": "Tuan-An",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nguyen",
                "given": "Nham-Tan",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Le-Pham",
                "given": "Nhat-Quynh",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nguyen",
                "given": "Hai-Dang",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Tran",
                "given": "Minh-Triet",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Qie",
                "given": "Yifan",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Anwer",
                "given": "Nabil",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "SHREC 2022: Fitting and recognition of simple geometric primitives on point clouds",
        "journal": "Computers & Graphics",
        "publication_year": 2022,
        "volume": "107",
        "number": "",
        "pages": "32\u201349",
        "number_of_pages": 18,
        "article_number": "",
        "abstract": "This paper presents the methods that have participated in the SHREC 2022 track on the fitting and recognition of simple geometric primitives on point clouds. As simple primitives we mean the classical surface primitives derived from constructive solid geometry, i.e., planes, spheres, cylinders, cones and tori. The aim of the track is to evaluate the quality of automatic algorithms for fitting and recognizing geometric primitives on point clouds. Specifically, the goal is to identify, for each point cloud, its primitive type and some geometric descriptors. For this purpose, we created a synthetic dataset, divided into a training set and a test set, containing segments perturbed with different kinds of point cloud artifacts. Among the six participants to this track, two are based on direct methods, while four are either fully based on deep learning or combine direct and neural approaches. The performance of the methods is evaluated using various classification and approximation measures.",
        "countries": [
            "IT",
            "GR",
            "CL",
            "VN",
            "FR"
        ]
    },
    "10.1016/j.cag.2022.07.015": {
        "doi": "10.1016/j.cag.2022.07.015",
        "authors": [
            {
                "family": "Emporio",
                "given": "Marco",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Caputo",
                "given": "Ariel",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Giachetti",
                "given": "Andrea",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Cristani",
                "given": "Marco",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Borghi",
                "given": "Guido",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "D\u2019Eusanio",
                "given": "Andrea",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Le",
                "given": "Minh-Quan",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nguyen",
                "given": "Hai-Dang",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Tran",
                "given": "Minh-Triet",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Ambellan",
                "given": "Felix",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Hanik",
                "given": "Martin",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Nava-Yazdani",
                "given": "Esfandiar",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "von Tycowicz",
                "given": "Christoph",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "SHREC 2022 track on online detection of heterogeneous gestures",
        "journal": "Computers & Graphics",
        "publication_year": 2022,
        "volume": "107",
        "number": "",
        "pages": "241\u2013251",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "This paper presents the outcomes of a contest organized to evaluate methods for the online recognition of heterogeneous gestures from sequences of 3D hand poses. The task is the detection of gestures belonging to a dictionary of 16 classes characterized by different pose and motion features. The dataset features continuous sequences of hand tracking data where the gestures are interleaved with non-significant motions. The data have been captured using the Hololens 2 finger tracking system in a realistic use-case of mixed reality interaction. The evaluation is based not only on the detection performances but also on the latency and the false positives, making it possible to understand the feasibility of practical interaction tools based on the algorithms proposed. The outcomes of the contest\u2019s evaluation demonstrate the necessity of further research to reduce recognition errors, while the computational cost of the algorithms proposed is sufficiently low.",
        "countries": [
            "IT",
            "VN",
            "DE"
        ]
    },
    "10.1016/j.cag.2022.06.008": {
        "doi": "10.1016/j.cag.2022.06.008",
        "authors": [
            {
                "family": "Damiand",
                "given": "Guillaume",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Nivoliers",
                "given": "Vincent",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Query-replace operations for topologically controlled 3D mesh editing",
        "journal": "Computers & Graphics",
        "publication_year": 2022,
        "volume": "106",
        "number": "",
        "pages": "187\u2013199",
        "number_of_pages": 13,
        "article_number": "",
        "abstract": "We propose a generic framework to describe modifications on 3D objects (surfaces and volumes) based on a query and replace mechanism. These modifications are described in terms of rewriting rules: a set of patterns is provided, each one defining a possible replacement. The patterns are expressed using 3D combinatorial maps, ensuring the global topological validity of the transformed mesh. At the core of the framework, we use topological signatures to efficiently query and match patterns on the input. Our formalism can generically describe many different transformations like subdivision, smoothing, topological correction, or remeshing. Its interest is twofold. It provides an easy implementation for such operations, especially when many cases arise: we provide an example with over 300 cases. It is also able to detect corner cases that were not provided and are required to ensure the topological correctness of the output.",
        "countries": [
            "FR"
        ]
    },
    "10.1016/j.cag.2022.07.005": {
        "doi": "10.1016/j.cag.2022.07.005",
        "authors": [
            {
                "family": "Gagliardi",
                "given": "Luca",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Raffo",
                "given": "Andrea",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Fugacci",
                "given": "Ulderico",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Biasotti",
                "given": "Silvia",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Rocchia",
                "given": "Walter",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Huang",
                "given": "Hao",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Amor",
                "given": "Boulbaba Ben",
                "countries": [
                    "AE"
                ]
            },
            {
                "family": "Fang",
                "given": "Yi",
                "countries": [
                    "AE"
                ]
            },
            {
                "family": "Zhang",
                "given": "Yuanyuan",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Wang",
                "given": "Xiao",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Christoffer",
                "given": "Charles",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Kihara",
                "given": "Daisuke",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Axenopoulos",
                "given": "Apostolos",
                "countries": [
                    "GR"
                ]
            },
            {
                "family": "Mylonas",
                "given": "Stelios",
                "countries": [
                    "GR"
                ]
            },
            {
                "family": "Daras",
                "given": "Petros",
                "countries": [
                    "GR"
                ]
            }
        ],
        "title": "SHREC 2022: Protein\u2013ligand binding site recognition",
        "journal": "Computers & Graphics",
        "publication_year": 2022,
        "volume": "107",
        "number": "",
        "pages": "20\u201331",
        "number_of_pages": 12,
        "article_number": "",
        "abstract": "This paper presents the methods that have participated in the SHREC 2022 contest on protein\u2013ligand binding site recognition. The prediction of protein- ligand binding regions is an active research domain in computational biophysics and structural biology and plays a relevant role for molecular docking and drug design. The goal of the contest is to assess the effectiveness of computational methods in recognizing ligand binding sites in a protein based on its geometrical structure. Performances of the segmentation algorithms are analyzed according to two evaluation scores describing the capacity of a putative pocket to contact a ligand and to pinpoint the correct binding region. Despite some methods perform remarkably, we show that simple non-machine-learning approaches remain very competitive against data-driven algorithms. In general, the task of pocket detection remains a challenging learning problem which suffers of intrinsic difficulties due to the lack of negative examples (data imbalance problem).",
        "countries": [
            "IT",
            "US",
            "AE"
        ]
    },
    "10.1016/j.simpa.2022.100367": {
        "doi": "10.1016/j.simpa.2022.100367",
        "authors": [
            {
                "family": "Arnaoutakis",
                "given": "Georgios E.",
                "countries": [
                    "GR"
                ]
            },
            {
                "family": "Papadakis",
                "given": "Nikolaos",
                "countries": [
                    "GR"
                ]
            },
            {
                "family": "Katsaprakakis",
                "given": "Dimitris Al.",
                "countries": [
                    "GR"
                ]
            }
        ],
        "title": "CombiCSP: A python routine for dynamic modeling of concentrating solar power plants",
        "journal": "Software Impacts",
        "publication_year": 2022,
        "volume": "13",
        "number": "",
        "pages": "100367:1\u2013100367:2",
        "number_of_pages": 2,
        "article_number": "100367",
        "abstract": "CombiCSP is an open source software for dynamic modeling of concentrating solar energy power plants. CombiCSP utilizes solar resource, system engineering inputs as well as financial tools to provide dynamic simulations and annual yields of concentrating solar power plants. It readily provides modeling of plants based on solar power tower and parabolic trough collectors and it can be extended to novel solar energy modeling approaches and analyses as needed.",
        "countries": [
            "GR"
        ]
    },
    "10.1016/j.cag.2022.06.007": {
        "doi": "10.1016/j.cag.2022.06.007",
        "authors": [
            {
                "family": "Ishikawa",
                "given": "Shudai",
                "countries": [
                    "JP"
                ]
            },
            {
                "family": "Ikenaga",
                "given": "Takumi",
                "countries": [
                    "JP"
                ]
            }
        ],
        "title": "Image-based virtual try-on system with clothing extraction module that adapts to any posture",
        "journal": "Computers & Graphics",
        "publication_year": 2022,
        "volume": "106",
        "number": "",
        "pages": "161\u2013173",
        "number_of_pages": 13,
        "article_number": "",
        "abstract": "In this study, we developed a virtual try-on system that automatically creates a clothing model from a person\u2019s image, and thus a clothing model is not required as an input. Recently, the scale of the E-commerce market in the fashion field has expanded. When purchasing clothes on a fashion E-commerce site, a user can browse and buy various brands at once without visiting a physical store. However, users cannot pick up the actual clothes and try them on. Therefore, the user may not be satisfied with the design and size after receiving clothing bought on-line. Virtual try-on systems have been developed in various studies that allow users to virtually try on clothes using a computer. In particular, many image-based virtual try-on systems have been reported that transition the clothing model\u2019s features to the clothing area on the target person. However, this method has the following problems: (1) it is necessary to prepare a clothing model in advance and (2) the posture for changing clothes is restricted. Thus, we developed a virtual try-on system that does not require a clothing model as an input, thereby enabling the automatic creation of a clothing model from a person\u2019s image by incorporating a clothing extraction module into the virtual try-on system. In addition, we improved the virtual try-on system so it can adapt to any posture and evaluated the improvements in simulations.",
        "countries": [
            "JP"
        ]
    },
    "10.1016/j.cag.2022.06.001": {
        "doi": "10.1016/j.cag.2022.06.001",
        "authors": [
            {
                "family": "Mesika",
                "given": "Adi",
                "countries": [
                    "IL"
                ]
            },
            {
                "family": "Ben-Shabat",
                "given": "Yizhak",
                "countries": [
                    "IL",
                    "AU"
                ]
            },
            {
                "family": "Tal",
                "given": "Ayellet",
                "countries": [
                    "IL"
                ]
            }
        ],
        "title": "CloudWalker: Random walks for 3D point cloud shape analysis",
        "journal": "Computers & Graphics",
        "publication_year": 2022,
        "volume": "106",
        "number": "",
        "pages": "110\u2013118",
        "number_of_pages": 9,
        "article_number": "",
        "abstract": "Point clouds are gaining prominence as a method for representing 3D shapes, but their irregular structure poses a challenge for deep learning methods. In this paper we propose CloudWalker, a novel method for learning 3D shapes using random walks. Previous works attempt to adapt Convolutional Neural Networks (CNNs) or impose a grid or mesh structure to 3D point clouds. This work presents a different approach for representing and learning the shape from a given point set. The key idea is to impose structure on the point set by multiple random walks through the cloud for exploring different regions of the 3D object. Then we learn a per-point and per-walk representation and aggregate multiple walk predictions at inference. Our approach achieves state-of-the-art results for two 3D shape analysis tasks: classification and retrieval.",
        "countries": [
            "IL",
            "AU"
        ]
    },
    "10.1016/j.cag.2022.05.009": {
        "doi": "10.1016/j.cag.2022.05.009",
        "authors": [
            {
                "family": "Agathos",
                "given": "Alexander",
                "countries": [
                    "GR"
                ]
            },
            {
                "family": "Azariadis",
                "given": "Philip",
                "countries": [
                    "GR"
                ]
            },
            {
                "family": "Kyratzi",
                "given": "Sofia",
                "countries": [
                    "GR"
                ]
            }
        ],
        "title": "Elliptic Gabriel Taubin smoothing of point clouds",
        "journal": "Computers & Graphics",
        "publication_year": 2022,
        "volume": "106",
        "number": "",
        "pages": "20\u201332",
        "number_of_pages": 13,
        "article_number": "",
        "abstract": "A point cloud smoothing algorithm is presented which is based on the mesh filtering procedure of Taubin. This is accomplished by defining a robust one-ring neighborhood for each vertex of the point cloud based on the elliptic Gabriel graph and by incorporating non-uniform Gaussian weights during the smoothing process. The proposed method is robust to noise and very simple to implement. It is able to produce high quality smoothed point clouds that avoid the shrinkage, point clustering and edge over-smoothing problems, without the use of normal information which is computationally unstable on noisy point sets. Through an extensive comparison with state-of-the-art smoothing methods the advantages of the proposed method in both free-form and CAD-oriented models are presented. A framework for efficient GPU implementation is also provided. The proposed method is able to process more than 15 million points in about 20 secs making it very suitable for point sets produced by modern 3D scanners.",
        "countries": [
            "GR"
        ]
    },
    "10.1016/j.cag.2021.10.017": {
        "doi": "10.1016/j.cag.2021.10.017",
        "authors": [
            {
                "family": "Xiao",
                "given": "Dong",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Lin",
                "given": "Siyou",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Shi",
                "given": "Zuoqiang",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wang",
                "given": "Bin",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Learning modified indicator functions for surface reconstruction",
        "journal": "Computers & Graphics",
        "publication_year": 2022,
        "volume": "102",
        "number": "",
        "pages": "309\u2013319",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "Surface reconstruction is a fundamental problem in 3D graphics. In this paper, we propose a learning-based approach for implicit surface reconstruction from raw point clouds without normals. Our method is inspired by Gauss Lemma in potential energy theory, which gives an explicit integral formula for the indicator functions. We design a novel deep neural network to perform surface integral and learn the modified indicator functions from un-oriented and noisy point clouds. We concatenate features with different scales for accurate point-wise contributions to the integral. Moreover, we propose a novel Surface Element Feature Extractor to learn local shape properties. Experiments show that our method generates smooth surfaces with high normal consistency from point clouds with different noise scales and achieves state-of-the-art reconstruction performance compared with current data-driven and non-data-driven approaches.",
        "countries": [
            "CN"
        ]
    },
    "10.1016/j.cag.2021.11.005": {
        "doi": "10.1016/j.cag.2021.11.005",
        "authors": [
            {
                "family": "Ma",
                "given": "Jing",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wang",
                "given": "Jin",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Li",
                "given": "Jituo",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhang",
                "given": "Dongliang",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Real-time skeletonization for sketch-based modeling",
        "journal": "Computers & Graphics",
        "publication_year": 2022,
        "volume": "102",
        "number": "",
        "pages": "56\u201366",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "Skeleton creation is an important phase in the character animation pipeline. However, handcrafting skeleton takes extensive labor time and domain knowledge. Automatic skeletonization provides a solution. However, most of the current approaches are far from real-time and lack the flexibility to control the skeleton complexity. In this paper, we present an efficient skeletonization method, which can be seamlessly integrated into the sketch-based modeling process in real-time. The method contains three steps: (i) local sub-skeleton extraction; (ii) sub-skeleton connection; and (iii) global skeleton refinement. Firstly, the local skeleton is extracted from processed polygon stroke and forms a subpart along with the sub-mesh. Then, local sub-skeletons are connected according to the intersecting relationships and modeling sequence of subparts. Lastly, a global refinement method is proposed to gives users coarse-to-fine control on the connected skeleton. We demonstrate the effectiveness of our method on a variety of examples created from both novices and professionals.",
        "countries": [
            "CN"
        ]
    },
    "10.1016/j.cag.2021.10.021": {
        "doi": "10.1016/j.cag.2021.10.021",
        "authors": [
            {
                "family": "Chen",
                "given": "Qiaorui",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhang",
                "given": "Shuai",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zheng",
                "given": "Yao",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Enhanced narrow band surface reconstruction with anisotropic kernel",
        "journal": "Computers & Graphics",
        "publication_year": 2022,
        "volume": "102",
        "number": "",
        "pages": "280\u2013288",
        "number_of_pages": 9,
        "article_number": "",
        "abstract": "This paper presents a novel pipeline that improves the efficiency of narrowband surface reconstruction for particle-based fluids. Different from previous narrow band methods, we only construct the scalar field in the outer surface region. A method with robust criteria for detecting the outer surface vertices of the scalar field is then proposed to eliminate the redundant inner vertices, leading to a significant reduction in the computational complexity and memory consumption. The presented pipeline is fully parallel with a parallel compact memory scheme to avoid race conditions. Several experiments are conducted to compare our present method with the state-of-the-art approach, and the results indicate that our method saves nearly half of the computing time and ten percent of the memory consumption.",
        "countries": [
            "CN"
        ]
    },
    "10.1016/j.cag.2021.07.010": {
        "doi": "10.1016/j.cag.2021.07.010",
        "authors": [
            {
                "family": "Sipiran",
                "given": "Ivan",
                "countries": [
                    "CL"
                ]
            },
            {
                "family": "Lazo",
                "given": "Patrick",
                "countries": [
                    "PE"
                ]
            },
            {
                "family": "Lopez",
                "given": "Cristian",
                "countries": [
                    "PE"
                ]
            },
            {
                "family": "Jimenez",
                "given": "Milagritos",
                "countries": [
                    "PE"
                ]
            },
            {
                "family": "Bagewadi",
                "given": "Nihar",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Bustos",
                "given": "Benjamin",
                "countries": [
                    "CL"
                ]
            },
            {
                "family": "Dao",
                "given": "Hieu",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Gangisetty",
                "given": "Shankar",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Hanik",
                "given": "Martin",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Ho-Thi",
                "given": "Ngoc-Phuong",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Holenderski",
                "given": "Mike",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Jarnikov",
                "given": "Dmitri",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Labrada",
                "given": "Arniel",
                "countries": [
                    "CL"
                ]
            },
            {
                "family": "Lengauer",
                "given": "Stefan",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Licandro",
                "given": "Roxane",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Nguyen",
                "given": "Dinh-Huan",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nguyen-Ho",
                "given": "Thang-Long",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Perez Rey",
                "given": "Luis A.",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Pham",
                "given": "Bang-Dang",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Pham",
                "given": "Minh-Khoi",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Preiner",
                "given": "Reinhold",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Schreck",
                "given": "Tobias",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Trinh",
                "given": "Quoc-Huy",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Tonnaer",
                "given": "Loek",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "von Tycowicz",
                "given": "Christoph",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Vu-Le",
                "given": "The-Anh",
                "countries": [
                    "VN"
                ]
            }
        ],
        "title": "SHREC 2021: Retrieval of cultural heritage objects",
        "journal": "Computers & Graphics",
        "publication_year": 2021,
        "volume": "100",
        "number": "",
        "pages": "1\u201320",
        "number_of_pages": 20,
        "article_number": "",
        "abstract": "This paper presents the methods and results of the SHREC\u201921 track on a dataset of cultural heritage (CH) objects. We present a dataset of 938 scanned models that have varied geometry and artistic styles. For the competition, we propose two challenges: the retrieval-by-shape challenge and the retrieval-by-culture challenge. The former aims at evaluating the ability of retrieval methods to discriminate cultural heritage objects by overall shape. The latter focuses on assessing the effectiveness of retrieving objects from the same culture. Both challenges constitute a suitable scenario to evaluate modern shape retrieval methods in a CH domain. Ten groups participated in the challenges: thirty runs were submitted for the retrieval-by-shape task, and twenty-six runs were submitted for the retrieval-by-culture task. The results show a predominance of learning methods on image-based multi-view representations to characterize 3D objects. Nevertheless, the problem presented in our challenges is far from being solved. We also identify the potential paths for further improvements and give insights into the future directions of research.",
        "countries": [
            "CL",
            "PE",
            "IN",
            "VN",
            "DE",
            "NL",
            "AT"
        ]
    },
    "10.1016/j.cag.2021.06.010": {
        "doi": "10.1016/j.cag.2021.06.010",
        "authors": [
            {
                "family": "Raffo",
                "given": "Andrea",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Fugacci",
                "given": "Ulderico",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Biasotti",
                "given": "Silvia",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Rocchia",
                "given": "Walter",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Liu",
                "given": "Yonghuai",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Otu",
                "given": "Ekpo",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Zwiggelaar",
                "given": "Reyer",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Hunter",
                "given": "David",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Zacharaki",
                "given": "Evangelia I.",
                "countries": [
                    "GR"
                ]
            },
            {
                "family": "Psatha",
                "given": "Eleftheria",
                "countries": [
                    "GR"
                ]
            },
            {
                "family": "Laskos",
                "given": "Dimitrios",
                "countries": [
                    "GR"
                ]
            },
            {
                "family": "Arvanitis",
                "given": "Gerasimos",
                "countries": [
                    "GR"
                ]
            },
            {
                "family": "Moustakas",
                "given": "Konstantinos",
                "countries": [
                    "GR"
                ]
            },
            {
                "family": "Aderinwale",
                "given": "Tunde",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Christoffer",
                "given": "Charles",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Shin",
                "given": "Woong-Hee",
                "countries": [
                    "KR"
                ]
            },
            {
                "family": "Kihara",
                "given": "Daisuke",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Giachetti",
                "given": "Andrea",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Nguyen",
                "given": "Huu-Nghia",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nguyen",
                "given": "Tuan-Duy",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nguyen-Truong",
                "given": "Vinh-Thuyen",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Le-Thanh",
                "given": "Danh",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Nguyen",
                "given": "Hai-Dang",
                "countries": [
                    "VN"
                ]
            },
            {
                "family": "Tran",
                "given": "Minh-Triet",
                "countries": [
                    "VN"
                ]
            }
        ],
        "title": "SHREC 2021: Retrieval and classification of protein surfaces equipped with physical and chemical properties",
        "journal": "Computers & Graphics",
        "publication_year": 2021,
        "volume": "99",
        "number": "",
        "pages": "1\u201321",
        "number_of_pages": 21,
        "article_number": "",
        "abstract": "This paper presents the methods that have participated in the SHREC 2021 contest on retrieval and classification of protein surfaces on the basis of their geometry and physicochemical properties. The goal of the contest is to assess the capability of different computational approaches to identify different conformations of the same protein, or the presence of common sub-parts, starting from a set of molecular surfaces. We addressed two problems: defining the similarity solely based on the surface geometry or with the inclusion of physicochemical information, such as electrostatic potential, amino acid hydrophobicity, and the presence of hydrogen bond donors and acceptors. Retrieval and classification performances, with respect to the single protein or the existence of common sub-sequences, are analysed according to a number of information retrieval indicators.",
        "countries": [
            "IT",
            "GB",
            "GR",
            "US",
            "KR",
            "VN"
        ]
    },
    "10.1016/j.cag.2021.09.005": {
        "doi": "10.1016/j.cag.2021.09.005",
        "authors": [
            {
                "family": "Arslan",
                "given": "Mazlum Ferhat",
                "countries": [
                    "TR"
                ]
            },
            {
                "family": "Haridis",
                "given": "Alexandros",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Rosin",
                "given": "Paul L.",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Tari",
                "given": "Sibel",
                "countries": [
                    "TR"
                ]
            },
            {
                "family": "Brassey",
                "given": "Charlotte",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Gardiner",
                "given": "James D.",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Genctav",
                "given": "Asli",
                "countries": [
                    "TR"
                ]
            },
            {
                "family": "Genctav",
                "given": "Murat",
                "countries": [
                    "TR",
                    "US",
                    "GB"
                ]
            }
        ],
        "title": "SHREC\u201921: Quantifying shape complexity",
        "journal": "Computers & Graphics",
        "publication_year": 2022,
        "volume": "102",
        "number": "",
        "pages": "144\u2013153",
        "number_of_pages": 10,
        "article_number": "",
        "abstract": "This paper presents the results of SHREC\u201921 track: Quantifying Shape Complexity. Our goal is to investigate how good the submitted shape complexity measures are (i.e. with respect to ground truth) and investigate the relationships between these complexity measures (i.e. with respect to correlations). The dataset consists of three collections: 1800 perturbed cube and sphere models classified into 4 categories, 50 shapes inspired from the fields of architecture and design classified into 2 categories, and the data from the Princeton Segmentation Benchmark, which consists of 19 natural object categories. We evaluate the performances of the methods by computing Kendall rank correlation coefficients both between the orders produced by each complexity measure and the ground truth and between the pair of orders produced by each pair of complexity measures. Our work, being a quantitative and reproducible analysis with justified ground truths, presents an improved means and methodology for the evaluation of shape complexity.",
        "countries": [
            "TR"
        ]
    },
    "10.1016/j.cag.2021.09.013": {
        "doi": "10.1016/j.cag.2021.09.013",
        "authors": [
            {
                "family": "Romanengo",
                "given": "Chiara",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Raffo",
                "given": "Andrea",
                "countries": [
                    "IT",
                    "NO"
                ]
            },
            {
                "family": "Qie",
                "given": "Yifan",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Anwer",
                "given": "Nabil",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Falcidieno",
                "given": "Bianca",
                "countries": [
                    "IT"
                ]
            }
        ],
        "title": "Fit4CAD: A point cloud benchmark for fitting simple geometric primitives in CAD objects",
        "journal": "Computers & Graphics",
        "publication_year": 2022,
        "volume": "102",
        "number": "",
        "pages": "133\u2013143",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "We propose Fit4CAD, a benchmark for the evaluation and comparison of methods for fitting simple geometric primitives in point clouds representing CAD objects. This benchmark is meant to help both method developers and those who want to identify the best performing tools. The Fit4CAD dataset is composed by 225 high quality point clouds, each of which has been obtained by sampling a CAD object. The way these elements were created by using existing platforms and datasets makes the benchmark easily expandable. The dataset is already split into a training set and a test set. To assess performance and accuracy of the different primitive fitting methods, various measures are defined. To demonstrate the effective use of Fit4CAD, we have tested it on two methods belonging to two different categories of approaches to the primitive fitting problem: a clustering method based on a primitive growing framework and a parametric method based on the Hough transform.",
        "countries": [
            "IT",
            "NO",
            "FR"
        ]
    },
    "10.1016/j.cag.2021.07.001": {
        "doi": "10.1016/j.cag.2021.07.001",
        "authors": [
            {
                "family": "Manda",
                "given": "Bharadwaj",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Dhayarkar",
                "given": "Shubham",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Mitheran",
                "given": "Sai",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Viekash",
                "given": "V.K.",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Muthuganapathy",
                "given": "Ramanathan",
                "countries": [
                    "IN"
                ]
            }
        ],
        "title": "\u2018CADSketchNet\u2019 - An Annotated Sketch dataset for 3D CAD Model Retrieval with Deep Neural Networks",
        "journal": "Computers & Graphics",
        "publication_year": 2021,
        "volume": "99",
        "number": "",
        "pages": "100\u2013113",
        "number_of_pages": 14,
        "article_number": "",
        "abstract": "Ongoing advancements in the fields of 3D modelling and digital archiving have led to an outburst in the amount of data stored digitally. Consequently, several retrieval systems have been developed depending on the type of data stored in these databases. However, unlike text data or images, performing a search for 3D models is non-trivial. Among 3D models, retrieving 3D Engineering/CAD models or mechanical components is even more challenging due to the presence of holes, volumetric features, presence of sharp edges etc., which make CAD a domain unto itself. The research work presented in this paper aims at developing a dataset suitable for building a retrieval system for 3D CAD models based on deep learning. 3D CAD models from the available CAD databases are collected, and a dataset of computer-generated sketch data, termed \u2018CADSketchNet\u2019, has been prepared. Additionally, hand-drawn sketches of the components are also added to CADSketchNet. Using the sketch images from this dataset, the paper also aims at evaluating the performance of various retrieval system or a search engine for 3D CAD models that accepts a sketch image as the input query. Many experimental models are constructed and tested on CADSketchNet. These experiments, along with the model architecture, choice of similarity metrics are reported along with the search results.",
        "countries": [
            "IN"
        ]
    },
    "10.1016/j.cag.2021.07.022": {
        "doi": "10.1016/j.cag.2021.07.022",
        "authors": [
            {
                "family": "McDonnell",
                "given": "Rachel",
                "countries": [
                    "IE"
                ]
            },
            {
                "family": "Zibrek",
                "given": "Katja",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Carrigan",
                "given": "Emma",
                "countries": [
                    "IE"
                ]
            },
            {
                "family": "Dahyot",
                "given": "Rozenn",
                "countries": [
                    "IE"
                ]
            }
        ],
        "title": "Model for predicting perception of facial action unit activation using virtual humans",
        "journal": "Computers & Graphics",
        "publication_year": 2021,
        "volume": "100",
        "number": "",
        "pages": "81\u201392",
        "number_of_pages": 12,
        "article_number": "",
        "abstract": "Blendshape facial rigs are used extensively in the industry for facial animation of virtual humans. However, storing and manipulating large numbers of facial meshes (blendshapes) is costly in terms of memory and computation for gaming applications. Blendshape rigs are comprised of sets of semantically-meaningful expressions, which govern how expressive the character will be, often based on Action Units from the Facial Action Coding System (FACS). However, the relative perceptual importance of blendshapes has not yet been investigated. Research in Psychology and Neuroscience has shown that our brains process faces differently than other objects so we postulate that the perception of facial expressions will be feature-dependent rather than based purely on the amount of movement required to make the expression. Therefore, we believe that perception of blendshape visibility will not be reliably predicted by numerical calculations of the difference between the expression and the neutral mesh. In this paper, we explore the noticeability of blendshapes under different activation levels, and present new perceptually-based models to predict perceptual importance of blendshapes. The models predict visibility based on commonly-used geometry and image-based metrics.",
        "countries": [
            "IE",
            "FR"
        ]
    },
    "10.1016/j.cad.2021.103069": {
        "doi": "10.1016/j.cad.2021.103069",
        "authors": [
            {
                "family": "Mart\u00ednez",
                "given": "Jon\u00e0s",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Random Auxetic Porous Materials from Parametric Growth Processes",
        "journal": "Computer-Aided Design",
        "publication_year": 2021,
        "volume": "139",
        "number": "",
        "pages": "103069:1\u2013103069:11",
        "number_of_pages": 11,
        "article_number": "103069",
        "abstract": "We introduce a computational approach to optimize random porous materials via parametric growth processes. We focus on the problem of minimizing the Poisson\u2019s ratio of a two-phase porous random material, which results in an auxetic material. Initially, we perform a parametric optimization of the growth process. Afterward, the optimized parametric growth process implicitly generates an auxetic random material. Namely, the growth process intrinsically entails the formation of an auxetic material. Our approach enables the computation of large-scale auxetic random materials in commodity computers. We also provide numerical results indicating that the computed auxetic materials have close to isotropic linear elastic behavior and physical tests revealing auxetic behavior.",
        "countries": [
            "FR"
        ]
    },
    "10.1016/j.cag.2021.07.018": {
        "doi": "10.1016/j.cag.2021.07.018",
        "authors": [
            {
                "family": "Blokland",
                "given": "Bart Iver van",
                "countries": [
                    "NO"
                ]
            },
            {
                "family": "Theoharis",
                "given": "Theoharis",
                "countries": [
                    "NO"
                ]
            }
        ],
        "title": "Partial 3D object retrieval using local binary QUICCI descriptors and dissimilarity tree indexing",
        "journal": "Computers & Graphics",
        "publication_year": 2021,
        "volume": "100",
        "number": "",
        "pages": "32\u201342",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "A complete pipeline is presented for accurate and efficient partial 3D object retrieval based on Quick Intersection Count Change Image (QUICCI) binary local descriptors and a novel indexing tree. It is shown how a modification to the QUICCI query descriptor makes it ideal for partial retrieval. An indexing structure called Dissimilarity Tree is proposed which can significantly accelerate searching the large space of local descriptors; this is applicable to QUICCI and other binary descriptors. The index exploits the distribution of bits within descriptors for efficient retrieval. The retrieval pipeline is tested on the artificial part of SHREC\u201916 dataset with near-ideal retrieval results.",
        "countries": [
            "NO"
        ]
    },
    "10.1016/j.cag.2021.06.015": {
        "doi": "10.1016/j.cag.2021.06.015",
        "authors": [
            {
                "family": "Zhang",
                "given": "Jie",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Liu",
                "given": "Jian",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Liu",
                "given": "Xiuping",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wei",
                "given": "Jiang",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Cao",
                "given": "Junjie",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Tang",
                "given": "Kewei",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Feature interpolation convolution for point cloud analysis",
        "journal": "Computers & Graphics",
        "publication_year": 2021,
        "volume": "99",
        "number": "",
        "pages": "182\u2013191",
        "number_of_pages": 10,
        "article_number": "",
        "abstract": "Point clouds, as the native output of many real-world 3D sensors, can not be trivially consumed by convolutional networks in the same way with the 2D image. This is mainly caused by the irregular organization of points. In this paper, we propose a new convolution operation, named Feature Interpolation Convolution (FI-Conv), which is computationally efficient, invariant to the order of points, and robust to different samples and varying densities. First, point clouds are viewed as discrete samples of continuous space. The feature corresponding to one point is seen as a sampled point of continuous feature function. We desire a set of points, named key points, to describe the important locations of the convolution and relatively stable points of the feature function, such as extreme or inflection points. In our method, the positions of key points are trainable parameters of the networks, i.e., we can optimize the positions of key points. Then, we interpolate point features onto the learned key points. Finally, a standard convolution operation is applied to these estimated features. We use FI-Conv to replace the convolution operations of some cutting-edge networks. Experiments show that FI-Conv effectively improves the performance of these networks and achieves on par or better performance than state-of-the-art methods on multiple challenging benchmark datasets and tasks.",
        "countries": [
            "CN"
        ]
    },
    "10.1016/j.cag.2021.02.003": {
        "doi": "10.1016/j.cag.2021.02.003",
        "authors": [
            {
                "family": "Li",
                "given": "Shi",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zheng",
                "given": "Chuankun",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wang",
                "given": "Rui",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Huo",
                "given": "Yuchi",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zheng",
                "given": "Wenting",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Lin",
                "given": "Hai",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Bao",
                "given": "Hujun",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Multi-resolution terrain rendering using summed-area tables",
        "journal": "Computers & Graphics",
        "publication_year": 2021,
        "volume": "95",
        "number": "",
        "pages": "130\u2013140",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "Due to the fundamental weaknesses of level-of-detail (LOD) control and rich details in the Geometry Clipmaps, we propose a multi-resolution terrain rendering algorithm that utilizes summed-area tables (SATs)\u00a0[1] to facilitate the rendering of terrain with better geometric and shading details. First, our algorithm introduces a novel geometric error bound on the screen-based terrain rendering approach that juggles low rendering throughput and better LOD control. Geometric errors are estimated in real-time from SATs, enabling error-bounded geometry clipmap. Second, we utilize Spherical Gaussian (SG) functions to approximate lighting and bidirectional reflection distribution functions (BRDFs), and efficiently calculate outgoing radiance with self-occlusions of the terrain. SATs are utilized to enable the mipmapping of visibility and normal maps. We demonstrate the improvements of our method with experiments on accuracy and efficiency.",
        "countries": [
            "CN"
        ]
    },
    "10.1016/j.cag.2021.01.014": {
        "doi": "10.1016/j.cag.2021.01.014",
        "authors": [
            {
                "family": "Joshi",
                "given": "Piyush",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Rastegarpanah",
                "given": "Alireza",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Stolkin",
                "given": "Rustam",
                "countries": [
                    "GB"
                ]
            }
        ],
        "title": "A training free technique for 3D object recognition using the concept of vibration, energy and frequency",
        "journal": "Computers & Graphics",
        "publication_year": 2021,
        "volume": "95",
        "number": "",
        "pages": "92\u2013105",
        "number_of_pages": 14,
        "article_number": "",
        "abstract": "This paper presents a local surface feature based 3D object recognition technique that is free from any training and handles texture-less objects. Our technique is proposed based on building a strong relationship among the different regions of an object using the combination of Vibration, Energy and Frequency of points in a point cloud. The robustness of the proposed technique has been validated by comparing with top-rated training free recognition techniques on the Bologna dataset. Results show that the proposed technique has performed well and efficiently as top-rated techniques on this dataset. In real time scenario, captured scenes by an RGBD camera are cluttered with many unwanted objects and background. Most of the state-of-the-art techniques (techniques that are training free and recognize texture-less objects) have not experimented on such scenes in the literature. To observe the performance, we propose to present a 3D dataset of 10 texture-less objects (including industrial and household objects). Our experimental results demonstrate that the proposed technique has outperformed other state-of-the-art techniques on the proposed dataset. We also experiment on three very cluttered and occluded RGBD datasets (Challenge, Clutter and Willow). The poor performance of all techniques on these datasets has revealed the need for more robust techniques in the future.",
        "countries": [
            "GB"
        ]
    },
    "10.1016/j.cag.2020.09.007": {
        "doi": "10.1016/j.cag.2020.09.007",
        "authors": [
            {
                "family": "Jiang",
                "given": "Giulio",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Kainz",
                "given": "Bernhard",
                "countries": [
                    "GB"
                ]
            }
        ],
        "title": "Deep radiance caching: Convolutional autoencoders deeper in ray tracing",
        "journal": "Computers & Graphics",
        "publication_year": 2021,
        "volume": "94",
        "number": "",
        "pages": "22\u201331",
        "number_of_pages": 10,
        "article_number": "",
        "abstract": "Rendering realistic images with global illumination is a computationally demanding task and often requires dedicated hardware for feasible runtime. Recent research uses Deep Neural Networks to predict indirect lighting on image level, but such methods are commonly limited to diffuse materials and require training on each scene. We present Deep Radiance Caching (DRC), an efficient variant of Radiance Caching utilizing Convolutional Autoencoders for rendering global illumination. DRC employs a denoising neural network with Radiance Caching to support a wide range of material types, without the requirement of offline pre-computation or training for each scene. This offers high performance CPU rendering for maximum accessibility. Our method has been evaluated on interior scenes, and is able to produce high-quality images within 180 s on a single CPU.",
        "countries": [
            "GB"
        ]
    },
    "10.1016/j.cag.2020.09.001": {
        "doi": "10.1016/j.cag.2020.09.001",
        "authors": [
            {
                "family": "Blokland",
                "given": "Bart Iver van",
                "countries": [
                    "NO"
                ]
            },
            {
                "family": "Theoharis",
                "given": "Theoharis",
                "countries": [
                    "NO"
                ]
            }
        ],
        "title": "An indexing scheme and descriptor for 3D object retrieval based on local shape querying",
        "journal": "Computers & Graphics",
        "publication_year": 2020,
        "volume": "92",
        "number": "",
        "pages": "55\u201366",
        "number_of_pages": 12,
        "article_number": "",
        "abstract": "A binary descriptor indexing scheme based on Hamming distance called the Hamming tree for local shape queries is presented. A new binary clutter resistant descriptor named Quick Intersection Count Change Image (QUICCI) is also introduced. This local shape descriptor is extremely small and fast to compare. Additionally, a novel distance function called Weighted Hamming applicable to QUICCI images is proposed for retrieval applications. The effectiveness of the indexing scheme and QUICCI is demonstrated on 828 million QUICCI images derived from the SHREC2017 dataset, while the clutter resistance of QUICCI is shown using the clutterbox experiment.",
        "countries": [
            "NO"
        ]
    },
    "10.1016/j.cag.2020.08.008": {
        "doi": "10.1016/j.cag.2020.08.008",
        "authors": [
            {
                "family": "Dyke",
                "given": "Roberto M.",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Lai",
                "given": "Yu-Kun",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Rosin",
                "given": "Paul L.",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Zappal\u00e0",
                "given": "Stefano",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Dykes",
                "given": "Seana",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Guo",
                "given": "Daoliang",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Li",
                "given": "Kun",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Marin",
                "given": "Riccardo",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Melzi",
                "given": "Simone",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Yang",
                "given": "Jingyu",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "SHREC\u201920: Shape correspondence with non-isometric deformations",
        "journal": "Computers & Graphics",
        "publication_year": 2020,
        "volume": "92",
        "number": "",
        "pages": "28\u201343",
        "number_of_pages": 16,
        "article_number": "",
        "abstract": "Estimating correspondence between two shapes continues to be a challenging problem in geometry processing. Most current methods assume deformation to be near-isometric, however this is often not the case. For this paper, a collection of shapes of different animals has been curated, where parts of the animals (e.g., mouths, tails & ears) correspond yet are naturally non-isometric. Ground-truth correspondences were established by asking three specialists to independently label corresponding points on each of the models with respect to a previously labelled reference model. We employ an algorithmic strategy to select a single point for each correspondence that is representative of the proposed labels. A novel technique that characterises the sparsity and distribution of correspondences is employed to measure the performance of ten shape correspondence methods.",
        "countries": [
            "GB",
            "CN",
            "IT"
        ]
    },
    "10.1016/j.cag.2020.07.007": {
        "doi": "10.1016/j.cag.2020.07.007",
        "authors": [
            {
                "family": "van Blokland",
                "given": "Bart Iver",
                "countries": [
                    "NO"
                ]
            },
            {
                "family": "Theoharis",
                "given": "Theoharis",
                "countries": [
                    "NO"
                ]
            }
        ],
        "title": "Radial intersection count image: A clutter resistant 3D shape descriptor",
        "journal": "Computers & Graphics",
        "publication_year": 2020,
        "volume": "91",
        "number": "",
        "pages": "118\u2013128",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "A novel shape descriptor for cluttered scenes is presented, the Radial Intersection Count Image (RICI), and is shown to significantly outperform the classic Spin Image (SI) and 3D Shape Context (3DSC) in both uncluttered and, more significantly, cluttered scenes. It is also faster to compute and compare. The clutter resistance of the RICI is mainly due to the design of a novel distance function, capable of disregarding clutter to a great extent. As opposed to the SI and 3DSC, which both count point samples, the RICI uses intersection counts with the mesh surface, and is therefore noise-free. For efficient RICI construction, novel algorithms of general interest were developed. These include an efficient circle-triangle intersection algorithm and an algorithm for projecting a point into SI-like (\u03b1, \u03b2) coordinates. The \u2019clutterbox experiment\u2019 is also introduced as a better way of evaluating descriptors\u2019 response to clutter. The SI, 3DSC, and RICI are evaluated in this framework and the advantage of the RICI is clearly demonstrated.",
        "countries": [
            "NO"
        ]
    },
    "10.1016/j.cag.2020.08.001": {
        "doi": "10.1016/j.cag.2020.08.001",
        "authors": [
            {
                "family": "Garrison",
                "given": "Laura",
                "countries": [
                    "NO"
                ]
            },
            {
                "family": "Va\u0161\u00ed\u010dek",
                "given": "Jakub",
                "countries": [
                    "CZ"
                ]
            },
            {
                "family": "Craven",
                "given": "Alexander R.",
                "countries": [
                    "NO"
                ]
            },
            {
                "family": "Gr\u00fcner",
                "given": "Renate",
                "countries": [
                    "NO"
                ]
            },
            {
                "family": "Smit",
                "given": "Noeska N.",
                "countries": [
                    "NO"
                ]
            },
            {
                "family": "Bruckner",
                "given": "Stefan",
                "countries": [
                    "NO"
                ]
            }
        ],
        "title": "Interactive visual exploration of metabolite ratios in MR spectroscopy studies",
        "journal": "Computers & Graphics",
        "publication_year": 2020,
        "volume": "92",
        "number": "",
        "pages": "1\u201312",
        "number_of_pages": 12,
        "article_number": "",
        "abstract": "Magnetic resonance spectroscopy (MRS) is an advanced biochemical technique used to identify metabolic compounds in living tissue. While its sensitivity and specificity to chemical imbalances render it a valuable tool in clinical assessment, the results from this modality are abstract and difficult to interpret. With this design study we characterized and explored the tasks and requirements for evaluating these data from the perspective of a MRS research specialist. Our resulting tool, SpectraMosaic, links with upstream spectroscopy quantification software to provide a means for precise interactive visual analysis of metabolites with both single- and multi-peak spectral signatures. Using a layered visual approach, SpectraMosaic allows researchers to analyze any permutation of metabolites in ratio form for an entire cohort, or by sample region, individual, acquisition date, or brain activity status at the time of acquisition. A case study with three MRS researchers demonstrates the utility of our approach in rapid and iterative spectral data analysis.",
        "countries": [
            "NO",
            "CZ"
        ]
    },
    "10.1016/j.cag.2020.06.001": {
        "doi": "10.1016/j.cag.2020.06.001",
        "authors": [
            {
                "family": "Hu",
                "given": "Zhiyu",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhang",
                "given": "Dongbo",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Li",
                "given": "Shuai",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Qin",
                "given": "Hong",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Attention-based relation and context modeling for point cloud semantic segmentation",
        "journal": "Computers & Graphics",
        "publication_year": 2020,
        "volume": "90",
        "number": "",
        "pages": "126\u2013134",
        "number_of_pages": 9,
        "article_number": "",
        "abstract": "Semantic segmentation of point cloud is a fundamental problem in scene-level understanding. Despite advancement in recent years by leveraging capabilities of Neural Networks and massive labeling datasets available, providing fine-grained semantic segmentation for point cloud is still challenging, given the fact that point cloud is usually unstructured, unordered and sparse. In this paper, we achieve semantic point cloud labeling by adaptively exploring semantic relation and aggregating contextual information between points. Specifically, we first introduce an attention-based local relation learning module for collecting local features, which can capture semantic relation in a manner of anisotropy. And we then design a novel context aggregation module guided by multi-scale supervision to obtain long-range dependencies between semantically-correlated points and enhance the distinctive ability of points in feature space. In addition, a gated propagation strategy is adopted instead of skip links to conditionally concatenate local point features in different layers. We empirically evaluate our method on public benchmarks (S3DIS and ShapeNetPart), and demonstrate our performance is on par or better than state-of-the-art methods.",
        "countries": [
            "CN",
            "US"
        ]
    },
    "10.1016/j.cag.2020.05.029": {
        "doi": "10.1016/j.cag.2020.05.029",
        "authors": [
            {
                "family": "Dong",
                "given": "Zhetong",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Hu",
                "given": "Chuanfeng",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhou",
                "given": "Chi",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Lin",
                "given": "Hongwei",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Vectorization of persistence barcode with applications in pattern classification of porous structures",
        "journal": "Computers & Graphics",
        "publication_year": 2020,
        "volume": "90",
        "number": "",
        "pages": "182\u2013192",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "Persistence barcode is a topological summary for persistent homology to exhibit topological features with different persistence. Persistence rank function (PRF), derived from persistence barcode, organizes persistence Betti numbers in the form of an integer-valued function. To obtain topological patterns of objects such as point clouds represented by finite-dimensional vectors for machine learning classification tasks, the vectorizing representations of barcodes is generated via decomposing PRF on a system of Haar basis. Theoretically, the generated vectorizing representation is proved to have 1-Wasserstein stability. In practice, to reduce training time and achieve better results, a technique of dimensionality reduction through out-of-sample mapping in supervised manifold learning is used to generate a low-dimensional vector. Experiments demonstrate that the representation is effective for capturing the topological patterns of data sets. Moreover, the classification of porous structures has become an essential problem in the fields such as material science in recent decades. The proposed method is successfully applied to distinguish porous structures on a novel data set of porous models.",
        "countries": [
            "CN"
        ]
    },
    "10.1016/j.cag.2020.05.028": {
        "doi": "10.1016/j.cag.2020.05.028",
        "authors": [
            {
                "family": "van Onzenoodt",
                "given": "Christian",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Huckauf",
                "given": "Anke",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Ropinski",
                "given": "Timo",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "On the perceptual influence of shape overlap on data-comparison using scatterplots",
        "journal": "Computers & Graphics",
        "publication_year": 2020,
        "volume": "90",
        "number": "",
        "pages": "169\u2013181",
        "number_of_pages": 13,
        "article_number": "",
        "abstract": "Scatterplots can be used for a wide range of visual analysis tasks, for example comparing correlations or variances of clusters across potentially multiple classes of data, in order to find answers to higher-level questions. Comparing classes of data in one scatterplot demands additional visual channels to encode this dimension. While perception research suggests colors as rather perceptually dominant, other studies show that shapes can also be visually salient. However, with an increasing amount of data, overlapping shapes can cause perceptual difficulties and obscure data. Even though shapes in scatterplots have been investigated extensively, the overlap between these shapes has usually been avoided by using synthetic scatterplots. To overcome this limitation, we investigate the perceptual implications of overlap when comparing data using scatterplots using a series of crowd-sourced user studies. These studies include common visual analysis tasks, like comparing the number of points, comparing mean values, and determine the set of points that is more clustered. To support our investigations, we introduced and compared four metrics for overlap in scatterplots. Our results provide insight into the overlap in scatterplots, recommend combinations of shapes that are less prone to overlap, and outline how our metrics could be used to optimize future scatterplot design.",
        "countries": [
            "DE"
        ]
    },
    "10.1016/j.cag.2020.05.024": {
        "doi": "10.1016/j.cag.2020.05.024",
        "authors": [
            {
                "family": "Boges",
                "given": "Daniya",
                "countries": [
                    "SA"
                ]
            },
            {
                "family": "Agus",
                "given": "Marco",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Sicat",
                "given": "Ronell",
                "countries": [
                    "SA"
                ]
            },
            {
                "family": "Magistretti",
                "given": "Pierre J.",
                "countries": [
                    "SA"
                ]
            },
            {
                "family": "Hadwiger",
                "given": "Markus",
                "countries": [
                    "SA"
                ]
            },
            {
                "family": "Cal\u00ec",
                "given": "Corrado",
                "countries": [
                    "IT"
                ]
            }
        ],
        "title": "Virtual reality framework for editing and exploring medial axis representations of nanometric scale neural structures",
        "journal": "Computers & Graphics",
        "publication_year": 2020,
        "volume": "91",
        "number": "",
        "pages": "12\u201324",
        "number_of_pages": 13,
        "article_number": "",
        "abstract": "We present a novel virtual reality (VR) based framework for the exploratory analysis of nanoscale 3D reconstructions of cellular structures acquired from rodent brain samples through serial electron microscopy. The system is specifically targeted on medial axis representations (skeletons) of branched and tubular structures of cellular shapes, and it is designed for providing to domain scientists: i) effective and fast semi-automatic interfaces for tracing skeletons directly on surface-based representations of cells and structures, ii) fast tools for proofreading, i.e., correcting and editing of semi-automatically constructed skeleton representations, and iii) natural methods for interactive exploration, i.e., measuring, comparing, and analyzing geometric features related to cellular structures based on medial axis representations. Neuroscientists currently use the system for performing morphology studies on sparse reconstructions of glial cells and neurons extracted from a sample of the somatosensory cortex of a juvenile rat. The framework runs in a standard PC and has been tested on two different display and interaction setups: PC-tethered stereoscopic head-mounted display (HMD) with 3D controllers and tracking sensors, and a large display wall with a standard gamepad controller. We report on a user study that we carried out for analyzing user performance on different tasks using these two setups.",
        "countries": [
            "SA",
            "IT"
        ]
    },
    "10.1016/j.gvc.2020.200013": {
        "doi": "10.1016/j.gvc.2020.200013",
        "authors": [
            {
                "family": "Steed",
                "given": "Chad A.",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Goodall",
                "given": "John R.",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Chae",
                "given": "Junghoon",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Trofimov",
                "given": "Artem",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "CrossVis: A visual analytics system for exploring heterogeneous multivariate data with applications to materials and climate sciences",
        "journal": "Graphics and Visual Computing",
        "publication_year": 2020,
        "volume": "3",
        "number": "",
        "pages": "200013:1\u2013200013:13",
        "number_of_pages": 13,
        "article_number": "200013",
        "abstract": "We present a new visual analytics system, called CrossVis, that allows flexible exploration of multivariate data with heterogeneous data types. After presenting the design requirements, which were derived from prior collaborations with domain experts, we introduce key features of CrossVis beginning with a tabular data model that coordinates multiple linked views and performance enhancements that enable scalable exploration of complex data. Next, we introduce extensions to the parallel coordinates plot, which include new axis representations for numerical, temporal, categorical, and image data, an embedded bivariate axis option, dynamic selections, focus+context axis scaling, and graphical indicators of key statistical values. We demonstrate the practical effectiveness of CrossVis through two scientific use cases; one focused on understanding neural network image classifications from a genetic engineering project and another involving general exploration of a large and complex data set of historical hurricane observations. We conclude with discussions regarding domain expert feedback, future enhancements to address limitations, and the interdisciplinary process used to design CrossVis.",
        "countries": [
            "US"
        ]
    },
    "10.1016/j.cag.2019.05.024": {
        "doi": "10.1016/j.cag.2019.05.024",
        "authors": [
            {
                "family": "Delanoy",
                "given": "Johanna",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Coeurjolly",
                "given": "David",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Lachaud",
                "given": "Jacques-Olivier",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Bousseau",
                "given": "Adrien",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Combining voxel and normal predictions for multi-view 3D sketching",
        "journal": "Computers & Graphics",
        "publication_year": 2019,
        "volume": "82",
        "number": "",
        "pages": "65\u201372",
        "number_of_pages": 8,
        "article_number": "",
        "abstract": "Recent works on data-driven sketch-based modeling use either voxel grids or normal/depth maps as geometric representations compatible with convolutional neural networks. While voxel grids can represent complete objects \u2013 including parts not visible in the sketches \u2013 their memory consumption restricts them to low-resolution predictions. In contrast, a single normal or depth map can capture fine details, but multiple maps from different viewpoints need to be predicted and fused to produce a closed surface. We propose to combine these two representations to address their respective shortcomings in the context of a multi-view sketch-based modeling system. Our method predicts a voxel grid common to all the input sketches, along with one normal map per sketch. We then use the voxel grid as a support for normal map fusion by optimizing its extracted surface such that it is consistent with the re-projected normals, while being as piecewise-smooth as possible overall. We compare our method with a recent voxel prediction system, demonstrating improved recovery of sharp features over a variety of man-made objects.",
        "countries": [
            "FR"
        ]
    },
    "10.1016/j.cag.2018.05.015": {
        "doi": "10.1016/j.cag.2018.05.015",
        "authors": [
            {
                "family": "Parakkat",
                "given": "Amal Dev",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Methirumangalath",
                "given": "Subhasree",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Muthuganapathy",
                "given": "Ramanathan",
                "countries": [
                    "IN"
                ]
            }
        ],
        "title": "Peeling the longest: A simple generalized curve reconstruction algorithm",
        "journal": "Computers & Graphics",
        "publication_year": 2018,
        "volume": "74",
        "number": "",
        "pages": "191\u2013201",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "Given a planar point set sampled from a curve, the curve reconstruction problem computes a polygonal approximation of the curve. In this paper, we propose a Delaunay triangulation-based algorithm for curve reconstruction, which removes the longest edge of each triangle to result in a graph. Further, each vertex of the graph is checked for a degree constraint to compute simple closed/open curves. Assuming \u03f5-sampling, we provide theoretical guarantee which ensures that a simple closed/open curve is a piecewise linear approximation of the original curve. Input point sets with outliers are handled as part of the algorithm, without pre-processing. We also propose strategies to identify the presence of noise and simplify a noisy point set, identify self-intersections and enhance our algorithm to reconstruct such point sets. Perhaps, this is the first algorithm to identify the presence of noise in a point set. Our algorithm is able to detect closed/open curves, disconnected components, multiple holes and sharp corners. The algorithm is simple to implement, independent of the type of input, non-feature specific and hence it is a generalized one. We have performed extensive comparative studies to demonstrate that our method is comparable or better than other existing methods. Limitations of our approach have also been discussed.",
        "countries": [
            "IN"
        ]
    },
    "10.1016/j.cag.2018.05.016": {
        "doi": "10.1016/j.cag.2018.05.016",
        "authors": [
            {
                "family": "Gonzalez",
                "given": "Diego",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "van Kaick",
                "given": "Oliver",
                "countries": [
                    "CA"
                ]
            }
        ],
        "title": "3D synthesis of man-made objects based on fine-grained parts",
        "journal": "Computers & Graphics",
        "publication_year": 2018,
        "volume": "74",
        "number": "",
        "pages": "150\u2013160",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "We present a novel approach for 3D shape synthesis from a collection of existing models. The main idea of our approach is to synthesize shapes by recombining fine-grained parts extracted from the existing models based purely on the objects\u2019 geometry. Thus, unlike most previous works, a key advantage of our method is that it does not require a semantic segmentation, nor part correspondences between the shapes of the input set. Our method uses a template shape to guide the synthesis. After extracting a set of fine-grained segments from the input dataset, we compute the similarity among the segments in the collection and segments of the template using shape descriptors. Next, we use the similarity estimates to select, from the set of fine-grained segments, compatible replacements for each part of the template. By sampling different segments for each part of the template, and by using different templates, our method can synthesize many distinct shapes that have a variety of local fine details. Additionally, we maintain the plausibility of the objects by preserving the general structure of the template. We show with several experiments performed on different datasets that our algorithm can be used for synthesizing a wide variety of man-made objects.",
        "countries": [
            "CA"
        ]
    },
    "10.1016/j.cag.2018.05.014": {
        "doi": "10.1016/j.cag.2018.05.014",
        "authors": [
            {
                "family": "Yadav",
                "given": "Sunil Kumar",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Reitebuch",
                "given": "Ulrich",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Skrodzki",
                "given": "Martin",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Zimmermann",
                "given": "Eric",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Polthier",
                "given": "Konrad",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Constraint-based point set denoising using normal voting tensor and restricted quadratic error metrics",
        "journal": "Computers & Graphics",
        "publication_year": 2018,
        "volume": "74",
        "number": "",
        "pages": "234\u2013243",
        "number_of_pages": 10,
        "article_number": "",
        "abstract": "In many applications, point set surfaces are acquired by 3D scanners. During this acquisition process, noise and outliers are inevitable. For a high fidelity surface reconstruction from a noisy point set, a feature preserving point set denoising operation has to be performed to remove noise and outliers from the input point set. To suppress these undesired components while preserving features, we introduce an anisotropic point set denoising algorithm in the normal voting tensor framework. The proposed method consists of three different stages that are iteratively applied to the input: in the first stage, noisy vertex normals, are initially computed using principal component analysis, are processed using a vertex-based normal voting tensor and binary eigenvalues optimization. In the second stage, feature points are categorized into corners, edges, and surface patches using a weighted covariance matrix, which is computed based on the processed vertex normals. In the last stage, vertex positions are updated according to the processed vertex normals using restricted quadratic error metrics. For the vertex updates, we add different constraints to the quadratic error metric based on feature (edges and corners) and non-feature (planar) vertices. Finally, we show our method to be robust and comparable to state-of-the-art methods in several experiments.",
        "countries": [
            "DE"
        ]
    },
    "10.1016/j.cad.2017.05.014": {
        "doi": "10.1016/j.cad.2017.05.014",
        "authors": [
            {
                "family": "Kim",
                "given": "Yun-hyeong",
                "countries": [
                    "KR"
                ]
            },
            {
                "family": "Xi",
                "given": "Zhonghua",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Lien",
                "given": "Jyh-Ming",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Disjoint convex shell and its applications in mesh unfolding",
        "journal": "Computer-Aided Design",
        "publication_year": 2017,
        "volume": "90",
        "number": "",
        "pages": "180\u2013190",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "In this work, we study a geometric structure called disjoint convex shell or simply DC-shell. A DC-shell of a polyhedron is a set of pairwise interior disjoint convex objects that collectively approximate the given polyhedron. Preventing convex objects from overlapping enables faster and robust collision response and more realistic fracturing simulation. Without the disjointness constraint, a physical realization of the approximation becomes impossible. This paper investigates multiple approaches that construct DC-shells from shapes that are either composed of overlapping components or segmented into parts. We show theoretically that, even under this rather simplified setting, constructing DC-shell is difficult. To demonstrate the power of DC-shell, we studied how DC-shell can be used in mesh unfolding, an important computational method in manufacturing 3D shape from the 2D material. Approximating a given polyhedron model by DC-shells provides two major benefits. First, they are much easier to unfold using the existing unfolding methods. Second, they can be folded easily by both human folder or self-folding machines. Consequently, DC-shell makes paper craft creation and design more accessible to younger children and provides chances to enrich their education experiences.",
        "countries": [
            "KR",
            "US"
        ]
    },
    "10.1016/j.cag.2017.05.006": {
        "doi": "10.1016/j.cag.2017.05.006",
        "authors": [
            {
                "family": "Methirumangalath",
                "given": "Subhasree",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Kannan",
                "given": "Shyam Sundar",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Dev Parakkat",
                "given": "Amal",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Muthuganapathy",
                "given": "Ramanathan",
                "countries": [
                    "IN"
                ]
            }
        ],
        "title": "Hole detection in a planar point set: An empty disk approach",
        "journal": "Computers & Graphics",
        "publication_year": 2017,
        "volume": "66",
        "number": "",
        "pages": "124\u2013134",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "Given a planar point set S, outer boundary detection (shape reconstruction) is an extensively studied problem whereas, inner boundary (hole) detection is not a well researched one, probably because detecting the presence of a hole itself is a difficult task. Nevertheless, hole detection has wide applications in areas such as face recognition, model retrieval and pattern recognition. We present a Delaunay triangulation based strategy to detect the presence of holes and an algorithm to reconstruct them. Our algorithm is a unified one which reconstructs holes, both for a boundary sample (points sampled only from the boundary of the object) as well as for a dot pattern (points sampled from the entire object). Our method is a non-parametric one which detects holes irrespective of its shape. Assuming a sampling model, we provide theoretical analysis of the proposed algorithm, which ensures the correctness of the reconstructed holes, for specific structures. We conduct both qualitative and quantitative comparisons with existing methods and demonstrate that our method is better or comparable with them. Experiments with varying point densities and distributions demonstrate that the algorithm is independent of sampling. We also discuss the limitations of the algorithm.",
        "countries": [
            "IN"
        ]
    },
    "10.1016/j.cad.2017.05.004": {
        "doi": "10.1016/j.cad.2017.05.004",
        "authors": [
            {
                "family": "Kar\u010diauskas",
                "given": "K\u0229stutis",
                "countries": [
                    "LT"
                ]
            },
            {
                "family": "Peters",
                "given": "J\u00f6rg",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Improved shape for refinable surfaces with singularly parameterized irregularities",
        "journal": "Computer-Aided Design",
        "publication_year": 2017,
        "volume": "90",
        "number": "",
        "pages": "191\u2013198",
        "number_of_pages": 8,
        "article_number": "",
        "abstract": "To date, singularly-parameterized surface constructions suffer from poor highlight line distributions, ruling them out as a surface representation of choice for primary design surfaces. This paper explores graded, many-piece, everywhere C1 singularly-parameterized surface caps that mimic the shape of a high-quality guide surface. The approach illustrates the trade-off between polynomial degree and surface quality. For bi-degree 5, minor flaws in the highlight line distribution are still visible when zooming in on the singularity, but the distribution is good at the macroscopic level. Constructions of degree bi-4 or bi-3 may require one or more steps of guided subdivision to reach the same macroscopic quality. Akin to subdivision surfaces, singularly-parameterized functions on the surfaces are straightforward to refine.",
        "countries": [
            "LT",
            "US"
        ]
    },
    "10.1016/j.cag.2016.05.015": {
        "doi": "10.1016/j.cag.2016.05.015",
        "authors": [
            {
                "family": "Huang",
                "given": "Zhiyang",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Ju",
                "given": "Tao",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Extrinsically smooth direction fields",
        "journal": "Computers & Graphics",
        "publication_year": 2016,
        "volume": "58",
        "number": "",
        "pages": "109\u2013117",
        "number_of_pages": 9,
        "article_number": "",
        "abstract": "We consider the problem of finding a unit vector field (i.e., a direction field) over a domain that balances two competing objectives, smoothness and conformity to the shape of the domain. Common examples of this problem are finding normal directions along a curve and tangent directions over a surface. In a recent work, Jakob et al. observed that minimizing extrinsic variation of a tangent direction field on a surface achieves both objectives without the need for parameter-tuning or the use of additional constraints. Inspired by their empirical observations, we analyze the relation between extrinsic smoothness, intrinsic smoothness, and shape conformity in a continuous and general setting. Our analysis not only explains their observations but also suggests that an extrinsically smooth normal field along a curve can strike a similar balance between smoothness and shape-awareness. Our second contribution is offering extension of, justification for and improvement over the optimization framework of Jakob et al. In our experiments, we demonstrate the suitability of extrinsically smooth field in a variety of applications and compared with existing solutions.",
        "countries": [
            "US"
        ]
    },
    "10.1016/j.cag.2016.05.017": {
        "doi": "10.1016/j.cag.2016.05.017",
        "authors": [
            {
                "family": "Magalh\u00e3es",
                "given": "Salles V.G.",
                "countries": [
                    "BR",
                    "US"
                ]
            },
            {
                "family": "Andrade",
                "given": "Marcus V.A.",
                "countries": [
                    "BR"
                ]
            },
            {
                "family": "Franklin",
                "given": "W. Randolph",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Li",
                "given": "Wenli",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "PinMesh\u2014Fast and exact 3D point location queries using a uniform grid",
        "journal": "Computers & Graphics",
        "publication_year": 2016,
        "volume": "58",
        "number": "",
        "pages": "1\u201311",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "This paper presents PinMesh, a very fast algorithm with implementation to preprocess a polyhedral mesh, also known as a multi-material mesh, in order to perform 3D point location queries. PinMesh combines several innovative components to efficiently handle the largest available meshes. Because of a 2-level uniform grid, the expected preprocessing time is linear in the input size, and the code parallelizes well on a shared memory machine. Querying time is almost independent of the dataset size. PinMesh uses exact arithmetic with rational numbers to prevent roundoff errors, and symbolic perturbation with Simulation of Simplicity (SoS) to handle geometric degeneracies or special cases. PinMesh is intended to be a subroutine in more complex algorithms. It can preprocess a dataset and perform 1 million queries up to 27 times faster than RCT (Relative Closest Triangle), the current fastest algorithm. Preprocessing a sample dataset with 50 million triangles took only 14 elapsed seconds on a 16-core Xeon processor. The mean query time was 0.6\u03bcs.",
        "countries": [
            "BR",
            "US"
        ]
    },
    "10.1016/j.cag.2016.05.009": {
        "doi": "10.1016/j.cag.2016.05.009",
        "authors": [
            {
                "family": "Carlier",
                "given": "Axel",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Leonard",
                "given": "Kathryn",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Hahmann",
                "given": "Stefanie",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Morin",
                "given": "Geraldine",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Collins",
                "given": "Misha",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "The 2D shape structure dataset: A user annotated open access database",
        "journal": "Computers & Graphics",
        "publication_year": 2016,
        "volume": "58",
        "number": "",
        "pages": "23\u201330",
        "number_of_pages": 8,
        "article_number": "",
        "abstract": "In this paper we present the 2D Shape Structure database, a public, user-generated dataset of 2D shape decompositions into a hierarchy of shape parts with geometric relationships retained. It is the outcome of a large-scale user study obtained by crowdsourcing, involving over 1200 shapes in 70 shape classes, and 2861 participants. A total of 41,953 annotations has been collected with at least 24 annotations per shape. For each shape, user decompositions into main shape, one or more levels of parts, and a level of details are available. This database reinforces a philosophy that understanding shape structure as a whole, rather than in the separated categories of parts decomposition, parts hierarchy, and analysis of relationships between parts, is crucial for full shape understanding. We provide initial statistical explorations of the data to determine representative (\u201cmean\u201d) shape annotations and to determine the number of modes in the annotations. The primary goal of the paper is to make this rich and complex database openly available (through the website http://2dshapesstructure.github.io/index.html), providing the shape community with a ground truth of human perception of holistic shape structure.",
        "countries": [
            "FR",
            "US"
        ]
    },
    "10.1016/j.cag.2016.05.020": {
        "doi": "10.1016/j.cag.2016.05.020",
        "authors": [
            {
                "family": "\u010comi\u0107",
                "given": "Lidija",
                "countries": [
                    "RS"
                ]
            },
            {
                "family": "De Floriani",
                "given": "Leila",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Iuricich",
                "given": "Federico",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Magillo",
                "given": "Paola",
                "countries": [
                    "IT"
                ]
            }
        ],
        "title": "Computing a discrete Morse gradient from a watershed decomposition",
        "journal": "Computers & Graphics",
        "publication_year": 2016,
        "volume": "58",
        "number": "",
        "pages": "43\u201352",
        "number_of_pages": 10,
        "article_number": "",
        "abstract": "We consider the problem of segmenting triangle meshes endowed with a discrete scalar function f based on the critical points of f. The watershed transform induces a decomposition of the domain of function f into regions of influence of its minima, called catchment basins. The discrete Morse gradient induced by f allows recovering not only catchment basins but also a complete topological characterization of the function and of the shape on which it is defined through a Morse decomposition. Unfortunately, discrete Morse theory and related algorithms assume that the input scalar function has no flat areas, whereas such areas are common in real data and are easily handled by watershed algorithms. We propose here a new approach for building a discrete Morse gradient on a triangulated 3D shape endowed by a scalar function starting from the decomposition of the shape induced by the watershed transform. This allows for treating flat areas without adding noise to the data. Experimental results show that our approach has significant advantages over existing ones, which eliminate noise through perturbation: it is faster and always precise in extracting the correct number of critical elements.",
        "countries": [
            "RS",
            "US",
            "IT"
        ]
    },
    "10.1016/j.cad.2016.05.001": {
        "doi": "10.1016/j.cad.2016.05.001",
        "authors": [
            {
                "family": "Liu",
                "given": "Shengjun",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wang",
                "given": "Charlie C.L.",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Brunnett",
                "given": "Guido",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Wang",
                "given": "Jun",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "A closed-form formulation of HRBF-based surface reconstruction by approximate solution",
        "journal": "Computer-Aided Design",
        "publication_year": 2016,
        "volume": "78",
        "number": "",
        "pages": "147\u2013157",
        "number_of_pages": 11,
        "article_number": "",
        "abstract": "The Hermite radial basis functions (HRBFs) implicits have been used to reconstruct surfaces from scattered Hermite data points. In this work, we propose a closed-form formulation to construct HRBF-based implicits by a quasi-solution to approximate the exact one. A scheme is developed to automatically adjust the support sizes of basis functions to hold the error bound of a quasi-solution. Our method can generate an implicit function from positions and normals of scattered points without taking any global operation. Robust and efficient reconstructions are observed in our experimental tests on real data captured from a variety of scenes.",
        "countries": [
            "CN",
            "NL",
            "DE"
        ]
    },
    "10.1016/j.cad.2016.05.010": {
        "doi": "10.1016/j.cad.2016.05.010",
        "authors": [
            {
                "family": "Peraza Hernandez",
                "given": "Edwin A.",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Hartl",
                "given": "Darren J.",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Akleman",
                "given": "Ergun",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Lagoudas",
                "given": "Dimitris C.",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Modeling and analysis of origami structures with smooth folds",
        "journal": "Computer-Aided Design",
        "publication_year": 2016,
        "volume": "78",
        "number": "",
        "pages": "93\u2013106",
        "number_of_pages": 14,
        "article_number": "",
        "abstract": "Origami has the potential to impact numerous areas of design and manufacturing. Modeling and analysis of origami structures allow for the understanding of their behavior and the development of computational tools for their design. Most available origami models are limited to the idealization of folds as creases of zeroth-order geometric continuity, which is not proper for origami structures having non-negligible fold thickness or with maximum curvature at the folds restricted by material limitations. Structural analysis of origami sheets having creased folds requires further idealizations of the fold mechanical response such as the representation of the folds as torsional springs. In view of this, a novel model analogous to that for rigid origami is presented in this work for origami structures having folds of non-zero surface area that exhibit higher-order geometric continuity (termed smooth folds). This origami model allows for a proper structural analysis of origami sheets using plate or shell representations for the folds. The shape formulation of the smooth folds and the kinematic constraints on their associated shape variables are presented. Modeling of origami structures with smooth folds exhibiting elastic behavior is performed by determining the configuration of the structure that minimizes its total potential energy subject to the derived kinematic constraints. The presented results show that the structural response determined using the proposed model is in good agreement with both experiments and higher-fidelity finite element analyses.",
        "countries": [
            "US"
        ]
    },
    "10.1109/tvcg.2024.3355884": {
        "doi": "10.1109/tvcg.2024.3355884",
        "authors": [
            {
                "family": "Rogha",
                "given": "Milad",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Sah",
                "given": "Subham",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Karduni",
                "given": "Alireza",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Markant",
                "given": "Douglas",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Dou",
                "given": "Wenwen",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "The Impact of Elicitation and Contrasting Narratives on Engagement, Recall and Attitude Change With News Articles Containing Data Visualization",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "7",
        "pages": "4375\u20134389",
        "article_number": "",
        "number_of_pages": 15,
        "abstract": "News articles containing data visualizations play an important role in informing the public on issues ranging from public health to politics. Recent research on the persuasive appeal of data visualizations suggests that prior attitudes can be notoriously difficult to change. Inspired by an NYT article, we designed two experiments to evaluate the impact of elicitation and contrasting narratives on attitude change, recall, and engagement. We hypothesized that eliciting prior beliefs leads to more elaborative thinking that ultimately results in higher attitude change, better recall, and engagement. Our findings revealed that visual elicitation leads to higher engagement in terms of feelings of surprise. While there is an overall attitude change across all experiment conditions, we did not observe a significant effect of belief elicitation on attitude change. With regard to recall error, while participants in the draw trend elicitation exhibited significantly lower recall error than participants in the categorize trend condition, we found no significant difference in recall error when comparing elicitation conditions to no elicitation. In a follow-up study, we added contrasting narratives with the purpose of making the main visualization (communicating data on the focal issue) appear strikingly different. Compared to the results of Study 1, we found that contrasting narratives improved engagement in terms of surprise and interest but interestingly resulted in higher recall error and no significant change in attitude. We discuss the effects of elicitation and contrasting narratives in the context of topic involvement and the strengths of temporal trends encoded in the data visualization.",
        "countries": [
            "US",
            "CA"
        ]
    },
    "10.1109/tvcg.2023.3345532": {
        "doi": "10.1109/tvcg.2023.3345532",
        "authors": [
            {
                "family": "Zabel",
                "given": "Susanne",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Hennig",
                "given": "Philipp",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Nieselt",
                "given": "Kay",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "VIPurPCA: Visualizing and Propagating Uncertainty in Principal Component Analysis",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "4",
        "pages": "2011\u20132022",
        "article_number": "",
        "number_of_pages": 12,
        "abstract": "Variables obtained by experimental measurements or statistical inference typically carry uncertainties. When an algorithm uses such quantities as input variables, this uncertainty should propagate to the algorithm's output. Concretely, we consider the classic notion of principal component analysis (PCA): If it is applied to a finite data matrix containing imperfect (i.e., uncertain) multidimensional measurements, its output\u2014a lower-dimensional representation\u2014is itself subject to uncertainty. We demonstrate that this uncertainty can be approximated by appropriate linearization of the algorithm's nonlinear functionality, using automatic differentiation. By itself, however, this structured, uncertain output is difficult to interpret for users. We provide an animation method that effectively visualizes the uncertainty of the lower dimensional map. Implemented as an open-source software package, it allows researchers to assess the reliability of PCA embeddings.",
        "countries": [
            "DE"
        ]
    },
    "10.1109/tvcg.2023.3337173": {
        "doi": "10.1109/tvcg.2023.3337173",
        "authors": [
            {
                "family": "Wang",
                "given": "Shaoyu",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Yan",
                "given": "Hang",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Isaacs",
                "given": "Katherine E.",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Sun",
                "given": "Yifan",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Visual Exploratory Analysis for Designing Large-Scale Network-on-Chip Architectures: A Domain Expert-Led Design Study",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "4",
        "pages": "1970\u20131983",
        "article_number": "",
        "number_of_pages": 14,
        "abstract": "Visualization design studies bring together visualization researchers and domain experts to address yet unsolved data analysis challenges stemming from the needs of the domain experts. Typically, the visualization researchers lead the design study process and implementation of any visualization solutions. This setup leverages the visualization researchers\u2019 knowledge of methodology, design, and programming, but the availability to synchronize with the domain experts can hamper the design process. We consider an alternative setup where the domain experts take the lead in the design study, supported by the visualization experts. In this study, the domain experts are computer architecture experts who simulate and analyze novel computer chip designs. These chips rely on a Network-on-Chip (NOC) to connect components. The experts want to understand how the chip designs perform and what in the design led to their performance. To aid this analysis, we develop Vis4Mesh, a visualization system that provides spatial, temporal, and architectural context to simulated NOC behavior. Integration with an existing computer architecture visualization tool enables architects to perform deep-dives into specific architecture component behavior. We validate Vis4Mesh through a case study and a user study with computer architecture researchers. We reflect on our design and process, discussing advantages, disadvantages, and guidance for engaging in a domain expert-led design studies.",
        "countries": [
            "CN",
            "US"
        ]
    },
    "10.1016/j.cag.2024.103891": {
        "doi": "10.1016/j.cag.2024.103891",
        "authors": [
            {
                "family": "Huang",
                "given": "Hao",
                "countries": [
                    "AE",
                    "US"
                ]
            },
            {
                "family": "Yuan",
                "given": "Shuaihang",
                "countries": [
                    "AE",
                    "US"
                ]
            },
            {
                "family": "Peng",
                "given": "Zheng",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Hao",
                "given": "Yu",
                "countries": [
                    "AE",
                    "US"
                ]
            },
            {
                "family": "Wen",
                "given": "Congcong",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Fang",
                "given": "Yi",
                "countries": [
                    "AE",
                    "US"
                ]
            }
        ],
        "title": "A single 3D shape wavelet-based generative model",
        "journal": "Computers & Graphics",
        "publication_year": 2024,
        "volume": "119",
        "number": "",
        "pages": "103891:1\u2013103891:14",
        "number_of_pages": 14,
        "article_number": "103891",
        "abstract": "3D shape generation, vital in fields including computer graphics, industrial design, and robotics, has seen a significant growth due to deep learning advancements. Nevertheless, a prevailing challenge in this area lies in its heavy reliance on extensive data for training. Consequently, the ability to generate 3D shapes with a limited quantity of training samples emerges as a desirable objective. The aim of this research is to design deep generative models capable of learning from a single reference 3D shape, thereby eliminating the requirement for sizeable datasets. Drawing inspiration from contemporary Generative Adversarial Networks (GANs) that operate on individual 3D shapes in a coarse-to-fine manner hierarchically, we propose a novel wavelet-based framework for single 3D shape generation, which preserves the global shape structure whilst inducing local variability. Our key observation is that, through wavelet decomposition, the low-frequency components of two inputs, where one input is a corrupted version of the other, are very similar. This similarity enables reconstruction of the uncorrupted input by leveraging the low-frequency components of the corrupted version. This observation motivates us to propose the wavelet decomposition of the 2D tri-plane feature maps of a given 3D shape, followed by the synthesis of new tri-plane feature maps for shape generation. To the best of our knowledge, this work represents the first endeavor to incorporate wavelet analysis into a deep generative model for the purpose of generating novel 3D shapes with a single example. Furthermore, we adapt data augmentation and Coulomb adversarial generative loss to facilitate training and generation procedures. We demonstrate the effectiveness of our approach by generating diverse 3D shapes and conducting quantitative comparisons with established baseline methods. Our implementation is available at https://github.com/hhuang-code/SinWavelet.",
        "countries": [
            "AE",
            "US"
        ]
    },
    "10.1016/j.cag.2024.01.013": {
        "doi": "10.1016/j.cag.2024.01.013",
        "authors": [
            {
                "family": "Yurto\u011flu",
                "given": "Ayda",
                "countries": [
                    "TR"
                ]
            },
            {
                "family": "Sonlu",
                "given": "Sinan",
                "countries": [
                    "TR"
                ]
            },
            {
                "family": "Do\u011fan",
                "given": "Yal\u0131m",
                "countries": [
                    "TR"
                ]
            },
            {
                "family": "G\u00fcd\u00fckbay",
                "given": "U\u011fur",
                "countries": [
                    "TR"
                ]
            }
        ],
        "title": "Personality perception in human videos altered by motion transfer networks",
        "journal": "Computers & Graphics",
        "publication_year": 2024,
        "volume": "119",
        "number": "",
        "pages": "103886:1\u2013103886:11",
        "number_of_pages": 11,
        "article_number": "103886",
        "abstract": "The successful portrayal of personality in digital characters improves communication and immersion. Current research focuses on expressing personality through modifying animations using heuristic rules or data-driven models. While studies suggest motion style highly influences the apparent personality, the role of appearance can be similarly essential. This work analyzes the influence of movement and appearance on the perceived personality of short videos altered by motion transfer networks. We label the personalities in conference video clips with a user study to determine the samples that best represent the Five-Factor model\u2019s high, neutral, and low traits. We alter these videos using the Thin-Plate Spline Motion Model, utilizing the selected samples as the source and driving inputs. We follow five different cases to study the influence of motion and appearance on personality perception. Our comparative study reveals that motion and appearance influence different factors: motion strongly affects perceived extraversion, and appearance helps convey agreeableness and neuroticism.",
        "countries": [
            "TR"
        ]
    },
    "10.1109/tvcg.2023.3326517": {
        "doi": "10.1109/tvcg.2023.3326517",
        "authors": [
            {
                "family": "Zhao",
                "given": "Lixiang",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Isenberg",
                "given": "Tobias",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Xie",
                "given": "Fuqi",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Liang",
                "given": "Hai-Ning",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Yu",
                "given": "Lingyun",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "MeTACAST: Target- and Context-aware Spatial Selection in VR",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "1",
        "pages": "480\u2013494",
        "number_of_pages": 15,
        "article_number": "",
        "abstract": "We propose three novel spatial data selection techniques for particle data in VR visualization environments. They are designed to be target- and context-aware and be suitable for a wide range of data features and complex scenarios. Each technique is designed to be adjusted to particular selection intents: the selection of consecutive dense regions, the selection of filament-like structures, and the selection of clusters\u2014with all of them facilitating post-selection threshold adjustment. These techniques allow users to precisely select those regions of space for further exploration\u2014with simple and approximate 3D pointing, brushing, or drawing input\u2014using flexible point- or path-based input and without being limited by 3D occlusions, non-homogeneous feature density, or complex data shapes. These new techniques are evaluated in a controlled experiment and compared with the Baseline method, a region-based 3D painting selection. Our results indicate that our techniques are effective in handling a wide range of scenarios and allow users to select data based on their comprehension of crucial features. Furthermore, we analyze the attributes, requirements, and strategies of our spatial selection methods and compare them with existing state-of-the-art selection methods to handle diverse data features and situations. Based on this analysis we provide guidelines for choosing the most suitable 3D spatial selection techniques based on the interaction environment, the given data characteristics, or the need for interactive post-selection threshold adjustment.",
        "countries": [
            "CN",
            "FR"
        ]
    },
    "10.1145/3610548.3618163": {
        "doi": "10.1145/3610548.3618163",
        "authors": [
            {
                "family": "B\u00e6rentzen",
                "given": "J. Andreas",
                "countries": [
                    "DK"
                ]
            },
            {
                "family": "Frisvad",
                "given": "Jeppe Revall",
                "countries": [
                    "DK"
                ]
            },
            {
                "family": "Mart\u00ednez",
                "given": "Jon\u00e0s",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Curl Noise Jittering",
        "journal": "ACM SIGGRAPH Asia Conference Papers",
        "publication_year": 2023,
        "volume": "0",
        "number": "0",
        "pages": "88:1\u201388:11",
        "article_number": "88",
        "number_of_pages": 11,
        "abstract": "We propose a method for implicitly generating blue noise point sets. Our method is based on the observations that curl noise vector fields are volume-preserving and that jittering can be construed as moving points along the streamlines of a vector field. We demonstrate that the volume preservation keeps the points well separated when jittered using a curl noise vector field. At the same time, the anisotropy that stems from regular lattices is significantly reduced by such jittering. In combination, these properties entail that jittering by curl noise effectively transforms a regular lattice into a point set with blue noise properties. Our implicit method does not require computing the point set in advance. This makes our technique valuable when an arbitrarily large set of points with blue noise properties is needed. We compare our method to several other methods based on jittering as well as other methods for blue noise point set generation. Finally, we show several applications of curl noise jittering in two and three dimensions.",
        "countries": [
            "DK",
            "FR"
        ]
    },
    "10.1109/tvcg.2023.3338451": {
        "doi": "10.1109/tvcg.2023.3338451",
        "authors": [
            {
                "family": "Stokes",
                "given": "Chase",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Bearfield",
                "given": "Cindy Xiong",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Hearst",
                "given": "Marti A.",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "The Role of Text in Visualizations: How Annotations Shape Perceptions of Bias and Influence Predictions",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 3024,
        "volume": "",
        "number": "",
        "pages": "",
        "article_number": "",
        "number_of_pages": 12,
        "abstract": "This paper investigates the role of text in visualizations, specifically the impact of text position, semantic content, and biased wording. Two empirical studies were conducted based on two tasks (predicting data trends and appraising bias) using two visualization types (bar and line charts). While the addition of text had a minimal effect on how people perceive data trends, there was a significant impact on how biased they perceive the authors to be. This finding revealed a relationship between the degree of bias in textual information and the perception of the authors' bias. Exploratory analyses support an interaction between a person's prediction and the degree of bias they perceived. This paper also develops a crowdsourced method for creating chart annotations that range from neutral to highly biased. This research highlights the need for designers to mitigate potential polarization of readers' opinions based on how authors' ideas are expressed.",
        "countries": [
            "US"
        ]
    },
    "10.1109/tvcg.2024.3366343": {
        "doi": "10.1109/tvcg.2024.3366343",
        "authors": [
            {
                "family": "Xu",
                "given": "Rong-Kai",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhang",
                "given": "Lei",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhang",
                "given": "Fang-Lue",
                "countries": [
                    "NZ"
                ]
            }
        ],
        "title": "Intrinsic Omnidirectional Image Decomposition With Illumination Pre-Extraction",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "7",
        "pages": "4416\u20134428",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "Capturing an omnidirectional image with a 360-degree field of view entails capturing intricate spatial and lighting details of the scene. Consequently, existing intrinsic image decomposition methods face significant challenges when attempting to separate reflectance and shading components from a low dynamic range (LDR) omnidirectional images. To address this, our article introduces a novel method specifically designed for the intrinsic decomposition of omnidirectional images. Leveraging the unique characteristics of the 360-degree scene representation, we employ a pre-extraction technique to isolate specific illumination information. Subsequently, we establish new constraints based on these extracted details and the inherent characteristics of omnidirectional images. These constraints limit the illumination intensity range and incorporate spherical-based illumination variation. By formulating and solving an objective function that accounts for these constraints, our method achieves a more accurate separation of reflectance and shading components. Comprehensive qualitative and quantitative evaluations demonstrate the superiority of our proposed method over state-of-the-art intrinsic decomposition methods.",
        "countries": [
            "CN",
            "NZ"
        ]
    },
    "10.1109/tvcg.2023.3334755": {
        "doi": "10.1109/tvcg.2023.3334755",
        "authors": [
            {
                "family": "Pont",
                "given": "Mathieu",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Tierny",
                "given": "Julien",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Wasserstein Auto-Encoders of Merge Trees (and Persistence Diagrams)",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "9",
        "pages": "6390\u20136406",
        "article_number": "",
        "number_of_pages": 17,
        "abstract": "This article presents a computational framework for the Wasserstein auto-encoding of merge trees (MT-WAE), a novel extension of the classical auto-encoder neural network architecture to the Wasserstein metric space of merge trees. In contrast to traditional auto-encoders which operate on vectorized data, our formulation explicitly manipulates merge trees on their associated metric space at each layer of the network, resulting in superior accuracy and interpretability. Our novel neural network approach can be interpreted as a non-linear generalization of previous linear attempts (Pont et al. 2023) at merge tree encoding. It also trivially extends to persistence diagrams. Extensive experiments on public ensembles demonstrate the efficiency of our algorithms, with MT-WAE computations in the orders of minutes on average. We show the utility of our contributions in two applications adapted from previous work on merge tree encoding (Pont et al. 2023). First, we apply MT-WAE to merge tree compression, by concisely representing them with their coordinates in the final layer of our auto-encoder. Second, we document an application to dimensionality reduction, by exploiting the latent space of our auto-encoder, for the visual analysis of ensemble data. We illustrate the versatility of our framework by introducing two penalty terms, to help preserve in the latent space both the Wasserstein distances between merge trees, as well as their clusters. In both applications, quantitative experiments assess the relevance of our framework. Finally, we provide a C++ implementation that can be used for reproducibility.",
        "countries": [
            "FR"
        ]
    },
    "10.1145/3618386": {
        "doi": "10.1145/3618386",
        "authors": [
            {
                "family": "Jourdan",
                "given": "David",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Hugron",
                "given": "Pierre-Alexandre",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Schreck",
                "given": "Camille",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Mart\u00ednez",
                "given": "Jon\u00e0s",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Lefebvre",
                "given": "Sylvain",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Shrink &amp; Morph: 3D-Printed Self-Shaping Shells Actuated by a Shape Memory Effect",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2023,
        "volume": "42",
        "number": "6",
        "pages": "187:1\u2013187:13",
        "article_number": "187",
        "number_of_pages": 13,
        "abstract": "While 3D printing enables the customization and home fabrication of a wide range of shapes, fabricating freeform thin-shells remains challenging. As layers misalign with the curvature, they incur structural deficiencies, while the curved shells require large support structures, typically using more material than the part itself.We present a computational framework for optimizing the internal structure of 3D printed plates such that they morph into a desired freeform shell when heated. This exploits the shrinkage effect of thermoplastics such as PLA, which store internal stresses along the deposition directions. These stresses get released when the material is heated again above its glass transition temperature, causing an anisotropic deformation that induces curvature.Our inverse design method takes as input a freeform surface and finds an optimized set of deposition trajectories in each layer such that their anisotropic shrinkage deforms the plate into the prescribed surface geometry. We optimize for a continuous vector field that varies across the plate and within its thickness. The algorithm then extracts a set of deposition trajectories from the vector field in order to fabricate the flat plates on standard FFF printers. We validate our algorithm on freeform, doubly-curved surfaces.",
        "countries": [
            "FR"
        ]
    },
    "10.1145/3618366": {
        "doi": "10.1145/3618366",
        "authors": [
            {
                "family": "Becker",
                "given": "Quentin",
                "countries": [
                    "CH"
                ]
            },
            {
                "family": "Suzuki",
                "given": "Seiichi",
                "countries": [
                    "CH"
                ]
            },
            {
                "family": "Ren",
                "given": "Yingying",
                "countries": [
                    "CH"
                ]
            },
            {
                "family": "Pellis",
                "given": "Davide",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Panetta",
                "given": "Julian",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Pauly",
                "given": "Mark",
                "countries": [
                    "CH"
                ]
            }
        ],
        "title": "C-Shells: Deployable Gridshells with Curved Beams",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2023,
        "volume": "42",
        "number": "6",
        "pages": "173:1\u2013173:17",
        "article_number": "173",
        "number_of_pages": 17,
        "abstract": "We introduce a computational pipeline for simulating and designing C-shells, a new class of planar-to-spatial deployable linkage structures. A C-shell is composed of curved flexible beams connected at rotational joints that can be assembled in a stress-free planar configuration. When actuated, the elastic beams deform and the assembly deploys towards the target 3D shape.We propose two alternative computational design approaches for C-shells: (i) Forward exploration simulates the deployed shape from a planar beam layout provided by the user. Once a satisfactory overall shape is found, a subsequent design optimization adapts the beam geometry to reduce the elastic energy of the linkage while preserving the target shape. (ii) Inverse design is facilitated by a new geometric flattening method that takes a design surface as input and computes an initial layout of piecewise straight linkage beams. Our design optimization algorithm then calculates the smooth curved beams to best reproduce the target shape at minimal elastic energy.We find that C-shells offer a rich space for design and show several studies that highlight new shape topologies that cannot be achieved with existing deployable linkage structures.",
        "countries": [
            "CH",
            "IT",
            "US"
        ]
    },
    "10.1109/tvcg.2024.3355200": {
        "doi": "10.1109/tvcg.2024.3355200",
        "authors": [
            {
                "family": "Miandji",
                "given": "Ehsan",
                "countries": [
                    "SE"
                ]
            },
            {
                "family": "Tongbuasirilai",
                "given": "Tanaboon",
                "countries": [
                    "TH"
                ]
            },
            {
                "family": "Hajisharif",
                "given": "Saghi",
                "countries": [
                    "SE"
                ]
            },
            {
                "family": "Kavoosighafi",
                "given": "Behnaz",
                "countries": [
                    "SE"
                ]
            },
            {
                "family": "Unger",
                "given": "Jonas",
                "countries": [
                    "SE"
                ]
            }
        ],
        "title": "FROST-BRDF: A Fast and Robust Optimal Sampling Technique for BRDF Acquisition",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "7",
        "pages": "4390\u20134402",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "Efficient and accurate BRDF acquisition of real world materials is a challenging research problem that requires sampling millions of incident light and viewing directions. To accelerate the acquisition process, one needs to find a minimal set of sampling directions such that the recovery of the full BRDF is accurate and robust given such samples. In this article, we formulate BRDF acquisition as a compressed sensing problem, where the sensing operator is one that performs sub-sampling of the BRDF signal according to a set of optimal sample directions. To solve this problem, we propose the Fast and Robust Optimal Sampling Technique (FROST) for designing a provably optimal sub-sampling operator that places light-view samples such that the recovery error is minimized. FROST casts the problem of designing an optimal sub-sampling operator for compressed sensing into a sparse representation formulation under the Multiple Measurement Vector (MMV) signal model. The proposed reformulation is exact, i.e. without any approximations, hence it converts an intractable combinatorial problem into one that can be solved with standard optimization techniques. As a result, FROST is accompanied by strong theoretical guarantees from the field of compressed sensing. We perform a thorough analysis of FROST-BRDF using a 10-fold cross-validation with publicly available BRDF datasets and show significant advantages compared to the state-of-the-art with respect to reconstruction quality. Finally, FROST is simple, both conceptually and in terms of implementation, it produces consistent results at each run, and it is at least two orders of magnitude faster than the prior art.",
        "countries": [
            "SE",
            "TH"
        ]
    },
    "10.1145/3610548.3618215": {
        "doi": "10.1145/3610548.3618215",
        "authors": [
            {
                "family": "Xu",
                "given": "Yanrui",
                "countries": [
                    "CN",
                    "NL"
                ]
            },
            {
                "family": "Wang",
                "given": "Xiaokun",
                "countries": [
                    "CN",
                    "GB"
                ]
            },
            {
                "family": "Wang",
                "given": "Jiamin",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Song",
                "given": "Chongming",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wang",
                "given": "Tiancheng",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhang",
                "given": "Yalan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Chang",
                "given": "Jian",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Zhang",
                "given": "Jian Jun",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Kosinka",
                "given": "Jiri",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Telea",
                "given": "Alexandru",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Ban",
                "given": "Xiaojuan",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "An Implicitly Stable Mixture Model for Dynamic Multi-fluid Simulations",
        "journal": "ACM SIGGRAPH Asia Conference Papers",
        "publication_year": 2023,
        "volume": "0",
        "number": "0",
        "pages": "6:1\u20136:11",
        "article_number": "6",
        "number_of_pages": 11,
        "abstract": "Particle-based simulations have become increasingly popular in real-time applications due to their efficiency and adaptability, especially for generating highly dynamic fluid effects. However, the swift and stable simulation of interactions among distinct fluids continues to pose challenges for current mixture model techniques. When using a single-mixture flow field to represent all fluid phases, numerical discontinuities in phase fields can result in significant losses of dynamic effects and unstable conservation of mass and momentum. To tackle these issues, we present an advanced implicit mixture model for smoothed particle hydrodynamics. Instead of relying on an explicit mixture field for all dynamic computations and phase transfers between particles, our approach calculates phase momentum sources from the mixture model to derive explicit and continuous velocity phase fields. We then implicitly obtain the mixture field using a phase-mixture momentum-mapping mechanism that ensures conservation of incompressibility, mass, and momentum. In addition, we propose a mixture viscosity model and establish viscous effects between the mixture and individual fluid phases to avoid instability under extreme inertia conditions. Through a series of experiments, we show that, compared to existing mixture models, our method effectively improves dynamic effects while reducing critical instability factors. This makes our approach especially well-suited for long-duration, efficiency-oriented virtual reality scenarios.",
        "countries": [
            "CN",
            "NL",
            "GB"
        ]
    },
    "10.1016/j.cag.2024.103910": {
        "doi": "10.1016/j.cag.2024.103910",
        "authors": [
            {
                "family": "de Figueiredo",
                "given": "Luiz Henrique",
                "countries": [
                    "BR"
                ]
            }
        ],
        "title": "A vertex-centric representation for adaptive diamond-kite meshes",
        "journal": "Computers & Graphics",
        "publication_year": 2024,
        "volume": "119",
        "number": "",
        "pages": "103910:1\u2013103910:10",
        "number_of_pages": 10,
        "article_number": "103910",
        "abstract": "We describe a concise representation for adaptive diamond-kite meshes based solely on the vertices and their stars. The representation is exact because it uses only integers, is much smaller than standard topological data structures, and is highly compressible. All topological elements are reconstructed in expected constant time per element.",
        "countries": [
            "BR"
        ]
    },
    "10.1109/tvcg.2023.3326908": {
        "doi": "10.1109/tvcg.2023.3326908",
        "authors": [
            {
                "family": "Zhang",
                "given": "Yu",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Jiang",
                "given": "Ruike",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Xie",
                "given": "Liwenhan",
                "countries": [
                    "HK"
                ]
            },
            {
                "family": "Zhao",
                "given": "Yuheng",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Liu",
                "given": "Can",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Ding",
                "given": "Tianhong",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Chen",
                "given": "Siming",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Yuan",
                "given": "Xiaoru",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "OldVisOnline: Curating a Dataset of Historical Visualizations",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "1",
        "pages": "551\u2013561",
        "article_number": "",
        "number_of_pages": 11,
        "abstract": "With the increasing adoption of digitization, more and more historical visualizations created hundreds of years ago are accessible in digital libraries online. It provides a unique opportunity for visualization and history research. Meanwhile, there is no large-scale digital collection dedicated to historical visualizations. The visualizations are scattered in various collections, which hinders retrieval. In this study, we curate the first large-scale dataset dedicated to historical visualizations. Our dataset comprises 13K historical visualization images with corresponding processed metadata from seven digital libraries. In curating the dataset, we propose a workflow to scrape and process heterogeneous metadata. We develop a semi-automatic labeling approach to distinguish visualizations from other artifacts. Our dataset can be accessed with OldVisOnline, a system we have built to browse and label historical visualizations. We discuss our vision of usage scenarios and research opportunities with our dataset, such as textual criticism for historical visualizations. Drawing upon our experience, we summarize recommendations for future efforts to improve our dataset.",
        "countries": [
            "GB",
            "CN",
            "HK"
        ]
    },
    "10.1111/cgf.15000": {
        "doi": "10.1111/cgf.15000",
        "authors": [
            {
                "family": "Erler",
                "given": "Philipp",
                "orcid": "0000-0002-2790-9279",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Fuentes-Perez",
                "given": "Lizeth",
                "orcid": "0000-0003-1096-2871",
                "countries": [
                    "CH"
                ]
            },
            {
                "family": "Hermosilla",
                "given": "Pedro",
                "orcid": "0000-0003-3586-4741",
                "countries": [
                    "AT"
                ]
            },
            {
                "family": "Guerrero",
                "given": "Paul",
                "orcid": "0000-0002-7568-2849",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Pajarola",
                "given": "Renato",
                "orcid": "0000-0002-6724-526X",
                "countries": [
                    "CH"
                ]
            },
            {
                "family": "Wimmer",
                "given": "Michael",
                "orcid": "0000-0002-9370-2663",
                "countries": [
                    "AT"
                ]
            }
        ],
        "title": "<scp>PPSurf</scp>: Combining Patches and Point Convolutions for Detailed Surface Reconstruction",
        "journal": "Computer Graphics Forum",
        "publication_year": 2024,
        "volume": "43",
        "number": "1",
        "pages": "e15000:1\u2013e15000:12",
        "article_number": "e15000",
        "number_of_pages": 12,
        "abstract": "3D surface reconstruction from point clouds is a key step in areas such as content creation, archaeology, digital cultural heritage and engineering. Current approaches either try to optimize a non-data-driven surface representation to fit the points, or learn a data-driven prior over the distribution of commonly occurring surfaces and how they correlate with potentially noisy point clouds. Data-driven methods enable robust handling of noise and typically either focus on a global or a local prior, which trade-off between robustness to noise on the global end and surface detail preservation on the local end. We propose PPSurf as a method that combines a global prior based on point convolutions and a local prior based on processing local point cloud patches. We show that this approach is robust to noise while recovering surface details more accurately than the current state-of-the-art. Our source code, pre-trained model and dataset are available at <jats:ext-link xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"https://github.com/cg-tuwien/ppsurf\">https://github.com/cg-tuwien/ppsurf</jats:ext-link>.",
        "countries": [
            "AT",
            "CH",
            "GB"
        ]
    },
    "10.1145/3618318": {
        "doi": "10.1145/3618318",
        "authors": [
            {
                "family": "Li",
                "given": "Zhehao",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Xu",
                "given": "Qingyu",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Ye",
                "given": "Xiaohan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Ren",
                "given": "Bo",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Liu",
                "given": "Ligang",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "DiffFR: Differentiable SPH-Based Fluid-Rigid Coupling for Rigid Body Control",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2023,
        "volume": "42",
        "number": "6",
        "pages": "179:1\u2013179:17",
        "article_number": "179",
        "number_of_pages": 17,
        "abstract": "Differentiable physics simulation has shown its efficacy in inverse design problems. Given the pervasiveness of the diverse interactions between fluids and solids in life, a differentiable simulator for the inverse design of the motion of rigid objects in two-way fluid-rigid coupling is also demanded. There are two main challenges to develop a differentiable two-way fluid-solid coupling simulator for rigid body control tasks: the ubiquitous, discontinuous contacts in fluid-solid interactions, and the high computational cost of gradient formulation due to the large number of degrees of freedom (DoF) of fluid dynamics. In this work, we propose a novel differentiable SPH-based two-way fluid-rigid coupling simulator to address these challenges. Our purpose is to provide a differentiable simulator for SPH which incorporates a unified representation for both fluids and solids using particles. However, naively differentiating the forward simulation of the particle system encounters gradient explosion issues. We investigate the instability in differentiating the SPH-based fluid-rigid coupling simulator and present a feasible gradient computation scheme to address its differentiability. In addition, we also propose an efficient method to compute the gradient of fluid-rigid coupling without incurring the high computational cost of differentiating the entire high-DoF fluid system. We show the efficacy, scalability, and extensibility of our method in various challenging rigid body control tasks with diverse fluid-rigid interactions and multi-rigid contacts, achieving up to an order of magnitude speedup in optimization compared to baseline methods in experiments.",
        "countries": [
            "CN"
        ]
    },
    "10.1145/3618335": {
        "doi": "10.1145/3618335",
        "authors": [
            {
                "family": "Kim",
                "given": "Juhyeon",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Jarosz",
                "given": "Wojciech",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Gkioulekas",
                "given": "Ioannis",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Pediredla",
                "given": "Adithya",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Doppler Time-of-Flight Rendering",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2023,
        "volume": "42",
        "number": "6",
        "pages": "271:1\u2013271:18",
        "article_number": "271",
        "number_of_pages": 18,
        "abstract": "We introduce Doppler time-of-flight (D-ToF) rendering, an extension of ToF rendering for dynamic scenes, with applications in simulating D-ToF cameras. D-ToF cameras use high-frequency modulation of illumination and exposure, and measure the Doppler frequency shift to compute the radial velocity of dynamic objects. The time-varying scene geometry and high-frequency modulation functions used in such cameras make it challenging to accurately and efficiently simulate their measurements with existing ToF rendering algorithms. We overcome these challenges in a twofold manner: To achieve accuracy, we derive path integral expressions for D-ToF measurements under global illumination and form unbiased Monte Carlo estimates of these integrals. To achieve efficiency, we develop a tailored time-path sampling technique that combines antithetic time sampling with correlated path sampling. We show experimentally that our sampling technique achieves up to two orders of magnitude lower variance compared to naive time-path sampling. We provide an open-source simulator that serves as a digital twin for D-ToF imaging systems, allowing imaging researchers, for the first time, to investigate the impact of modulation functions, material properties, and global illumination on D-ToF imaging performance.",
        "countries": [
            "US"
        ]
    },
    "10.1145/3618352": {
        "doi": "10.1145/3618352",
        "authors": [
            {
                "family": "Diazzi",
                "given": "Lorenzo",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Panozzo",
                "given": "Daniele",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Vaxman",
                "given": "Amir",
                "countries": [
                    "GB"
                ]
            },
            {
                "family": "Attene",
                "given": "Marco",
                "countries": [
                    "IT"
                ]
            }
        ],
        "title": "Constrained Delaunay Tetrahedrization: A Robust and Practical Approach",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2023,
        "volume": "42",
        "number": "6",
        "pages": "181:1\u2013181:15",
        "article_number": "181",
        "number_of_pages": 15,
        "abstract": "We present a numerically robust algorithm for computing the constrained Delaunay tetrahedrization (CDT) of a piecewise-linear complex, which has a 100% success rate on the 4408 valid models in the Thingi10k dataset.We build on the underlying theory of the well-known tetgen software, but use a floating-point implementation based on indirect geometric predicates to implicitly represent Steiner points: this new approach dramatically simplifies the implementation, removing the need for ad-hoc tolerances in geometric operations. Our approach leads to a robust and parameter-free implementation, with an empirically manageable number of added Steiner points. Furthermore, our algorithm addresses a major gap in tetgen's theory which may lead to algorithmic failure on valid models, even when assuming perfect precision in the calculations.Our output tetrahedrization conforms with the input geometry without approximations. We can further round our output to floating-point coordinates for downstream applications, which almost always results in valid floating-point meshes unless the input triangulation is very close to being degenerate.",
        "countries": [
            "IT",
            "US",
            "GB"
        ]
    },
    "10.1016/j.cag.2024.103915": {
        "doi": "10.1016/j.cag.2024.103915",
        "authors": [
            {
                "family": "Xie",
                "given": "Yizhou",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Xie",
                "given": "Xiangning",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wang",
                "given": "Yuran",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhang",
                "given": "Yanci",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Lv",
                "given": "Zejun",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Terrain point cloud inpainting via signal decomposition",
        "journal": "Computers & Graphics",
        "publication_year": 2024,
        "volume": "120",
        "number": "",
        "pages": "103915",
        "number_of_pages": 10,
        "article_number": "103915",
        "abstract": "The rapid development of 3D acquisition technology has made it possible to obtain point clouds of real-world terrains. However, due to limitations in sensor acquisition technology or specific requirements, point clouds often contain defects such as holes with missing data. Inpainting algorithms are widely used to patch these holes. However, existing traditional inpainting algorithms rely on precise hole boundaries, which limits their ability to handle cases where the boundaries are not well-defined. On the other hand, learning-based completion methods often prioritize reconstructing the entire point cloud instead of solely focusing on hole filling. Based on the fact that real-world terrain exhibits both global smoothness and rich local detail, we propose a novel representation for terrain point clouds. This representation can help to repair the holes without clear boundaries. Specifically, it decomposes terrains into low-frequency and high-frequency components, which are represented by B-spline surfaces and relative height maps respectively. In this way, the terrain point cloud inpainting problem is transformed into a B-spline surface fitting and 2D image inpainting problem. By solving the two problems, the highly complex and irregular holes on the terrain point clouds can be well-filled, which not only satisfies the global terrain undulation but also exhibits rich geometric details. The experimental results also demonstrate the effectiveness of our method.",
        "countries": [
            "CN"
        ]
    },
    "10.1145/3610548.3618243": {
        "doi": "10.1145/3610548.3618243",
        "authors": [
            {
                "family": "Doignies",
                "given": "Bastien",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Bonneel",
                "given": "Nicolas",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Coeurjolly",
                "given": "David",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Digne",
                "given": "Julie",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Paulin",
                "given": "Lo\u00efs",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Iehl",
                "given": "Jean-Claude",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Ostromoukhov",
                "given": "Victor",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Example-Based Sampling with Diffusion Models",
        "journal": "ACM SIGGRAPH Asia Conference Papers",
        "publication_year": 2023,
        "volume": "0",
        "number": "0",
        "pages": "63:1\u201363:11",
        "article_number": "63",
        "number_of_pages": 11,
        "abstract": "Much effort has been put into developing samplers with specific properties, such as producing blue noise, low-discrepancy, lattice or Poisson disk samples. These samplers can be slow if they rely on optimization processes, may rely on a wide range of numerical methods, are not always differentiable. The success of recent diffusion models for image generation suggests that these models could be appropriate for learning how to generate point sets from examples. However, their convolutional nature makes these methods impractical for dealing with scattered data such as point sets. We propose a generic way to produce 2-d point sets imitating existing samplers from observed point sets using a diffusion model. We address the problem of convolutional layers by leveraging neighborhood information from an optimal transport matching to a uniform grid, that allows us to benefit from fast convolutions on grids, and to support the example-based learning of non-uniform sampling patterns. We demonstrate how the differentiability of our approach can be used to optimize point sets to enforce properties.",
        "countries": [
            "FR"
        ]
    },
    "10.1145/3618363": {
        "doi": "10.1145/3618363",
        "authors": [
            {
                "family": "Tang",
                "given": "Yijie",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhang",
                "given": "Jiazhao",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Yu",
                "given": "Zhinan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wang",
                "given": "He",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Xu",
                "given": "Kai",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "MIPS-Fusion: Multi-Implicit-Submaps for Scalable and Robust Online Neural RGB-D Reconstruction",
        "journal": "ACM Transactions on Graphics",
        "publication_year": 2023,
        "volume": "42",
        "number": "6",
        "pages": "246:1\u2013246:16",
        "article_number": "246",
        "number_of_pages": 16,
        "abstract": "We introduce MIPS-Fusion, a robust and scalable online RGB-D reconstruction method based on a novel neural implicit representation - multi-implicit-submap. Different from existing neural RGB-D reconstruction methods lacking either flexibility with a single neural map or scalability due to extra storage of feature grids, we propose a pure neural representation tackling both difficulties with a divide-and-conquer design. In our method, neural submaps are incrementally allocated alongside the scanning trajectory and efficiently learned with local neural bundle adjustments. The submaps can be refined individually in a back-end optimization and optimized jointly to realize submap-level loop closure. Meanwhile, we propose a hybrid tracking approach combining randomized and gradient-based pose optimizations. For the first time, randomized optimization is made possible in neural tracking with several key designs to the learning process, enabling efficient and robust tracking even under fast camera motions. The extensive evaluation demonstrates that our method attains higher reconstruction quality than the state of the arts for large-scale scenes and under fast camera motions.",
        "countries": [
            "CN"
        ]
    },
    "10.1145/3610548.3618135": {
        "doi": "10.1145/3610548.3618135",
        "authors": [
            {
                "family": "Kavakl\u0131",
                "given": "Koray",
                "countries": [
                    "TR"
                ]
            },
            {
                "family": "Shi",
                "given": "Liang",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "\u00dcrey",
                "given": "Hakan",
                "countries": [
                    "TR"
                ]
            },
            {
                "family": "Matusik",
                "given": "Wojciech",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Ak\u015fit",
                "given": "Kaan",
                "countries": [
                    "GB"
                ]
            }
        ],
        "title": "Multi-color Holograms Improve Brightness in Holographic Displays",
        "journal": "ACM SIGGRAPH Asia Conference Papers",
        "publication_year": 2023,
        "volume": "0",
        "number": "0",
        "pages": "20:1\u201320:11",
        "article_number": "20",
        "number_of_pages": 11,
        "abstract": "Holographic displays generate Three-Dimensional (3D) images by displaying single-color holograms time-sequentially, each lit by a single-color light source. However, representing each color one by one limits brightness in holographic displays. This paper introduces a new driving scheme for realizing brighter images in holographic displays. Unlike the conventional driving scheme, our method utilizes three light sources to illuminate each displayed hologram simultaneously at various intensity levels. In this way, our method reconstructs a multiplanar three-dimensional target scene using consecutive multi-color holograms and persistence of vision. We co-optimize multi-color holograms and required intensity levels from each light source using a gradient descent-based optimizer with a combination of application-specific loss terms. We experimentally demonstrate that our method can increase the intensity levels in holographic displays up to three times, reaching a broader range and unlocking new potentials for perceptual realism in holographic displays.",
        "countries": [
            "TR",
            "US",
            "GB"
        ]
    },
    "10.1109/tvcg.2024.3364841": {
        "doi": "10.1109/tvcg.2024.3364841",
        "authors": [
            {
                "family": "Skrodzki",
                "given": "Martin",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Geffen",
                "given": "Hunter van",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Chaves-de-Plaza",
                "given": "Nicolas F.",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "H\u00f6llt",
                "given": "Thomas",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Eisemann",
                "given": "Elmar",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Hildebrandt",
                "given": "Klaus",
                "countries": [
                    "NL"
                ]
            }
        ],
        "title": "Accelerating Hyperbolic t-SNE",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "7",
        "pages": "4403\u20134415",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "The need to understand the structure of hierarchical or high-dimensional data is present in a variety of fields. Hyperbolic spaces have proven to be an important tool for embedding computations and analysis tasks as their non-linear nature lends itself well to tree or graph data. Subsequently, they have also been used in the visualization of high-dimensional data, where they exhibit increased embedding performance. However, none of the existing dimensionality reduction methods for embedding into hyperbolic spaces scale well with the size of the input data. That is because the embeddings are computed via iterative optimization schemes and the computation cost of every iteration is quadratic in the size of the input. Furthermore, due to the non-linear nature of hyperbolic spaces, euclidean acceleration structures cannot directly be translated to the hyperbolic setting. This article introduces the first acceleration structure for hyperbolic embeddings, building upon a polar quadtree. We compare our approach with existing methods and demonstrate that it computes embeddings of similar quality in significantly less time. Implementation and scripts for the experiments can be found at https://graphics.tudelft.nl/accelerating-hyperbolic-tsne.",
        "countries": [
            "NL"
        ]
    },
    "10.1145/3610548.3618229": {
        "doi": "10.1145/3610548.3618229",
        "authors": [
            {
                "family": "Romero",
                "given": "Cristian",
                "countries": [
                    "ES"
                ]
            },
            {
                "family": "Casas",
                "given": "Dan",
                "countries": [
                    "ES"
                ]
            },
            {
                "family": "Chiaramonte",
                "given": "Maurizio",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Otaduy",
                "given": "Miguel A.",
                "countries": [
                    "ES"
                ]
            }
        ],
        "title": "Learning Contact Deformations with General Collider Descriptors",
        "journal": "ACM SIGGRAPH Asia Conference Papers",
        "publication_year": 2023,
        "volume": "0",
        "number": "0",
        "pages": "77:1\u201377:10",
        "article_number": "77",
        "number_of_pages": 10,
        "abstract": "This paper presents a learning-based method for the simulation of rich contact deformations on reduced deformation models. Previous works learn deformation models for specific pairs of objects; we lift this limitation by designing a neural model that supports general rigid collider shapes. We do this by formulating a novel collider descriptor that characterizes local geometry in a region of interest. The paper shows that the learning-based deformation model can be trained on a library of colliders, but it accurately supports unseen collider shapes at runtime. We showcase our method on interactive dynamic simulations with animation of rich deformation detail, manipulation and exploration of untrained objects, and augmentation of contact information suitable for high-fidelity haptics.",
        "countries": [
            "ES",
            "US"
        ]
    },
    "10.1145/3610548.3618178": {
        "doi": "10.1145/3610548.3618178",
        "authors": [
            {
                "family": "Careaga",
                "given": "Chris",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Miangoleh",
                "given": "S. Mahdi H.",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Aksoy",
                "given": "Ya\u011f\u0131z",
                "countries": [
                    "CA"
                ]
            }
        ],
        "title": "Intrinsic Harmonization for Illumination-Aware Image Compositing",
        "journal": "ACM SIGGRAPH Asia Conference Papers",
        "publication_year": 2023,
        "volume": "0",
        "number": "0",
        "pages": "100:1\u2013100:10",
        "article_number": "100",
        "number_of_pages": 10,
        "abstract": "Despite significant advancements in network-based image harmonization techniques, there still exists a domain disparity between typical training pairs and real-world composites encountered during inference. Most existing methods are trained to reverse global edits made on segmented image regions, which fail to accurately capture the lighting inconsistencies between the foreground and background found in composited images. In this work, we introduce a self-supervised illumination harmonization approach formulated in the intrinsic image domain. First, we estimate a simple global lighting model from mid-level vision representations to generate a rough shading for the foreground region. A network then refines this inferred shading to generate a harmonious re-shading that aligns with the background scene. In order to match the color appearance of the foreground and background, we utilize ideas from prior harmonization approaches to perform parameterized image edits in the albedo domain. To validate the effectiveness of our approach, we present results from challenging real-world composites and conduct a user study to objectively measure the enhanced realism achieved compared to state-of-the-art harmonization methods.",
        "countries": [
            "CA"
        ]
    },
    "10.1016/j.cag.2024.103901": {
        "doi": "10.1016/j.cag.2024.103901",
        "authors": [
            {
                "family": "Prasse",
                "given": "Paul",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Reich",
                "given": "David R.",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Makowski",
                "given": "Silvia",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Scheffer",
                "given": "Tobias",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "J\u00e4ger",
                "given": "Lena A.",
                "countries": [
                    "DE",
                    "CH"
                ]
            }
        ],
        "title": "Improving cognitive-state analysis from eye gaze with synthetic eye-movement data",
        "journal": "Computers & Graphics",
        "publication_year": 2024,
        "volume": "119",
        "number": "",
        "pages": "103901",
        "number_of_pages": 11,
        "article_number": "103901",
        "abstract": "Eye movements can be used to analyze a viewer\u2019s cognitive capacities or mental state. Neural networks that process the raw eye-tracking signal can outperform methods that operate on scan paths preprocessed into fixations and saccades. However, the scarcity of such data poses a major challenge. We therefore develop SP-EyeGAN, a neural network that generates synthetic raw eye-tracking data. SP-EyeGAN consists of Generative Adversarial Networks; it produces a sequence of gaze angles indistinguishable from human ocular micro- and macro-movements. We explore the use of these synthetic eye movements for pre-training neural networks using contrastive learning. We find that pre-training on synthetic data does not help for biometric identification, while results are inconclusive for the detection of ADHD and gender classification. However, for the eye movement-based assessment of higher-level cognitive skills such general reading comprehension, text comprehension, and the distinction of native from non-native readers, pre-training on synthetic eye-gaze data improves the models\u2019 performance and even advances the state-of-the-art for reading comprehension. The SP-EyeGAN model, pre-trained on GazeBase, along with the code for developing your own raw eye-tracking machine learning model with contrastive learning, is available at https://github.com/aeye-lab/sp-eyegan.",
        "countries": [
            "DE",
            "CH"
        ]
    },
    "10.1109/tvcg.2024.3388521": {
        "doi": "10.1109/tvcg.2024.3388521",
        "authors": [
            {
                "family": "Chen",
                "given": "Changjian",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Chen",
                "given": "Jiashu",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Yang",
                "given": "Weikai",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wang",
                "given": "Haoze",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Knittel",
                "given": "Johannes",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Zhao",
                "given": "Xibin",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Koch",
                "given": "Steffen",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Ertl",
                "given": "Thomas",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Liu",
                "given": "Shixia",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Enhancing Single-Frame Supervision for Better Temporal Action Localization",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "6",
        "pages": "2903\u20132915",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "Temporal action localization aims to identify the boundaries and categories of actions in videos, such as scoring a goal in a football match. Single-frame supervision has emerged as a labor-efficient way to train action localizers as it requires only one annotated frame per action. However, it often suffers from poor performance due to the lack of precise boundary annotations. To address this issue, we propose a visual analysis method that aligns similar actions and then propagates a few user-provided annotations (e.g., boundaries, category labels) to similar actions via the generated alignments. Our method models the alignment between actions as a heaviest path problem and the annotation propagation as a quadratic optimization problem. As the automatically generated alignments may not accurately match the associated actions and could produce inaccurate localization results, we develop a storyline visualization to explain the localization results of actions and their alignments. This visualization facilitates users in correcting wrong localization results and misalignments. The corrections are then used to improve the localization results of other actions. The effectiveness of our method in improving localization performance is demonstrated through quantitative evaluation and a case study.",
        "countries": [
            "CN",
            "DE"
        ]
    },
    "10.1016/j.cag.2024.103943": {
        "doi": "10.1016/j.cag.2024.103943",
        "authors": [
            {
                "family": "H\u00e1cha",
                "given": "Filip",
                "countries": [
                    "CZ"
                ]
            },
            {
                "family": "Dvo\u0159\u00e1k",
                "given": "Jan",
                "countries": [
                    "CZ"
                ]
            },
            {
                "family": "K\u00e1\u010derekov\u00e1",
                "given": "Zuzana",
                "countries": [
                    "CZ"
                ]
            },
            {
                "family": "V\u00e1\u0161a",
                "given": "Libor",
                "countries": [
                    "CZ"
                ]
            }
        ],
        "title": "Editing mesh sequences with varying connectivity",
        "journal": "Computers & Graphics",
        "publication_year": 2024,
        "volume": "121",
        "number": "",
        "pages": "103943",
        "number_of_pages": 13,
        "article_number": "103943",
        "abstract": "Time-varying connectivity of triangle mesh sequences leads to substantial difficulties in their processing. Unlike editing sequences with constant connectivity, editing sequences with varying connectivity requires addressing the problem of temporal correspondence between the frames of the sequence. We present a method for time-consistent editing of triangle mesh sequences with varying connectivity using sparse temporal correspondence, which can be obtained using existing methods. Our method includes a deformation model based on the usage of the sparse temporal correspondence, which is suitable for the temporal propagation of user-specified deformations of the edited surface with respect to the shape and true topology of the surface while preserving the individual connectivity of each frame. Since there is no other method capable of comparable types of editing on time-varying meshes, we compare our method and the proposed deformation model with a baseline approach and demonstrate the benefits of our framework.",
        "countries": [
            "CZ"
        ]
    },
    "10.1145/3610548.3618176": {
        "doi": "10.1145/3610548.3618176",
        "authors": [
            {
                "family": "Cheema",
                "given": "Noshaba",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Xu",
                "given": "Rui",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Kim",
                "given": "Nam Hee",
                "countries": [
                    "FI"
                ]
            },
            {
                "family": "H\u00e4m\u00e4l\u00e4inen",
                "given": "Perttu",
                "countries": [
                    "FI"
                ]
            },
            {
                "family": "Golyanik",
                "given": "Vladislav",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Habermann",
                "given": "Marc",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Theobalt",
                "given": "Christian",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Slusallek",
                "given": "Philipp",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Discovering Fatigued Movements for Virtual Character Animation",
        "journal": "ACM SIGGRAPH Asia Conference Papers",
        "publication_year": 2023,
        "volume": "0",
        "number": "0",
        "pages": "47:1\u201347:12",
        "article_number": "47",
        "number_of_pages": 12,
        "abstract": "Virtual character animation and movement synthesis have advanced rapidly during recent years, especially through a combination of extensive motion capture datasets and machine learning. A remaining challenge is interactively simulating characters that fatigue when performing extended motions, which is indispensable for the realism of generated animations. However, capturing such movements is problematic, as performing movements like backflips with fatigued variations up to exhaustion raises capture cost and risk of injury. Surprisingly, little research has been done on faithful fatigue modeling. To address this, we propose a deep reinforcement learning-based approach, which\u2014for the first time in literature\u2014generates control policies for full-body physically simulated agents aware of cumulative fatigue. For this, we first leverage Generative Adversarial Imitation Learning (GAIL) to learn an expert policy for the skill; Second, we learn a fatigue policy by limiting the generated constant torque bounds based on endurance time to non-linear, state- and time-dependent limits in the joint-actuation space using a Three-Compartment Controller (3CC) model. Our results demonstrate that agents can adapt to different fatigue and rest rates interactively, and discover realistic recovery strategies without the need for any captured data of fatigued movement.",
        "countries": [
            "DE",
            "FI"
        ]
    },
    "10.1109/tvcg.2024.3405369": {
        "doi": "10.1109/tvcg.2024.3405369",
        "authors": [
            {
                "family": "Finke",
                "given": "Lennart",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Weitz",
                "given": "Edmund",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "A Phenomenological Approach to Interactive Knot Diagrams",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "8",
        "pages": "5901\u20135907",
        "article_number": "",
        "number_of_pages": 7,
        "abstract": "Knot diagrams are among the most common visual tools in topology. Computer programs now make it possible to draw, manipulate and render them digitally, which proves to be useful in knot theory teaching and research. Still, an openly available tool to manipulate knot diagrams in a real-time, interactive way is yet to be developed. We introduce a method of operating on the geometry of the knot diagram itself without any underlying three-dimensional structure that can underpin such an application. This allows us to directly interact with vector graphics knot diagrams while at the same time computing knot invariants in ways proposed by previous work. An implementation of this method is provided.",
        "countries": [
            "DE"
        ]
    },
    "10.1109/tvcg.2024.3390219": {
        "doi": "10.1109/tvcg.2024.3390219",
        "authors": [
            {
                "family": "Guillou",
                "given": "Eve Le",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Will",
                "given": "Michael",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Guillou",
                "given": "Pierre",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Lukasczyk",
                "given": "Jonas",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Fortin",
                "given": "Pierre",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Garth",
                "given": "Christoph",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Tierny",
                "given": "Julien",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "TTK is Getting MPI-Ready",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "8",
        "pages": "5875\u20135892",
        "article_number": "",
        "number_of_pages": 18,
        "abstract": "This system paper documents the technical foundations for the extension of the Topology ToolKit (TTK) to distributed-memory parallelism with the Message Passing Interface (MPI). While several recent papers introduced topology-based approaches for distributed-memory environments, these were reporting experiments obtained with tailored, mono-algorithm implementations. In contrast, we describe in this paper a versatile approach (supporting both triangulated domains and regular grids) for the support of topological analysis pipelines, i.e., a sequence of topological algorithms interacting together, possibly on distinct numbers of processes. While developing this extension, we faced several algorithmic and software engineering challenges, which we document in this paper. Specifically, we describe an MPI extension of TTK\u2019s data structure for triangulation representation and traversal, a central component to the global performance and generality of TTK\u2019s topological implementations. We also introduce an intermediate interface between TTK and MPI, both at the global pipeline level, and at the fine-grain algorithmic level. We provide a taxonomy for the distributed-memory topological algorithms supported by TTK, depending on their communication needs and provide examples of hybrid MPI+thread parallelizations. Detailed performance analyses show that parallel efficiencies range from 20% to 80% (depending on the algorithms), and that the MPI-specific preconditioning introduced by our framework induces a negligible computation time overhead. We illustrate the new distributed-memory capabilities of TTK with an example of advanced analysis pipeline, combining multiple algorithms, run on the largest publicly available dataset we have found (120 billion vertices) on a standard cluster with 64 nodes (for a total of 1536 cores). Finally, we provide a roadmap for the completion of TTK\u2019s MPI extension, along with generic recommendations for each algorithm communication category.",
        "countries": [
            "FR",
            "DE"
        ]
    },
    "10.1109/tvcg.2023.3237768": {
        "doi": "10.1109/tvcg.2023.3237768",
        "authors": [
            {
                "family": "Sharma",
                "given": "Mohit",
                "countries": [
                    "IN"
                ]
            },
            {
                "family": "Masood",
                "given": "Talha Bin",
                "countries": [
                    "SE"
                ]
            },
            {
                "family": "Thygesen",
                "given": "Signe Sidwall",
                "countries": [
                    "SE"
                ]
            },
            {
                "family": "Linares",
                "given": "Mathieu",
                "countries": [
                    "SE"
                ]
            },
            {
                "family": "Hotz",
                "given": "Ingrid",
                "countries": [
                    "SE",
                    "IN"
                ]
            },
            {
                "family": "Natarajan",
                "given": "Vijay",
                "countries": [
                    "IN"
                ]
            }
        ],
        "title": "Continuous Scatterplot Operators for Bivariate Analysis and Study of Electronic Transitions",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "7",
        "pages": "3532\u20133544",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "Electronic transitions in molecules due to the absorption or emission of light is a complex quantum mechanical process. Their study plays an important role in the design of novel materials. A common yet challenging task in the study is to determine the nature of electronic transitions, namely which subgroups of the molecule are involved in the transition by donating or accepting electrons, followed by an investigation of the variation in the donor-acceptor behavior for different transitions or conformations of the molecules. In this article, we present a novel approach for the analysis of a bivariate field and show its applicability to the study of electronic transitions. This approach is based on two novel operators, the continuous scatterplot (CSP) lens operator and the CSP peel operator, that enable effective visual analysis of bivariate fields. Both operators can be applied independently or together to facilitate analysis. The operators motivate the design of control polygon inputs to extract fiber surfaces of interest in the spatial domain. The CSPs are annotated with a quantitative measure to further support the visual analysis. We study different molecular systems and demonstrate how the CSP peel and CSP lens operators help identify and study donor and acceptor characteristics in molecular systems.",
        "countries": [
            "SE",
            "IN"
        ]
    },
    "10.1111/cgf.15020": {
        "doi": "10.1111/cgf.15020",
        "authors": [
            {
                "family": "Genest",
                "given": "Baptiste",
                "orcid": "0009-0009-7718-5553",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Courty",
                "given": "Nicolas",
                "orcid": "0000-0003-1353-0126",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Coeurjolly",
                "given": "David",
                "orcid": "0000-0003-3164-8697",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Non\u2010Euclidean Sliced Optimal Transport Sampling",
        "journal": "Computer Graphics Forum",
        "publication_year": 2024,
        "volume": "43",
        "number": "2",
        "pages": "e15020",
        "article_number": "e15020",
        "number_of_pages": 14,
        "abstract": "In machine learning and computer graphics, a fundamental task is the approximation of a probability density function through a well-dispersed collection of samples. Providing a formal metric for measuring the distance between probability measures on general spaces, Optimal Transport (OT) emerges as a pivotal theoretical framework within this context. However, the associated computational burden is prohibitive in most real-world scenarios. Leveraging the simple structure of OT in 1D, Sliced Optimal Transport (SOT) has appeared as an efficient alternative to generate samples in Euclidean spaces. This paper pushes the boundaries of SOT utilization in computational geometry problems by extending its application to sample densities residing on more diverse mathematical domains, including the spherical space \ud835\udd4ad, the hyperbolic plane \u210dd, and the real projective plane \u2119d. Moreover, it ensures the quality of these samples by achieving a blue noise characteristic, regardless of the dimensionality involved. The robustness of our approach is highlighted through its application to various geometry processing tasks, such as the intrinsic blue noise sampling of meshes, as well as the sampling of directions and rotations. These applications collectively underscore the efficacy of our methodology.",
        "countries": [
            "FR"
        ]
    },
    "10.1109/tvcg.2024.3385637": {
        "doi": "10.1109/tvcg.2024.3385637",
        "authors": [
            {
                "family": "Ferrarotti",
                "given": "Anna",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Baldoni",
                "given": "Sara",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Carli",
                "given": "Marco",
                "countries": [
                    "IT"
                ]
            },
            {
                "family": "Battisti",
                "given": "Federica",
                "countries": [
                    "IT"
                ]
            }
        ],
        "title": "Stress Assessment for Augmented Reality Applications Based on Head Movement Features",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 3024,
        "volume": "",
        "number": "",
        "pages": "",
        "article_number": "",
        "number_of_pages": 14,
        "abstract": "Augmented reality is one of the enabling technologies of the upcoming future. Its usage in working and learning scenarios may lead to a better quality of work and training by helping the operators during the most crucial stages of processes. Therefore, the automatic detection of stress during augmented reality experiences can be a valuable support to prevent consequences on people's health and foster the spreading of this technology. In this work, we present the design of a non-invasive stress assessment approach. The proposed system is based on the analysis of the head movements of people wearing a Head Mounted Display while performing stress-inducing tasks. First, we designed a subjective experiment consisting of two stress-related tests for data acquisition. Then, a statistical analysis of head movements has been performed to determine which features are representative of the presence of stress. Finally, a stress classifier based on a combination of Support Vector Machines has been designed and trained. The proposed approach achieved promising performances thus paving the way for further studies in this research direction.",
        "countries": [
            "IT"
        ]
    },
    "10.1109/tvcg.2024.3388516": {
        "doi": "10.1109/tvcg.2024.3388516",
        "authors": [
            {
                "family": "Hong",
                "given": "Jiayi",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Hnatyshyn",
                "given": "Rostyslav",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Santos",
                "given": "Ebrar A. D.",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Maciejewski",
                "given": "Ross",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Isenberg",
                "given": "Tobias",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "A Survey of Designs for Combined 2D+3D Visual Representations",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 2024,
        "volume": "30",
        "number": "6",
        "pages": "2888\u20132902",
        "article_number": "",
        "number_of_pages": 15,
        "abstract": "We examine visual representations of data that make use of combinations of both 2D and 3D data mappings. Combining 2D and 3D representations is a common technique that allows viewers to understand multiple facets of the data with which they are interacting. While 3D representations focus on the spatial character of the data or the dedicated 3D data mapping, 2D representations often show abstract data properties and take advantage of the unique benefits of mapping to a plane. Many systems have used unique combinations of both types of data mappings effectively. Yet there are no systematic reviews of the methods in linking 2D and 3D representations. We systematically survey the relationships between 2D and 3D visual representations in major visualization publications\u2014IEEE VIS, IEEE TVCG, and EuroVis\u2014from 2012 to 2022. We closely examined 105 articles where 2D and 3D representations are connected visually, interactively, or through animation. These approaches are designed based on their visual environment, the relationships between their visual representations, and their possible layouts. Through our analysis, we introduce a design space as well as provide design guidelines for effectively linking 2D and 3D visual representations.",
        "countries": [
            "US",
            "FR"
        ]
    },
    "10.1109/tvcg.2024.3393236": {
        "doi": "10.1109/tvcg.2024.3393236",
        "authors": [
            {
                "family": "Zhang",
                "given": "Fan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wang",
                "given": "Zhaohan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Lyu",
                "given": "Xin",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Zhao",
                "given": "Siyuan",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Li",
                "given": "Mengjian",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Geng",
                "given": "Weidong",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Ji",
                "given": "Naye",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Du",
                "given": "Hui",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Gao",
                "given": "Fuxing",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Wu",
                "given": "Hao",
                "countries": [
                    "CN"
                ]
            },
            {
                "family": "Li",
                "given": "Shunman",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Speech-driven Personalized Gesture Synthetics: Harnessing Automatic Fuzzy Feature Inference",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 3024,
        "volume": "",
        "number": "",
        "pages": "",
        "article_number": "",
        "number_of_pages": 16,
        "abstract": "Speech-driven gesture generation is an emerging field within virtual human creation. However, a significant challenge lies in accurately determining and processing the multitude of input features (such as acoustic, semantic, emotional, personality, and even subtle unknown features). Traditional approaches, reliant on various explicit feature inputs and complex multimodal processing, constrain the expressiveness of resulting gestures and limit their applicability. To address these challenges, we present Persona-Gestor, a novel end-to-end generative model designed to generate highly personalized 3D full-body gestures solely relying on raw speech audio. The model combines a fuzzy feature extractor and a non-autoregressive Adaptive Layer Normalization (AdaLN) transformer diffusion architecture (DiTs-based). The fuzzy feature extractor harnesses a fuzzy inference strategy that automatically infers implicit, continuous fuzzy features. These fuzzy features, represented as a unified latent feature, are fed into the AdaLN transformer. The AdaLN transformer introduces a conditional mechanism that applies a uniform function across all tokens, thereby effectively modeling the correlation between the fuzzy features and the gesture sequence. This module ensures a high level of gesture-speech synchronization while preserving naturalness. Finally, we employ the diffusion model to train and infer various gestures. Extensive subjective and objective evaluations on the Trinity, ZEGGS, and BEAT datasets confirm our model's superior performance to the current state-of-the-art approaches. Persona-Gestor improves the system's usability and generalization capabilities, setting a new benchmark in speech-driven gesture synthesis and broadening the horizon for virtual human technology. Supplementary videos and code can be accessed at https://zf223669.github.io/Diffmotion-v2-website/.",
        "countries": [
            "CN"
        ]
    },
    "10.1016/j.cag.2024.103945": {
        "doi": "10.1016/j.cag.2024.103945",
        "authors": [
            {
                "family": "Yal\u00e7\u0131ner",
                "given": "Bora",
                "countries": [
                    "TR"
                ]
            },
            {
                "family": "Aky\u00fcz",
                "given": "Ahmet O\u011fuz",
                "countries": [
                    "TR"
                ]
            }
        ],
        "title": "Path guiding for wavefront path tracing: A memory efficient approach for GPU path tracers",
        "journal": "Computers & Graphics",
        "publication_year": 2024,
        "volume": "121",
        "number": "",
        "pages": "103945",
        "number_of_pages": 12,
        "article_number": "103945",
        "abstract": "We propose a path-guiding algorithm to be incorporated into the wavefront style of path tracers (WFPTs). As WFPTs are primarily implemented on graphics processing units (GPUs), the proposed method aims to leverage the capabilities of the GPUs and reduce the hierarchical data structure and memory usage typically required for such techniques. To achieve this, our algorithm only stores the radiant exitance on a single global sparse voxel octree (SVO) data structure. Probability density functions required to guide the rays are generated on-the-fly using this data structure. The proposed approach reduces the scene-related persistent memory requirements compared to other path-guiding techniques while producing similar or better results depending on scene characteristics. To our knowledge, our algorithm is the first one that incorporates path guiding into a WFPT.",
        "countries": [
            "TR"
        ]
    },
    "10.1109/tvcg.2024.3418653": {
        "doi": "10.1109/tvcg.2024.3418653",
        "authors": [
            {
                "family": "Solunke",
                "given": "Parikshit",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Guardieiro",
                "given": "Vitoria",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Rulff",
                "given": "Jo\u00e3o",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Xenopoulos",
                "given": "Peter",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Chan",
                "given": "Gromit Yeuk-Yin",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Barr",
                "given": "Brian",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Nonato",
                "given": "Luis Gustavo",
                "countries": [
                    "BR"
                ]
            },
            {
                "family": "Silva",
                "given": "Claudio",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "MOUNTAINEER: Topology-Driven Visual Analytics for Comparing Local Explanations",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 3024,
        "volume": "",
        "number": "",
        "pages": "",
        "article_number": "",
        "number_of_pages": 13,
        "abstract": "With the increasing use of black-box Machine Learning (ML) techniques in critical applications, there is a growing demand for methods that can provide transparency and accountability for model predictions. As a result, a large number of local explainability methods for black-box models have been developed and popularized. However, machine learning explanations are still hard to evaluate and compare due to the high dimensionality, heterogeneous representations, varying scales, and stochastic nature of some of these methods. Topological Data Analysis (TDA) can be an effective method in this domain since it can be used to transform attributions into uniform graph representations, providing a common ground for comparison across different explanation methods. We present a novel topology-driven visual analytics tool, Mountaineer, that allows ML practitioners to interactively analyze and compare these representations by linking the topological graphs back to the original data distribution, model predictions, and feature attributions. Mountaineer facilitates rapid and iterative exploration of ML explanations, enabling experts to gain deeper insights into the explanation techniques, understand the underlying data distributions, and thus reach well-founded conclusions about model behavior. Furthermore, we demonstrate the utility of Mountaineer through two case studies using real-world data. In the first, we show how Mountaineer enabled us to compare black-box ML explanations and discern regions of and causes of disagreements between different explanations. In the second, we demonstrate how the tool can be used to compare and understand ML models themselves. Finally, we conducted interviews with three industry experts to help us evaluate our work.",
        "countries": [
            "US",
            "BR"
        ]
    },
    "10.1016/j.cag.2024.104001": {
        "doi": "10.1016/j.cag.2024.104001",
        "authors": [
            {
                "family": "Kar\u010diauskas",
                "given": "K\u0229stutis",
                "countries": [
                    "LT"
                ]
            },
            {
                "family": "Peters",
                "given": "J\u00f6rg",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Quadratic-attraction subdivision with contraction-ratio \n                  \n                     \u03bb\n                     =\n                     \n                        \n                           1\n                        \n                        \n                           2",
        "journal": "Computers & Graphics",
        "publication_year": 2024,
        "volume": "123",
        "number": "",
        "pages": "104001",
        "number_of_pages": 11,
        "article_number": "104001",
        "abstract": "Classic generalized subdivision, such as Catmull\u2013Clark subdivision, as well as recent subdivision algorithms for high-quality surfaces, rely on slower convergence towards extraordinary points for mesh nodes surrounded by \n \n n\n >\n 4\n \n quadrilaterals. Slow convergence corresponds to a contraction-ratio of \n \n \u03bb\n >\n 0\n .\n 5\n \n . To improve shape, prevent parameterization discordant with surface growth, or to improve convergence in isogeometric analysis near extraordinary points, a number of algorithms explicitly adjust \n \u03bb\n by altering refinement rules. However, such tuning of \n \u03bb\n has so far led to poorer surface quality, visible as uneven distribution or oscillation of highlight lines. The recent Quadratic-Attraction Subdivision (QAS) generates high-quality, bounded curvature surfaces based on a careful choice of quadratic expansion at the central point and, just like Catmull\u2013Clark subdivision, creates the control points of the next subdivision ring by matrix multiplication. But QAS shares the contraction-ratio \n \n \n \n \u03bb\n \n \n C\n C\n \n \n >\n 1\n /\n 2\n \n of Catmull\u2013Clark subdivision when \n \n n\n >\n 4\n \n . For \n \n n\n =\n 5\n ,\n \u2026\n ,\n 10\n \n , QAS\n \n \n \n +\n \n \n improves the convergence to the uniform \n \n \u03bb\n =\n \n \n 1\n \n \n 2\n \n \n \n of binary domain refinement and without sacrificing surface quality compared to QAS.",
        "countries": [
            "LT",
            "US"
        ]
    },
    "10.1016/j.cag.2024.103951": {
        "doi": "10.1016/j.cag.2024.103951",
        "authors": [
            {
                "family": "Asiler",
                "given": "Merve",
                "countries": [
                    "TR"
                ]
            },
            {
                "family": "Sahillio\u011flu",
                "given": "Yusuf",
                "countries": [
                    "TR"
                ]
            }
        ],
        "title": "3D geometric kernel computation in polygon mesh structures",
        "journal": "Computers & Graphics",
        "publication_year": 2024,
        "volume": "122",
        "number": "",
        "pages": "103951",
        "number_of_pages": 11,
        "article_number": "103951",
        "abstract": "This paper introduces a novel approach to compute the geometric kernel of a polygon mesh embedded in 3D. The geometric kernel defines the set of points inside or on the shape\u2019s boundary, ensuring visibility of the entire shape. The proposed method utilizes scattered rays to identify a sufficient number of sample points on the kernel surface and subsequently leverages these points to locate as many surface vertices as possible. By computing the convex hull of these identified points, we derive an approximation of the kernel. Notably, the output of our method consists exclusively of interior or boundary points of the actual kernel. Comparative evaluations against established CGAL and Polyhedron Kernel algorithms highlight our method\u2019s superior computational speed and high approximation accuracy. The parametric structure of our solution allows for different levels of accuracy to be obtained, enabling the user to tailor the approximation to their specific needs. This property sets our algorithm apart from others and provides greater flexibility in its use. Additionally, adjusting the algorithmic settings also enables the computation of the kernel itself with a trade-off in computational speed. Furthermore, our algorithm swiftly and accurately identifies an empty kernel for non-star-shaped configurations.",
        "countries": [
            "TR"
        ]
    },
    "10.1016/j.cag.2024.103997": {
        "doi": "10.1016/j.cag.2024.103997",
        "authors": [
            {
                "family": "Gisbert",
                "given": "Guillaume",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Chaine",
                "given": "Rapha\u00eblle",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Coeurjolly",
                "given": "David",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "Neural inpainting of folded fabrics with interactive editing",
        "journal": "Computers & Graphics",
        "publication_year": 2024,
        "volume": "122",
        "number": "",
        "pages": "103997",
        "number_of_pages": 9,
        "article_number": "103997",
        "abstract": "We propose a deep learning approach for inpainting holes in digital models of fabric surfaces. Leveraging the developable nature of fabric surfaces, we flatten the area surrounding the holes with minor distortion and regularly sample it to obtain a discrete 2D map of the 3D embedding, with an indicator mask outlining holes locations. This enables the use of a standard 2D convolutional neural network to inpaint holes given the 3D positioning of the surface. The provided neural architecture includes an attention mechanism to capture long-range relationships on the surface. Finally, we provide ScarfFolds, a database of folded fabrics patches with varying complexity, which is used to train our convolutional network in a supervised manner. We successfully tested our approach on various examples and illustrated that previous 3D deep learning approaches suffer from several issues when applied to fabrics. Also, our method allows the users to interact with the construction of the inpainted surface. The editing is interactive and supports many tools like vertex grabbing, drape twisting or pinching.",
        "countries": [
            "FR"
        ]
    },
    "10.1145/3641519.3657435": {
        "doi": "10.1145/3641519.3657435",
        "authors": [
            {
                "family": "Huang",
                "given": "Xingchang",
                "orcid": "0000-0002-2769-8408",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Salaun",
                "given": "Corentin",
                "orcid": "0000-0002-5112-7488",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Vasconcelos",
                "given": "Cristina",
                "orcid": "0000-0003-2112-4806",
                "countries": [
                    "CA"
                ]
            },
            {
                "family": "Theobalt",
                "given": "Christian",
                "orcid": "0000-0001-6104-6625",
                "countries": [
                    "DE"
                ]
            },
            {
                "family": "Oztireli",
                "given": "Cengiz",
                "orcid": "0000-0002-4700-2236",
                "countries": [
                    "CH",
                    "GB"
                ]
            },
            {
                "family": "Singh",
                "given": "Gurprit",
                "orcid": "0000-0003-0970-5835",
                "countries": [
                    "DE"
                ]
            }
        ],
        "title": "Blue noise for diffusion models",
        "journal": "ACM SIGGRAPH Conference Papers",
        "publication_year": 2024,
        "volume": "0",
        "number": "0",
        "pages": "28:1\u201328:11",
        "article_number": "28",
        "number_of_pages": 11,
        "abstract": "Most of the existing diffusion models use Gaussian noise for training and sampling across all time steps, which may not optimally account for the frequency contents reconstructed by the denoising network. Despite the diverse applications of correlated noise in computer graphics, its potential for improving the training process has been underexplored. In this paper, we introduce a novel and general class of diffusion models taking correlated noise within and across images into account. More specifically, we propose a time-varying noise model to incorporate correlated noise into the training process, as well as a method for fast generation of correlated noise mask. Our model is built upon deterministic diffusion models and utilizes blue noise to help improve the generation quality compared to using Gaussian white (random) noise only. Further, our framework allows introducing correlation across images within a single mini-batch to improve gradient flow. We perform both qualitative and quantitative evaluations on a variety of datasets using our method, achieving improvements on different tasks over existing deterministic diffusion models in terms of FID metric. Code will be available at https://github.com/xchhuang/bndm.",
        "countries": [
            "DE",
            "CA",
            "CH",
            "GB"
        ]
    },
    "10.1016/j.cag.2024.103998": {
        "doi": "10.1016/j.cag.2024.103998",
        "authors": [
            {
                "family": "Lu",
                "given": "Yukun",
                "countries": [
                    "CN",
                    "SG"
                ]
            },
            {
                "family": "Wang",
                "given": "Yuhang",
                "countries": [
                    "CN",
                    "SG"
                ]
            },
            {
                "family": "Song",
                "given": "Peng",
                "countries": [
                    "SG"
                ]
            },
            {
                "family": "Wong",
                "given": "Hang Siang",
                "countries": [
                    "SG"
                ]
            },
            {
                "family": "Mok",
                "given": "Yingjuan",
                "countries": [
                    "SG"
                ]
            },
            {
                "family": "Liu",
                "given": "Ligang",
                "countries": [
                    "CN"
                ]
            }
        ],
        "title": "Computational design of custom-fit PAP masks",
        "journal": "Computers & Graphics",
        "publication_year": 2024,
        "volume": "122",
        "number": "",
        "pages": "103998",
        "number_of_pages": 11,
        "article_number": "103998",
        "abstract": "Positive airway pressure (PAP) therapy refers to sleep disordered breathing treatment that uses a stream of compressed air to support the airway during sleep. Even though the use of PAP therapy has been shown to be effective in improving the symptoms and quality of life, many patients are intolerant of the treatment due to poor mask fit. In this paper, our goal is to develop a computational approach for designing custom-fit PAP masks such that they can achieve better mask fit performance in terms of mask leakage and comfort. Our key observation is that a custom-fit PAP mask should fit a patient\u2019s face in its deformed state instead of in its rest state since the PAP mask cushion undergoes notable deformation before reaching an equilibrium state during PAP therapy. To this end, we compute the equilibrium state of a mask cushion using the finite element method, and quantitatively measure the leakage and comfort of the mask cushion in this state. We further optimize the mask cushion geometry to minimize the two measures while ensuring that the cushion can be easily fabricated with molding. We demonstrate the effectiveness of our computational approach on a variety of face models and different types of PAP masks. Experimental results on real subjects show that our designed custom-fit PAP masks are able to achieve better mask fit performance than a generic PAP mask and custom-fit PAP masks designed by a state-of-the-art approach.",
        "countries": [
            "CN",
            "SG"
        ]
    },
    "10.1016/j.cag.2024.103979": {
        "doi": "10.1016/j.cag.2024.103979",
        "authors": [
            {
                "family": "Yildiz",
                "given": "Tolga",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Akleman",
                "given": "Ergun",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "Volumetric nonwoven structures: An algebraic framework for systematic design of infinite polyhedral frames using nonwoven fabric patterns",
        "journal": "Computers & Graphics",
        "publication_year": 2024,
        "volume": "122",
        "number": "",
        "pages": "103979",
        "number_of_pages": 10,
        "article_number": "103979",
        "abstract": "In this paper, we present an algebraic framework that can be used to construct a large class of 3D shapes and structures that can potentially provide unusual material properties. We formalized this framework as a 3D generalization of planar nonwoven textile structures that are used to mimic the woven structures. Our extension is based on the fact that it is straightforward to extend planar nonwoven textile structures into volumetric nonwoven textile structures, which we also call nonwoven volumetric fabrics. This property is essential because such an extension is impossible with planar woven structures. In other words, using this approach, it can be possible to easily produce volumetric structures that mimic the fabric behavior as if they were planar nonwoven textile structures, which is impossible to produce. These volumetric structures also correspond to regular & semiregular frame structures and are capable of representing previously unknown infinite regular polyhedra and flexible wood structures.",
        "countries": [
            "US"
        ]
    },
    "10.vis2024/1153": {
        "doi": "10.vis2024/1153",
        "authors": [
            {
                "family": "van den Broek",
                "given": "Steven",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Meulemans",
                "given": "Wouter",
                "countries": [
                    "NL"
                ]
            },
            {
                "family": "Speckmann",
                "given": "Bettina",
                "countries": [
                    "NL"
                ]
            }
        ],
        "title": "SimpleSets: Capturing Categorical Point Patterns with Simple Shapes",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 3024,
        "volume": "",
        "number": "",
        "pages": "",
        "number_of_pages": -1,
        "article_number": "",
        "abstract": "Points of interest on a map such as restaurants, hotels, or subway stations, give rise to categorical point data: data that have a fixed location and one or more categorical attributes. Consequently, recent years have seen various set visualization approaches that visually connect points of the same category to support users in understanding the spatial distribution of categories. Existing methods use complex and often highly irregular shapes to connect points of the same category, leading to high cognitive load for the user. In this paper we introduce SimpleSets, which uses simple shapes to enclose categorical point patterns, thereby providing a clean overview of the data distribution. SimpleSets is designed to visualize sets of points with a single categorical attribute; as a result, the point patterns enclosed by SimpleSets form a partition of the data. We give formal definitions of point patterns that correspond to simple shapes and describe an algorithm that partitions categorical points into few such patterns. Our second contribution is a rendering algorithm that transforms a given partition into a clean set of shapes resulting in an aesthetically pleasing set visualization. Our algorithm pays particular attention to resolving intersections between nearby shapes in a consistent manner. We compare SimpleSets to the state-of-the-art set visualizations using standard datasets from the literature.",
        "countries": [
            "NL"
        ]
    },
    "10.vis2024/1461": {
        "doi": "10.vis2024/1461",
        "authors": [
            {
                "family": "Kissi",
                "given": "Mohamed",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Pont",
                "given": "Mathieu",
                "countries": [
                    "FR"
                ]
            },
            {
                "family": "Levine",
                "given": "Joshua A.",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Tierny",
                "given": "Julien",
                "countries": [
                    "FR"
                ]
            }
        ],
        "title": "A Practical Solver for Scalar Data Topological Simplification",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 3024,
        "volume": "",
        "number": "",
        "pages": "",
        "number_of_pages": -1,
        "article_number": "",
        "abstract": "Points of interest on a map such as restaurants, hotels, or subway stations, give rise to categorical point data: data that have a fixed location and one or more categorical attributes. Consequently, recent years have seen various set visualization approaches that visually connect points of the same category to support users in understanding the spatial distribution of categories. Existing methods use complex and often highly irregular shapes to connect points of the same category, leading to high cognitive load for the user. In this paper we introduce SimpleSets, which uses simple shapes to enclose categorical point patterns, thereby providing a clean overview of the data distribution. SimpleSets is designed to visualize sets of points with a single categorical attribute; as a result, the point patterns enclosed by SimpleSets form a partition of the data. We give formal definitions of point patterns that correspond to simple shapes and describe an algorithm that partitions categorical points into few such patterns. Our second contribution is a rendering algorithm that transforms a given partition into a clean set of shapes resulting in an aesthetically pleasing set visualization. Our algorithm pays particular attention to resolving intersections between nearby shapes in a consistent manner. We compare SimpleSets to the state-of-the-art set visualizations using standard datasets from the literature.",
        "countries": [
            "FR",
            "US"
        ]
    },
    "10.vis2024/1204": {
        "doi": "10.vis2024/1204",
        "authors": [
            {
                "family": "Narechania",
                "given": "Arpit",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "Odak",
                "given": "Kaustubh",
                "countries": [
                    "US"
                ]
            },
            {
                "family": "El-Assady",
                "given": "Mennatallah",
                "countries": [
                    "CH"
                ]
            },
            {
                "family": "Endert",
                "given": "Alex",
                "countries": [
                    "US"
                ]
            }
        ],
        "title": "ProvenanceWidgets: A Library of UI Control Elements to Track and Dynamically Overlay Analytic Provenance",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "publication_year": 3024,
        "volume": "",
        "number": "",
        "pages": "",
        "number_of_pages": -1,
        "article_number": "",
        "abstract": "We present ProvenanceWidgets, a Javascript library of UI control elements such as radio buttons, checkboxes, and dropdowns to track and dynamically overlay a user's analytic provenance. These in situ overlays not only save screen space but also minimize the amount of time and effort needed to access the same information from elsewhere in the UI. In this paper, we discuss how we design modular UI control elements to track how often and how recently a user interacts with them and design visual overlays showing an aggregated summary as well as a detailed temporal history. We demonstrate the capability of ProvenanceWidgets by recreating three prior widget libraries: (1) Scented Widgets, (2) Phosphor objects, and (3) Dynamic Query Widgets. We also evaluated its expressiveness and conducted case studies with visualization developers to evaluate its effectiveness. We find that ProvenanceWidgets enables developers to implement custom provenance-tracking applications effectively. ProvenanceWidgets is available as open-source software at this https URL to help application developers build custom provenance-based systems.",
        "countries": [
            "US",
            "CH"
        ]
    }
}